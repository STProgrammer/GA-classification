{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graded assignment 1 - text classification using Genetic Algorithms\n",
    "## By Abdullah Karagøz\n",
    "\n",
    "In this assignmetn we'll make a binary text classifier using genetic algorithms. We will classify movie reviews from IMDB as either negative or positive. This task consists of several steps:\n",
    "\n",
    "1. Preprocessing of the text\n",
    "2. Genetich Algorithm\n",
    "3. Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Uploading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abdka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abdka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Upload the text\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from scipy import special\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File directories\n",
    "corpus_train_pos_root = 'aclImdb/train/pos/'\n",
    "corpus_train_neg_root = 'aclImdb/train/neg/'\n",
    "corpus_test_pos_root = 'aclImdb/test/pos/'\n",
    "corpus_test_neg_root = 'aclImdb/test/neg/'\n",
    "\n",
    "# Corpus file objects\n",
    "files_train_pos = PlaintextCorpusReader(corpus_train_pos_root, '.*')\n",
    "files_train_neg = PlaintextCorpusReader(corpus_train_neg_root, '.*')\n",
    "files_test_pos = PlaintextCorpusReader(corpus_test_pos_root, '.*')\n",
    "files_test_neg = PlaintextCorpusReader(corpus_test_neg_root, '.*')\n",
    "\n",
    "\n",
    "# Getting review texts, labels and rates all in arrays\n",
    "# Here we save the labels as one hot encoded arrays so it's easier to make\n",
    "# calculations in the classifier easier.\n",
    "reviews_train_pos = [files_train_pos.open(n).read() for n in files_train_pos.fileids()]\n",
    "rates_train_pos = [int(re.split(\"_|\\.\", n)[-2]) for n in files_train_pos.fileids()]\n",
    "labels_train_pos = [1] * len(reviews_train_pos)\n",
    "\n",
    "reviews_train_neg = [files_train_neg.open(n).read() for n in files_train_neg.fileids()]\n",
    "rates_train_neg = [int(re.split(\"_|\\.\", n)[-2]) for n in files_train_neg.fileids()]\n",
    "labels_train_neg = [0] * len(reviews_train_neg)\n",
    "\n",
    "reviews_test_pos = [files_test_pos.open(n).read() for n in files_test_pos.fileids()]\n",
    "rates_test_pos = [int(re.split(\"_|\\.\", n)[-2]) for n in files_test_pos.fileids()]\n",
    "labels_test_pos = [1] * len(reviews_test_pos)\n",
    "\n",
    "reviews_test_neg = [files_test_neg.open(n).read() for n in files_test_neg.fileids()]\n",
    "rates_test_neg = [int(re.split(\"_|\\.\", n)[-2]) for n in files_test_neg.fileids()]\n",
    "labels_test_neg = [0] * len(reviews_test_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting all into two Pandas dataframes - training set and testing set\n",
    "train_set = pd.DataFrame()\n",
    "test_set = pd.DataFrame()\n",
    "valid_set = pd.DataFrame()\n",
    "\n",
    "train_set['review'] = reviews_train_pos + reviews_train_neg\n",
    "train_set['rate'] = rates_train_pos + rates_train_neg\n",
    "train_set['label'] = labels_train_pos + labels_train_neg\n",
    "\n",
    "negs_cut = int(len(labels_test_neg)/2)\n",
    "poss_cut = int(len(labels_test_pos)/2)\n",
    "\n",
    "test_set['review'] = reviews_test_pos[:poss_cut] + reviews_test_neg[:negs_cut]\n",
    "test_set['rate'] = rates_test_pos[:poss_cut] + rates_test_neg[:negs_cut]\n",
    "test_set['label'] = labels_test_pos[:poss_cut] + labels_test_neg[:negs_cut]\n",
    "\n",
    "valid_set['review'] = reviews_test_pos[poss_cut:] + reviews_test_neg[negs_cut:]\n",
    "valid_set['rate'] = rates_test_pos[poss_cut:] + rates_test_neg[negs_cut:]\n",
    "valid_set['label'] = labels_test_pos[poss_cut:] + labels_test_neg[negs_cut:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>Killjoy 2 is the same as killjoy 1. Bad acting...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>I really don't know why I agreed to watch this...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>Cops Logan Alexander and Debbie Rochon escort ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>Chuck Norris stars as Danny, a cop who took do...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>This film could cure sleep disorders, thats ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rate  label\n",
       "0      I went and saw this movie last night after bei...    10      1\n",
       "1      Actor turned director Bill Paxton follows up h...     7      1\n",
       "2      As a recreational golfer with some knowledge o...     9      1\n",
       "3      I saw this film in a sneak preview, and it is ...     8      1\n",
       "4      Bill Paxton has taken the true story of the 19...     8      1\n",
       "...                                                  ...   ...    ...\n",
       "12495  Killjoy 2 is the same as killjoy 1. Bad acting...     1      0\n",
       "12496  I really don't know why I agreed to watch this...     1      0\n",
       "12497  Cops Logan Alexander and Debbie Rochon escort ...     2      0\n",
       "12498  Chuck Norris stars as Danny, a cop who took do...     2      0\n",
       "12499  This film could cure sleep disorders, thats ho...     1      0\n",
       "\n",
       "[12500 rows x 3 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common 20 counted by appearance in nr of reviews:  [('the', 24666), ('a', 24047), ('and', 23964), ('of', 23675), ('to', 23405), ('is', 22260), ('in', 21644), ('this', 20697), ('that', 19539), ('it', 19041), ('I', 17968), ('for', 17356), ('with', 17062), ('but', 16164), ('was', 15992), ('The', 15610), ('as', 15376), ('on', 14946), ('/><br', 14665), ('have', 14011)]\n",
      "/nMost common 20 counted by word count total:  [('the', 287032), ('a', 155096), ('and', 152664), ('of', 142972), ('to', 132568), ('is', 103229), ('in', 85580), ('I', 65973), ('that', 64560), ('this', 57199), ('it', 54439), ('/><br', 50935), ('was', 46698), ('as', 42510), ('with', 41721), ('for', 41070), ('but', 33790), ('The', 33762), ('on', 30767), ('movie', 30506)]\n"
     ]
    }
   ],
   "source": [
    "# Data exploration\n",
    "# Most common words\n",
    "\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "cnt2 = Counter()\n",
    "for text in train_set[\"review\"].values:\n",
    "    # Counting the words\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "    # Counting in how many reviews the word appears\n",
    "    for word in set(text.split()):\n",
    "        cnt2[word] += 1\n",
    "\n",
    "print(\"Most common 20 counted by appearance in nr of reviews: \", cnt2.most_common(20))\n",
    "print(\"/nMost common 20 counted by word count total: \", cnt.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '% of documents')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What % of the reviews use what % of the vocab\n",
    "vocab_size = len(cnt2)\n",
    "sample_size = 25000\n",
    "\n",
    "y = [c/sample_size * 100 for (w, c) in cnt2.most_common()]\n",
    "x = [c/vocab_size * 100 for c in range(1, vocab_size+1)]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x, y)\n",
    "ax.set_title(\"% of the words used in % of the documents\")\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel(\"% of vocabolary\")\n",
    "ax.set_ylabel(\"% of documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Preprocessing and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I think to put this into own .PY file and import from there\n",
    "class text_preprocessor():\n",
    "    def __init__(self):\n",
    "        import nltk\n",
    "        import re\n",
    "        import string\n",
    "        \n",
    "        nltk.download('stopwords')\n",
    "        nltk.download('wordnet')\n",
    "        from nltk.corpus import stopwords\n",
    "        \", \".join(stopwords.words('english'))\n",
    "        from nltk.stem.wordnet import WordNetLemmatizer \n",
    "        \n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        self.punctuation = string.punctuation\n",
    "        \n",
    "        self.emoji_pattern = re.compile(\"[\"\n",
    "                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                u\"\\U00002702-\\U000027B0\"\n",
    "                                u\"\\U000024C2-\\U0001F251\"\n",
    "                                \"]+\", flags=re.UNICODE)\n",
    "        \n",
    "        # src : https://github.com/NeelShah18/emot/blob/master/emot/emo_unicode.py\n",
    "        self.emoticons = {\n",
    "            u\":‑\\)\":\"Happy face or smiley\",\n",
    "            u\":\\)\":\"Happy face or smiley\",\n",
    "            u\":-\\]\":\"Happy face or smiley\",\n",
    "            u\":\\]\":\"Happy face or smiley\",\n",
    "            u\":-3\":\"Happy face smiley\",\n",
    "            u\":3\":\"Happy face smiley\",\n",
    "            u\":->\":\"Happy face smiley\",\n",
    "            u\":>\":\"Happy face smiley\",\n",
    "            u\"8-\\)\":\"Happy face smiley\",\n",
    "            u\":o\\)\":\"Happy face smiley\",\n",
    "            u\":-\\}\":\"Happy face smiley\",\n",
    "            u\":\\}\":\"Happy face smiley\",\n",
    "            u\":-\\)\":\"Happy face smiley\",\n",
    "            u\":c\\)\":\"Happy face smiley\",\n",
    "            u\":\\^\\)\":\"Happy face smiley\",\n",
    "            u\"=\\]\":\"Happy face smiley\",\n",
    "            u\"=\\)\":\"Happy face smiley\"\n",
    "        }\n",
    "\n",
    "    def lower_case(self, text):\n",
    "        return str.lower(text)\n",
    "    \n",
    "    def remove_punctuation(self, text):\n",
    "        return text.translate(str.maketrans('', '', self.punctuation))\n",
    "    \n",
    "    def remove_stopwords(self, text):\n",
    "        return [word for word in text if word not in self.stop_words]\n",
    "    \n",
    "    def remove_words(self, text, freq_words):\n",
    "        return [word for word in text if word not in freq_words]\n",
    "    \n",
    "    def remove_emoji(self, text):\n",
    "        # src: https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "        return self.emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    \n",
    "    def remove_emoticons(self, text):\n",
    "        import re\n",
    "        # src : https://github.com/NeelShah18/emot/blob/master/emot/emo_unicode.py\n",
    "        emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in self.emoticons) + u')')\n",
    "        return emoticon_pattern.sub(r'', text)\n",
    "    \n",
    "    def convert_emoticons(self, text):\n",
    "        # src : https://github.com/NeelShah18/emot/blob/master/emot/emo_unicode.py\n",
    "        for emot in self.emoticons:\n",
    "            text = re.sub(u'('+emot+')', \"_\".join(self.emoticons[emot].replace(\",\",\"\").split()), text)\n",
    "        return text\n",
    "    \n",
    "    def lemmatization(self, text):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = word_tokenize(text)\n",
    "        for i in ['v','n','a']:\n",
    "            tokens = [lemmatizer.lemmatize(word, i) for word in tokens]\n",
    "        return tokens\n",
    "    \n",
    "    def expand_contractions(self, text):\n",
    "        text = re.sub(r\"i'm\", \" i am \", text)\n",
    "        text = re.sub(r\" im \", \" i am \", text)\n",
    "        text = re.sub(r\"\\: p\", \"\", text)\n",
    "        text = re.sub(r\" ive \", \" i have \", text)\n",
    "        text = re.sub(r\" he's \", \" he is \", text)\n",
    "        text = re.sub(r\" she's \", \" she is \", text)\n",
    "        text = re.sub(r\" that's \", \" that is \", text)\n",
    "        text = re.sub(r\" what's \", \" what is \", text)\n",
    "        text = re.sub(r\" where's \", \" where is \", text)\n",
    "        text = re.sub(r\" haven't \", \" have not \", text)\n",
    "        text = re.sub(r\" ur \", \" you are \", text)\n",
    "        text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "        text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "        text = re.sub(r\"\\'re\", \" are\", text)\n",
    "        text = re.sub(r\"\\'d\", \" would\", text)\n",
    "        text = re.sub(r\" won't \", \" will not \", text)\n",
    "        text = re.sub(r\" wouldn't \", \" would not \", text)\n",
    "        text = re.sub(r\" can't \", \" cannot \", text)\n",
    "        text = re.sub(r\" couldn't \", \" could not \", text)\n",
    "        text = re.sub(r\" don't \", \" do not \", text)\n",
    "        text = re.sub(r\" didn't \", \" did not \", text)\n",
    "        text = re.sub(r\" doesn't \", \" does not \", text)\n",
    "        text = re.sub(r\" isn't \", \" is not \", text)\n",
    "        text = re.sub(r\" it's \", \" it is \", text)\n",
    "        text = re.sub(r\" who's \", \" who is \", text)\n",
    "        text = re.sub(r\" there's \", \" there is \", text)\n",
    "        text = re.sub(r\" weren't \", \" were not \", text)\n",
    "        text = re.sub(r\" ok \", \" okay \", text)\n",
    "        text = re.sub(r\" you're \", \" you are \", text)\n",
    "        text = re.sub(r\" c'mon \", \" come on \", text)\n",
    "        text = re.sub(r\"in'\", \"ing\", text)\n",
    "        text = re.sub(r\"\\'s\", \" s\", text)\n",
    "        return text\n",
    "    \n",
    "    def remove_urls(self, text):\n",
    "        url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "        return url_pattern.sub(r'', text)\n",
    "    \n",
    "    # preprocessing IMDB reviews\n",
    "    def preprocess_imdb_reviews(self, df, max_df, min_df, n_freq_words = 10, n_rare_words = 10):\n",
    "        df['processed'] = df['review'].apply(lambda text: self.lower_case(text))\n",
    "        df['processed'] = df['processed'].apply(lambda text: self.expand_contractions(text))\n",
    "        df['processed'] = df['processed'].apply(lambda text: self.remove_urls(text))\n",
    "        df['processed'] = df['processed'].apply(lambda text: self.remove_emoji(text))\n",
    "        df['processed'] = df['processed'].apply(lambda text: self.remove_punctuation(text))\n",
    "        df['tokenized'] = df['processed'].apply(lambda text: self.lemmatization(text))\n",
    "        df['tokenized'] = df['tokenized'].apply(lambda text: self.remove_stopwords(text))\n",
    "        \n",
    "        # We tokenize the strings first after lemmatization. And when we tokenize the words we don't\n",
    "        # convert it to string again. That is because we have to tokenize in TF-IDF vectorization later\n",
    "        # anyway so no need to use extra time on that.\n",
    "\n",
    "        from collections import Counter\n",
    "        cnt = Counter()\n",
    "        cnt2 = Counter()\n",
    "        for text in df['tokenized'].values:\n",
    "            # Counting the words\n",
    "            for word in text:\n",
    "                cnt[word] += 1\n",
    "            # Counting in how many reviews the word appears\n",
    "            for word in set(text):\n",
    "                cnt2[word] += 1\n",
    "\n",
    "\n",
    "        # Removing most frequent words\n",
    "        freq_words = set([w for (w, wc) in cnt.most_common(n_freq_words)])\n",
    "        df['tokenized'] = df['tokenized'].apply(lambda text: self.remove_words(text, freq_words))\n",
    "\n",
    "        # Removing rarest words\n",
    "        rare_words = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
    "        df['tokenized'] = df['tokenized'].apply(lambda text: self.remove_words(text, rare_words))\n",
    "\n",
    "\n",
    "        # Remove words used in >90% and <5% of the reviews\n",
    "        curb_max_amount = len(df) * max_df\n",
    "        curb_min_amount = len(df) * min_df\n",
    "\n",
    "        curb_words = set([w for (w, wc) in cnt2.most_common() if wc > curb_max_amount or wc < curb_min_amount])\n",
    "\n",
    "        df['tokenized'] = df['tokenized'].apply(lambda text: self.remove_words(text, curb_words))\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TF-IDF VECTORIZER CLASS\n",
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from nltk import FreqDist\n",
    "\n",
    "class TfIdfVectorizer:\n",
    "    def __init__(self, df):\n",
    "        self._idfs = self.prepare_idfs(df)\n",
    "        self._vocab = self.prepare_vocab(df)\n",
    "    \n",
    "    @property\n",
    "    def idfs(self):\n",
    "        return self._idfs\n",
    "    \n",
    "    @idfs.setter\n",
    "    def idfs(self, idfs):\n",
    "        self._idfs = idfs\n",
    "    \n",
    "    @property\n",
    "    def vocab(self):\n",
    "        return self._vocab\n",
    "    \n",
    "    @vocab.setter\n",
    "    def vocab(self, vocab):\n",
    "        self._vocab = vocab\n",
    "    \n",
    "    # Prepare and return vocab out of corpus\n",
    "    def prepare_vocab(self, df):\n",
    "        # Prepare the vocab\n",
    "        self.vocab = set(np.hstack(df['tokenized'].values))\n",
    "        self.vocab = dict.fromkeys(self.vocab, 0)\n",
    "        self.vocab.update((k, i) for i, k in enumerate(self.vocab))\n",
    "        return self.vocab\n",
    "    \n",
    "    # Prepare and return idfs out of corpus\n",
    "    def prepare_idfs(self, df):\n",
    "        # Counting how many reviews a word appears ins\n",
    "        cnt = Counter()\n",
    "        for text in df[\"tokenized\"].values:\n",
    "            for word in set(text):\n",
    "                cnt[word] += 1\n",
    "        # Preparing the IDF vector\n",
    "        size = len(df)\n",
    "        self.idfs = dict()\n",
    "        for w, c in cnt.items():\n",
    "            self.idfs[w] = 0 if c == 0 else math.log(size / c)\n",
    "        return self.idfs\n",
    "\n",
    "\n",
    "    # TF-IDF vectorize a single text, returning an np.array\n",
    "    def tf_idf_vectorize(self, text):\n",
    "        freq_dist = FreqDist(text)\n",
    "        vector = np.zeros(len(self.vocab))\n",
    "        for w, c in freq_dist.items():\n",
    "            if w in self.vocab:\n",
    "                vector[self.vocab[w]] = c * self.idfs[w]\n",
    "        return vector\n",
    "\n",
    "\n",
    "    # One hot encode labels\n",
    "    def one_hot_encode(self, label, nr_of_labels):\n",
    "        arr = np.zeros(nr_of_labels, dtype=int)\n",
    "        arr[label] = 1\n",
    "        return arr\n",
    "\n",
    "    # Vectorize all in the dataset\n",
    "    def tf_idf_vectorize_all(self, df):\n",
    "        df['vectors'] = df['tokenized'].apply(lambda text: self.tf_idf_vectorize(text))\n",
    "        return df\n",
    "    \n",
    "    # Turn all labels into one hot encoded arrays\n",
    "    def one_hot_encode_all(self, df, nr_of_labels):\n",
    "        df['label-encoded'] = df['label'].apply(lambda label: self.one_hot_encode(label, nr_of_labels))\n",
    "        return df\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abdka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abdka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "      <th>label</th>\n",
       "      <th>processed</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's Bad for Ya really showcases more of Georg...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>it s bad for ya really showcases more of georg...</td>\n",
       "      <td>[bad, really, really, still, lose, year, comed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It might be a stretch saying this as a die-har...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>it might be a stretch saying this as a diehard...</td>\n",
       "      <td>[might, say, fan, write, bad, best, yet, back,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can't say I enjoyed this as much as \"The Big...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>i cannot say i enjoyed this as much as the big...</td>\n",
       "      <td>[say, enjoy, much, big, little, laugh, sense, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie was sooooooo good! It was hilarious...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>this movie was sooooooo good it was hilarious ...</td>\n",
       "      <td>[many, watch, john, love, guy, love, go, defin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jean Renoir's homage to the Paris of the late ...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>jean renoir s homage to the paris of the late ...</td>\n",
       "      <td>[late, beautiful, many, way, appear, end, men,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>I occasionally let my kids watch this garbage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>i occasionally let my kids watch this garbage ...</td>\n",
       "      <td>[let, kid, watch, understand, show, minute, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>When all we have anymore is pretty much realit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>when all we have anymore is pretty much realit...</td>\n",
       "      <td>[pretty, much, tv, show, people, reason, worth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>The basic genre is a thriller intercut with an...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>the basic genre is a thriller intercut with an...</td>\n",
       "      <td>[try, lot, use, title, bring, small, surprise,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>Four things intrigued me as to this film - fir...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>four things intrigued me as to this film  firs...</td>\n",
       "      <td>[thing, star, always, watch, feature, new, new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>David Bryce's comments nearby are exceptionall...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>david bryce s comments nearby are exceptionall...</td>\n",
       "      <td>[well, write, almost, say, everything, feel, m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rate  label  \\\n",
       "0      It's Bad for Ya really showcases more of Georg...    10      1   \n",
       "1      It might be a stretch saying this as a die-har...    10      1   \n",
       "2      I can't say I enjoyed this as much as \"The Big...     7      1   \n",
       "3      This movie was sooooooo good! It was hilarious...    10      1   \n",
       "4      Jean Renoir's homage to the Paris of the late ...     9      1   \n",
       "...                                                  ...   ...    ...   \n",
       "12495  I occasionally let my kids watch this garbage ...     1      0   \n",
       "12496  When all we have anymore is pretty much realit...     1      0   \n",
       "12497  The basic genre is a thriller intercut with an...     3      0   \n",
       "12498  Four things intrigued me as to this film - fir...     3      0   \n",
       "12499  David Bryce's comments nearby are exceptionall...     4      0   \n",
       "\n",
       "                                               processed  \\\n",
       "0      it s bad for ya really showcases more of georg...   \n",
       "1      it might be a stretch saying this as a diehard...   \n",
       "2      i cannot say i enjoyed this as much as the big...   \n",
       "3      this movie was sooooooo good it was hilarious ...   \n",
       "4      jean renoir s homage to the paris of the late ...   \n",
       "...                                                  ...   \n",
       "12495  i occasionally let my kids watch this garbage ...   \n",
       "12496  when all we have anymore is pretty much realit...   \n",
       "12497  the basic genre is a thriller intercut with an...   \n",
       "12498  four things intrigued me as to this film  firs...   \n",
       "12499  david bryce s comments nearby are exceptionall...   \n",
       "\n",
       "                                               tokenized  \n",
       "0      [bad, really, really, still, lose, year, comed...  \n",
       "1      [might, say, fan, write, bad, best, yet, back,...  \n",
       "2      [say, enjoy, much, big, little, laugh, sense, ...  \n",
       "3      [many, watch, john, love, guy, love, go, defin...  \n",
       "4      [late, beautiful, many, way, appear, end, men,...  \n",
       "...                                                  ...  \n",
       "12495  [let, kid, watch, understand, show, minute, an...  \n",
       "12496  [pretty, much, tv, show, people, reason, worth...  \n",
       "12497  [try, lot, use, title, bring, small, surprise,...  \n",
       "12498  [thing, star, always, watch, feature, new, new...  \n",
       "12499  [well, write, almost, say, everything, feel, m...  \n",
       "\n",
       "[12500 rows x 5 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the preprocessor\n",
    "preprocessor = text_preprocessor()\n",
    "train_set_processed = preprocessor.preprocess_imdb_reviews(train_set, 0.9, 0.05)\n",
    "test_set_processed = preprocessor.preprocess_imdb_reviews(test_set, 0.9, 0.05)\n",
    "valid_set_processed = preprocessor.preprocess_imdb_reviews(valid_set, 0.9, 0.05)\n",
    "\n",
    "valid_set_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "      <th>label</th>\n",
       "      <th>processed</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's Bad for Ya really showcases more of Georg...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>it s bad for ya really showcases more of georg...</td>\n",
       "      <td>[bad, really, really, still, lose, year, comed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It might be a stretch saying this as a die-har...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>it might be a stretch saying this as a diehard...</td>\n",
       "      <td>[might, say, fan, write, bad, best, yet, back,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can't say I enjoyed this as much as \"The Big...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>i cannot say i enjoyed this as much as the big...</td>\n",
       "      <td>[say, enjoy, much, big, little, laugh, sense, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie was sooooooo good! It was hilarious...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>this movie was sooooooo good it was hilarious ...</td>\n",
       "      <td>[many, watch, john, love, guy, love, go, defin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jean Renoir's homage to the Paris of the late ...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>jean renoir s homage to the paris of the late ...</td>\n",
       "      <td>[late, beautiful, many, way, appear, end, men,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>I occasionally let my kids watch this garbage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>i occasionally let my kids watch this garbage ...</td>\n",
       "      <td>[let, kid, watch, understand, show, minute, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>When all we have anymore is pretty much realit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>when all we have anymore is pretty much realit...</td>\n",
       "      <td>[pretty, much, tv, show, people, reason, worth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>The basic genre is a thriller intercut with an...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>the basic genre is a thriller intercut with an...</td>\n",
       "      <td>[try, lot, use, title, bring, small, surprise,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>Four things intrigued me as to this film - fir...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>four things intrigued me as to this film  firs...</td>\n",
       "      <td>[thing, star, always, watch, feature, new, new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>David Bryce's comments nearby are exceptionall...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>david bryce s comments nearby are exceptionall...</td>\n",
       "      <td>[well, write, almost, say, everything, feel, m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rate  label  \\\n",
       "0      It's Bad for Ya really showcases more of Georg...    10      1   \n",
       "1      It might be a stretch saying this as a die-har...    10      1   \n",
       "2      I can't say I enjoyed this as much as \"The Big...     7      1   \n",
       "3      This movie was sooooooo good! It was hilarious...    10      1   \n",
       "4      Jean Renoir's homage to the Paris of the late ...     9      1   \n",
       "...                                                  ...   ...    ...   \n",
       "12495  I occasionally let my kids watch this garbage ...     1      0   \n",
       "12496  When all we have anymore is pretty much realit...     1      0   \n",
       "12497  The basic genre is a thriller intercut with an...     3      0   \n",
       "12498  Four things intrigued me as to this film - fir...     3      0   \n",
       "12499  David Bryce's comments nearby are exceptionall...     4      0   \n",
       "\n",
       "                                               processed  \\\n",
       "0      it s bad for ya really showcases more of georg...   \n",
       "1      it might be a stretch saying this as a diehard...   \n",
       "2      i cannot say i enjoyed this as much as the big...   \n",
       "3      this movie was sooooooo good it was hilarious ...   \n",
       "4      jean renoir s homage to the paris of the late ...   \n",
       "...                                                  ...   \n",
       "12495  i occasionally let my kids watch this garbage ...   \n",
       "12496  when all we have anymore is pretty much realit...   \n",
       "12497  the basic genre is a thriller intercut with an...   \n",
       "12498  four things intrigued me as to this film  firs...   \n",
       "12499  david bryce s comments nearby are exceptionall...   \n",
       "\n",
       "                                               tokenized  \n",
       "0      [bad, really, really, still, lose, year, comed...  \n",
       "1      [might, say, fan, write, bad, best, yet, back,...  \n",
       "2      [say, enjoy, much, big, little, laugh, sense, ...  \n",
       "3      [many, watch, john, love, guy, love, go, defin...  \n",
       "4      [late, beautiful, many, way, appear, end, men,...  \n",
       "...                                                  ...  \n",
       "12495  [let, kid, watch, understand, show, minute, an...  \n",
       "12496  [pretty, much, tv, show, people, reason, worth...  \n",
       "12497  [try, lot, use, title, bring, small, surprise,...  \n",
       "12498  [thing, star, always, watch, feature, new, new...  \n",
       "12499  [well, write, almost, say, everything, feel, m...  \n",
       "\n",
       "[12500 rows x 5 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the IDF values and VOCAB vector\n",
    "vectorizer = TfIdfVectorizer(train_set_processed)\n",
    "idfs = vectorizer.idfs\n",
    "vocab = vectorizer.vocab\n",
    "\n",
    "\n",
    "# Vectorizing train set and test set\n",
    "train_set_vectorized = vectorizer.tf_idf_vectorize_all(train_set_processed)\n",
    "\n",
    "test_set_vectorized = vectorizer.tf_idf_vectorize_all(test_set_processed)\n",
    "\n",
    "valid_set_vectorized = vectorizer.tf_idf_vectorize_all(valid_set_processed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up genetic algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Classifier\n",
    "There are a lot of classifiers. I haven't any experience in most of them, just a little familiar with Neural Network thus this is what I did choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, idfs, vocab):\n",
    "        self.idfs = idfs\n",
    "        self.vocab = vocab\n",
    "        self.ws_1 = 0\n",
    "        self.ws_2 = 0\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return (x > 0) * x \n",
    "\n",
    "    # Initializing weights\n",
    "    def init_weights(self, hidden_nodes):\n",
    "        self.ws_1 = np.random.rand(len(vocab), hidden_nodes) - 0.5\n",
    "        self.ws_2 = np.random.rand(hidden_nodes, 2) - 0.5\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        from scipy import special\n",
    "        return special.expit(x)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        import numpy as np\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum()\n",
    "\n",
    "    def cross_entropy(self, p, o):\n",
    "        import numpy as np\n",
    "        y = [0,0]\n",
    "        y[o] = 1\n",
    "        return -(sum(np.nan_to_num(y*np.log(p))))\n",
    "    \n",
    "    def predict_single_row(self, x, y, w_1, w_2):\n",
    "        #forward pass/prediction\n",
    "        layer_1 = self.relu(x.dot(w_1))\n",
    "        layer_out = self.softmax(layer_1.dot(w_2))\n",
    "        return layer_out\n",
    "    \n",
    "    def get_predicted_label(self, p):\n",
    "        return np.argmax(p)\n",
    "    \n",
    "    def predict_whole_set(self, df, ws_1, ws_2):\n",
    "        df['predictions'] = df.apply(lambda vec: self.predict_single_row(vec.vectors, vec.label, ws_1, ws_2), axis=1)\n",
    "        df['CE-loss'] = df.apply(lambda x: self.cross_entropy(x.predictions, x.label), axis=1)\n",
    "        df['predicted-vals'] = df.apply(lambda p: self.get_predicted_label(p.predictions), axis=1)\n",
    "        mean_loss = df['CE-loss'].mean()\n",
    "        return mean_loss, df\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifier\n",
    "classifier = Classifier(idfs, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run classifier\n",
    "classifier.init_weights(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_training_CEL, output_df = classifier.predict_whole_set(valid_set_vectorized, classifier.ws_1, classifier.ws_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8570765042031592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.50104"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pre_training_CEL)\n",
    "output_df\n",
    "\n",
    "pre_training_nr_of_correct = output_df[output_df['label'] == output_df['predicted-vals']].count().values[0]\n",
    "pre_training_accuracy = pre_training_nr_of_correct / len(output_df)\n",
    "\n",
    "pre_training_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Chromosome\n",
    "It's just some weights that'll be used for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Chromosome:\n",
    "    # x_pos and y_pos are the features of our chromosome\n",
    "    def __init__(self, ws_1, ws_2):\n",
    "        self._fitness = 0\n",
    "        self._ws_1 = ws_1\n",
    "        self._ws_2 = ws_2\n",
    "    \n",
    "    # Getters and setters\n",
    "    @property\n",
    "    def ws_1(self):\n",
    "        return self._ws_1\n",
    "    \n",
    "    @ws_1.setter\n",
    "    def ws_1(self, value):\n",
    "        self._ws_1 = value\n",
    "    \n",
    "    @property\n",
    "    def ws_2(self):\n",
    "        return self._ws_2\n",
    "    \n",
    "    @ws_2.setter\n",
    "    def ws_2(self, value):\n",
    "        self._ws_2 = value\n",
    "    \n",
    "    @property\n",
    "    def fitness(self):\n",
    "        return self._fitness\n",
    "    \n",
    "    @fitness.setter\n",
    "    def fitness(self, value):\n",
    "        self._fitness = value\n",
    "    \n",
    "    def assign_fitness(self, classifier, data_set):\n",
    "        import math\n",
    "        loss, _ = classifier.predict_whole_set(data_set, self.ws_1, self.ws_2)\n",
    "        self.fitness = 1/loss #0 if loss <= 0 or loss == float('inf') else -math.log(1 / loss)\n",
    "    \n",
    "    # produce a new offspring from 2 parents\n",
    "    def crossover(self, other):\n",
    "        r = 0\n",
    "        \n",
    "        min_mat_1 = np.minimum(self.ws_1, other.ws_1)\n",
    "        max_mat_1 = np.maximum(self.ws_1, other.ws_1)\n",
    "        min_mat_2 = np.minimum(self.ws_2, other.ws_2)\n",
    "        max_mat_2 = np.maximum(self.ws_2, other.ws_2)\n",
    "        \n",
    "        ws_1 = np.random.uniform(min_mat_1-r, max_mat_1+r)\n",
    "        ws_2 = np.random.uniform(min_mat_2-r, max_mat_2+r) \n",
    "        \n",
    "        offspring = Chromosome(ws_1, ws_2)\n",
    "        return offspring\n",
    "\n",
    "    # mutate the individual\n",
    "    def mutate(self):\n",
    "        np.random.shuffle(self.ws_1)\n",
    "        self.ws_1 = self.ws_1 + np.random.uniform(-1, 1, size=self.ws_1.shape)\n",
    "        np.random.shuffle(self.ws_2)\n",
    "        self.ws_2 = self.ws_2 + np.random.uniform(-1, 1, size=self.ws_2.shape)\n",
    "        return\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Genetic Algorithm Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GAEngine:\n",
    "    def __init__(self):\n",
    "        self._population = []\n",
    "        self._generations = 0\n",
    "\n",
    "    def make_initial_population(self, population_size):       \n",
    "        for i in range(population_size):\n",
    "            ws_1, ws_2 = self.init_weights()\n",
    "            self.population.append(Chromosome(ws_1, ws_2))\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def generations(self):\n",
    "        return self._generations\n",
    "    \n",
    "    @generations.setter\n",
    "    def generations(self, g):\n",
    "        self._generations = g\n",
    "    \n",
    "    @property\n",
    "    def population(self):\n",
    "        return self._population\n",
    "    \n",
    "    @population.setter\n",
    "    def population(self, p):\n",
    "        self._population = p\n",
    "    \n",
    "    \n",
    "    # Initializing weights\n",
    "    def init_weights(self):\n",
    "        hidden_nodes = 8\n",
    "        ws_1 = np.random.rand(len(vocab), hidden_nodes) - 0.5\n",
    "        ws_2 = np.random.rand(hidden_nodes, 2) - 0.5\n",
    "        return ws_1, ws_2\n",
    "    \n",
    "\n",
    "    # selection code goes here...\n",
    "    def do_crossover(self, no_of_offspring):\n",
    "        import random\n",
    "        population_size = len(self.population)\n",
    "        # Here we combine elitism selection with roulette wheel\n",
    "        # We carry ca 20 % of the most fit over to the next generation.\n",
    "        # Then we use roulette wheel because we want diversity too.\n",
    "        # We want diversity because it's hard to predict optimal weights\n",
    "        \n",
    "        # Get the top ca 20 % fittest.\n",
    "        rate_to_keep = 0.2\n",
    "        keep_nr = int(population_size * rate_to_keep)\n",
    "        self.population = sorted(self.population, key=lambda x: x.fitness)\n",
    "        new_generation = self.population[-keep_nr:]\n",
    "        \n",
    "        # new_generation = list()\n",
    "\n",
    "        # Then we make offsprings based on random choices with weights.\n",
    "        # We raise the exponent fitness to 2 to make the differences more\n",
    "        # Since we are using \"roulette wheel\" in selection, we want to increase the chance of\n",
    "        # the most fit to be selected.\n",
    "        fitness_values = [x.fitness**2 for x in self.population]\n",
    "        for i in range(no_of_offspring):\n",
    "            parent1, parent2 = random.choices(self.population, weights=fitness_values, k=2)\n",
    "            offspring = parent1.crossover(parent2)\n",
    "            new_generation.append(offspring)\n",
    "        \n",
    "        self.population = new_generation\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # fitness calculation goes here...\n",
    "    def assign_fitness(self, classifier, data_set):\n",
    "        # Fitness is 987 substracted by distance to closest food\n",
    "        # We want the chromosomes close to some food to survive, not close to all foods on average.\n",
    "        for ch in self.population:\n",
    "            ch.assign_fitness(classifier, data_set)\n",
    "        return\n",
    "    \n",
    "    def get_population(self):\n",
    "        return self.population\n",
    "    \n",
    "    def get_best_chromosome(self):\n",
    "        ch = max(self.population, key=lambda x: x.fitness)\n",
    "        return ch\n",
    "    \n",
    "    def training_routine(self, init_population, nr_of_generations, \n",
    "                        no_of_mutation, rate_of_crossover):\n",
    "        self.make_initial_population(init_population)\n",
    "        self.generations = nr_of_generations\n",
    "        \n",
    "        cels = list()\n",
    "\n",
    "\n",
    "        for i in range(self.generations):\n",
    "            self.assign_fitness(classifier, test_set_vectorized)\n",
    "            cels.append(self.get_best_chromosome().fitness)\n",
    "            # ca 60 % of population to do crossover\n",
    "            no_of_crossover = int(rate_of_crossover * len(self.population))\n",
    "            self.do_crossover(no_of_crossover)\n",
    "\n",
    "\n",
    "            # High number of mutations for more variations\n",
    "            for i in range(no_of_mutation):\n",
    "                index = random.randint(0, len(self.population)-1)\n",
    "                self.population[index].mutate()\n",
    "            \n",
    "            \n",
    "\n",
    "        # Assign fitness last time before getting the best chromosome\n",
    "        self.assign_fitness(classifier, test_set_vectorized)\n",
    "        cels.append(self.get_best_chromosome().fitness)\n",
    "        return self.get_best_chromosome(), cels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-176-2e7ae14316a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mga\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGAEngine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mga\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_routine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mcels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-175-e864a98650e8>\u001b[0m in \u001b[0;36mtraining_routine\u001b[1;34m(self, init_population, nr_of_generations, no_of_mutation, rate_of_crossover)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set_vectorized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m             \u001b[0mcels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_chromosome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;31m# ca 60 % of population to do crossover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-175-e864a98650e8>\u001b[0m in \u001b[0;36massign_fitness\u001b[1;34m(self, classifier, data_set)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;31m# We want the chromosomes close to some food to survive, not close to all foods on average.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0mch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-160-73cf5f1db71d>\u001b[0m in \u001b[0;36massign_fitness\u001b[1;34m(self, classifier, data_set)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0massign_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_whole_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mws_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mws_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;31m#0 if loss <= 0 or loss == float('inf') else -math.log(1 / loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-155-9a7ea9d1fe51>\u001b[0m in \u001b[0;36mpredict_whole_set\u001b[1;34m(self, df, ws_1, ws_2)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_whole_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_single_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CE-loss'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predicted-vals'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_predicted_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\01basics\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   7543\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7544\u001b[0m         )\n\u001b[1;32m-> 7545\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7547\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"DataFrame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\01basics\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\01basics\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\01basics\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    282\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m                     \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m                         \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-155-9a7ea9d1fe51>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(vec)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_whole_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_single_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CE-loss'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predicted-vals'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_predicted_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-155-9a7ea9d1fe51>\u001b[0m in \u001b[0;36mpredict_single_row\u001b[1;34m(self, x, y, w_1, w_2)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_single_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m#forward pass/prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mlayer_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mlayer_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Here I run the GA engine\n",
    "ga = GAEngine()\n",
    "gens = 20\n",
    "ch, cels = ga.training_routine(20, gens, 4, 0.6)\n",
    "cels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3722897413006347\n"
     ]
    }
   ],
   "source": [
    "print(ch.fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting increase of fitness in training\n",
    "x = np.linspace(0, gens+1, gens+1)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(x, cels, label='fitness')\n",
    "\n",
    "plt.xlabel(\"Generations\")\n",
    "plt.ylabel(\"fitness\")\n",
    "plt.title(\"Change of fitness (fitness = 1 / (mean CEL))\")\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_training_CEL, output_df = classifier.predict_whole_set(valid_set_vectorized, ch.ws_1, ch.ws_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before training:  0.50104\n",
      "Accuracy after training:  0.49408\n",
      "CEL before training 1.8570765042031592\n",
      "CEL after training 0.8130857609149558\n"
     ]
    }
   ],
   "source": [
    "post_training_nr_of_correct = output_df[output_df['label'] == output_df['predicted-vals']].count().values[0]\n",
    "post_training_accuracy = post_training_nr_of_correct / len(output_df)\n",
    "\n",
    "print(\"Accuracy before training: \", pre_training_accuracy)\n",
    "print(\"Accuracy after training: \", post_training_accuracy)\n",
    "print(\"CEL before training\", pre_training_CEL)\n",
    "print(\"CEL after training\", post_training_CEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "      <th>label</th>\n",
       "      <th>processed</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>vectors</th>\n",
       "      <th>predictions</th>\n",
       "      <th>CE-loss</th>\n",
       "      <th>predicted-vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's Bad for Ya really showcases more of Georg...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>it s bad for ya really showcases more of georg...</td>\n",
       "      <td>[bad, really, really, still, lose, year, comed...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.6883234202263518, 0.3116765797736481]</td>\n",
       "      <td>1.165789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It might be a stretch saying this as a die-har...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>it might be a stretch saying this as a diehard...</td>\n",
       "      <td>[might, say, fan, write, bad, best, yet, back,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.7646891977053918, 0.0, 0.0, ...</td>\n",
       "      <td>[0.7989135081921105, 0.2010864918078896]</td>\n",
       "      <td>1.604020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can't say I enjoyed this as much as \"The Big...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>i cannot say i enjoyed this as much as the big...</td>\n",
       "      <td>[say, enjoy, much, big, little, laugh, sense, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 3.5293783954107836, 0.0, 0.0, ...</td>\n",
       "      <td>[0.6893847238014845, 0.3106152761985155]</td>\n",
       "      <td>1.169200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie was sooooooo good! It was hilarious...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>this movie was sooooooo good it was hilarious ...</td>\n",
       "      <td>[many, watch, john, love, guy, love, go, defin...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.762...</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jean Renoir's homage to the Paris of the late ...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>jean renoir s homage to the paris of the late ...</td>\n",
       "      <td>[late, beautiful, many, way, appear, end, men,...</td>\n",
       "      <td>[2.76843304264985, 2.5352740571517867, 0.0, 1....</td>\n",
       "      <td>[0.6383392436011415, 0.36166075639885853]</td>\n",
       "      <td>1.017049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>I occasionally let my kids watch this garbage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>i occasionally let my kids watch this garbage ...</td>\n",
       "      <td>[let, kid, watch, understand, show, minute, an...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.3653119229023507, ...</td>\n",
       "      <td>[0.4162229157251895, 0.5837770842748106]</td>\n",
       "      <td>0.876534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>When all we have anymore is pretty much realit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>when all we have anymore is pretty much realit...</td>\n",
       "      <td>[pretty, much, tv, show, people, reason, worth...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.3807130696654118, 0.6192869303345883]</td>\n",
       "      <td>0.965709</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>The basic genre is a thriller intercut with an...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>the basic genre is a thriller intercut with an...</td>\n",
       "      <td>[try, lot, use, title, bring, small, surprise,...</td>\n",
       "      <td>[0.0, 0.0, 1.6259738810742, 0.0, 2.57072601023...</td>\n",
       "      <td>[0.5186512769674743, 0.48134872303252574]</td>\n",
       "      <td>0.656524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>Four things intrigued me as to this film - fir...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>four things intrigued me as to this film  firs...</td>\n",
       "      <td>[thing, star, always, watch, feature, new, new...</td>\n",
       "      <td>[0.0, 0.0, 1.6259738810742, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.5899794301410015, 0.41002056985899843]</td>\n",
       "      <td>0.527668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>David Bryce's comments nearby are exceptionall...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>david bryce s comments nearby are exceptionall...</td>\n",
       "      <td>[well, write, almost, say, everything, feel, m...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.3653119229023507, ...</td>\n",
       "      <td>[0.666493817953155, 0.33350618204684496]</td>\n",
       "      <td>0.405724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rate  label  \\\n",
       "0      It's Bad for Ya really showcases more of Georg...    10      1   \n",
       "1      It might be a stretch saying this as a die-har...    10      1   \n",
       "2      I can't say I enjoyed this as much as \"The Big...     7      1   \n",
       "3      This movie was sooooooo good! It was hilarious...    10      1   \n",
       "4      Jean Renoir's homage to the Paris of the late ...     9      1   \n",
       "...                                                  ...   ...    ...   \n",
       "12495  I occasionally let my kids watch this garbage ...     1      0   \n",
       "12496  When all we have anymore is pretty much realit...     1      0   \n",
       "12497  The basic genre is a thriller intercut with an...     3      0   \n",
       "12498  Four things intrigued me as to this film - fir...     3      0   \n",
       "12499  David Bryce's comments nearby are exceptionall...     4      0   \n",
       "\n",
       "                                               processed  \\\n",
       "0      it s bad for ya really showcases more of georg...   \n",
       "1      it might be a stretch saying this as a diehard...   \n",
       "2      i cannot say i enjoyed this as much as the big...   \n",
       "3      this movie was sooooooo good it was hilarious ...   \n",
       "4      jean renoir s homage to the paris of the late ...   \n",
       "...                                                  ...   \n",
       "12495  i occasionally let my kids watch this garbage ...   \n",
       "12496  when all we have anymore is pretty much realit...   \n",
       "12497  the basic genre is a thriller intercut with an...   \n",
       "12498  four things intrigued me as to this film  firs...   \n",
       "12499  david bryce s comments nearby are exceptionall...   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      [bad, really, really, still, lose, year, comed...   \n",
       "1      [might, say, fan, write, bad, best, yet, back,...   \n",
       "2      [say, enjoy, much, big, little, laugh, sense, ...   \n",
       "3      [many, watch, john, love, guy, love, go, defin...   \n",
       "4      [late, beautiful, many, way, appear, end, men,...   \n",
       "...                                                  ...   \n",
       "12495  [let, kid, watch, understand, show, minute, an...   \n",
       "12496  [pretty, much, tv, show, people, reason, worth...   \n",
       "12497  [try, lot, use, title, bring, small, surprise,...   \n",
       "12498  [thing, star, always, watch, feature, new, new...   \n",
       "12499  [well, write, almost, say, everything, feel, m...   \n",
       "\n",
       "                                                 vectors  \\\n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1      [0.0, 0.0, 0.0, 1.7646891977053918, 0.0, 0.0, ...   \n",
       "2      [0.0, 0.0, 0.0, 3.5293783954107836, 0.0, 0.0, ...   \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.762...   \n",
       "4      [2.76843304264985, 2.5352740571517867, 0.0, 1....   \n",
       "...                                                  ...   \n",
       "12495  [0.0, 0.0, 0.0, 0.0, 0.0, 2.3653119229023507, ...   \n",
       "12496  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "12497  [0.0, 0.0, 1.6259738810742, 0.0, 2.57072601023...   \n",
       "12498  [0.0, 0.0, 1.6259738810742, 0.0, 0.0, 0.0, 0.0...   \n",
       "12499  [0.0, 0.0, 0.0, 0.0, 0.0, 2.3653119229023507, ...   \n",
       "\n",
       "                                     predictions   CE-loss  predicted-vals  \n",
       "0       [0.6883234202263518, 0.3116765797736481]  1.165789               0  \n",
       "1       [0.7989135081921105, 0.2010864918078896]  1.604020               0  \n",
       "2       [0.6893847238014845, 0.3106152761985155]  1.169200               0  \n",
       "3                                     [0.5, 0.5]  0.693147               0  \n",
       "4      [0.6383392436011415, 0.36166075639885853]  1.017049               0  \n",
       "...                                          ...       ...             ...  \n",
       "12495   [0.4162229157251895, 0.5837770842748106]  0.876534               1  \n",
       "12496   [0.3807130696654118, 0.6192869303345883]  0.965709               1  \n",
       "12497  [0.5186512769674743, 0.48134872303252574]  0.656524               0  \n",
       "12498  [0.5899794301410015, 0.41002056985899843]  0.527668               0  \n",
       "12499   [0.666493817953155, 0.33350618204684496]  0.405724               0  \n",
       "\n",
       "[12500 rows x 9 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
