{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graded assignment 1 - text classification using Genetic Algorithms\n",
    "\n",
    "In this assignmetn we'll make a binary text classifier using genetic algorithms. We will classify movie reviews from IMDB as either negative or positive. \n",
    "\n",
    "The assignment text contain 3 steps, so I divided the assignment in 3 sections:\n",
    "\n",
    "1. Preprocessing of the text\n",
    "2. Genetich Algorithm\n",
    "3. Testing\n",
    "\n",
    "**Preprocessing text**\n",
    "\n",
    "First I upload all data, put them together and split them into training, validation and testing set. Then I preprocess the text using different methods like removing stop words, lemmaitzation etc.\n",
    "\n",
    "Training set will be used to build vocabulary and IDF values. Validation set will be used when assigning fitness in Genetic Algorithm which I'll get into more. Testing set will be used at the end in validation part.\n",
    "\n",
    "What we basically do here is to try to predict what class a text belongs to by making some calculations based on how many of which words the text containts. But when we do this calculation we don't want to consider all the words. That's because some words don't help with predictions. That's why we do preprocessing and turn all the reviews into equally sized vectors containing numerical values which can be proceeded by our neural network. How we do the preprocessing will be futher explained later.\n",
    "\n",
    "\n",
    "I have built two classes for preprocessing stage. One is TextPreprocessor which processes contents with methods like removing stop words, lemmatization etc.\n",
    "\n",
    "The other is TF-IDF vectorizer class which is used to build a Numpy array of TF-IDF vectors. Each document is turned into a TF-IDF vector. TF\n",
    "\n",
    "**Genetic Algorithm**\n",
    "Genetic algorithm  (often referred as GA) is an algorithm inspired by evolution theory. Here rather than species we have solutions to a problem. We call those solutions for Chromosomes. In this case Chromosomes are just weights for a neural network. We use methods like \"cross-over\" and \"mutation\" to make changes in those Chromosomes, and we try to pick the best Chromosome. In here the best Chromosome is \n",
    "\n",
    "The classifier I used is a simple neural network. I considered decision tree, but I'm not familiar with decision trees while I'm a bit familiar with neural network. Thus I decided to go with neural network. \n",
    "\n",
    "The neural net has only 2 hidden layers, 16 and 8 hidden nodes. I kept it simple because I had to take hardware limitations into account too. In the Genetic Algorithm every time we assign fitness we are going to predict the whole validation set for each classifier. So I didn't want to make it very slow.\n",
    "\n",
    "**Testing**\n",
    "Validation is simply using the optimizied weights to predict all reviews in the testing set to see how our GA performs. In the assignment text they suggested to use testing set for assigning fitness in GA and in validation part. But I thought that could make weights a bit biased. Thus other than training set I used two seperate sets: validation set and testing set. Validation set will be used when assigning fitness while optimizing weights in GA. Testing set will be used at the end.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing\n",
    "\n",
    "The preprocessing consists of two parts. Preproceesing the texts in the dataframe, and then converting the texts into vectors that can be used in classifier.\n",
    "\n",
    "I have built twp seperate classes for each one. TextPreprocessor class and TF-IDF vectorizer.\n",
    "\n",
    "I searched online about different vectorizartion methods in text classifying. I found TF-IDF vectorization contains more data than others, which could help in classifying. With TF-IDF vectors one can see which words are more \"special\" than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Uploading data\n",
    "\n",
    "All the data is placed in four seperate folders. I found PlainTextCorpusReader from nlkt.corpus to be more effective in reading multiple text files. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abdka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abdka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Upload the text\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from scipy import special\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used for loop iteration to extract the info as array. Then I made a dataframe where I put all the samples together.\n",
    "\n",
    "The data contains 3 columns (among index): reviews (the content of TXT files), labels (positive or negative, 1 or 0), and rates (extracted from file names).\n",
    "\n",
    "I haven't used rate values anywhere in the assignment. I planned to use them but didn't use them. But still I didn't remove them so the code can be further developed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File directories\n",
    "corpus_train_pos_root = 'aclImdb/train/pos/'\n",
    "corpus_train_neg_root = 'aclImdb/train/neg/'\n",
    "corpus_test_pos_root = 'aclImdb/test/pos/'\n",
    "corpus_test_neg_root = 'aclImdb/test/neg/'\n",
    "\n",
    "# Corpus file objects\n",
    "files_train_pos = PlaintextCorpusReader(corpus_train_pos_root, '.*')\n",
    "files_train_neg = PlaintextCorpusReader(corpus_train_neg_root, '.*')\n",
    "files_test_pos = PlaintextCorpusReader(corpus_test_pos_root, '.*')\n",
    "files_test_neg = PlaintextCorpusReader(corpus_test_neg_root, '.*')\n",
    "\n",
    "\n",
    "# Getting review texts, labels and rates all in arrays\n",
    "reviews_train_pos = [files_train_pos.open(n).read() for n in files_train_pos.fileids()]\n",
    "rates_train_pos = [int(re.split(\"_|\\.\", n)[-2]) for n in files_train_pos.fileids()]\n",
    "labels_train_pos = [1] * len(reviews_train_pos)\n",
    "\n",
    "reviews_train_neg = [files_train_neg.open(n).read() for n in files_train_neg.fileids()]\n",
    "rates_train_neg = [int(re.split(\"_|\\.\", n)[-2]) for n in files_train_neg.fileids()]\n",
    "labels_train_neg = [0] * len(reviews_train_neg)\n",
    "\n",
    "reviews_test_pos = [files_test_pos.open(n).read() for n in files_test_pos.fileids()]\n",
    "rates_test_pos = [int(re.split(\"_|\\.\", n)[-2]) for n in files_test_pos.fileids()]\n",
    "labels_test_pos = [1] * len(reviews_test_pos)\n",
    "\n",
    "reviews_test_neg = [files_test_neg.open(n).read() for n in files_test_neg.fileids()]\n",
    "rates_test_neg = [int(re.split(\"_|\\.\", n)[-2]) for n in files_test_neg.fileids()]\n",
    "labels_test_neg = [0] * len(reviews_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_set = pd.DataFrame()\n",
    "\n",
    "# Puttin all data into whole set\n",
    "whole_set['review'] = reviews_train_pos + reviews_test_pos + reviews_train_neg + reviews_test_neg\n",
    "whole_set['rate'] = rates_train_pos + rates_test_pos + rates_train_neg + rates_test_neg\n",
    "whole_set['label'] = labels_train_pos + labels_test_pos + labels_train_neg + labels_test_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Splitting data\n",
    "\n",
    "The original sample was like 50% was testing and 50% for training. That's too little for training and too big for testing. And there's no validation.\n",
    "\n",
    "Thus I made the split into three: \n",
    "* 70 % on training, \n",
    "* 15 % on testing\n",
    "* 15 % on validation.\n",
    "\n",
    "Splitting the data into three sets where training set is significantly bigger is common in machine learning.\n",
    "\n",
    "TF-IDF vectors will be based on training set. Thus we need training set to be in bigger size.\n",
    "\n",
    "Validation set will be used in Genetic Algorithm when assigning fitness to classifiers.\n",
    "Too big validation set could slow it the GA much.\n",
    "\n",
    "Testing set will be used at the end to test how much the \"trained classifier\" performs.\n",
    "\n",
    "Then I shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's a soap-opera drawing upon an applied ethi...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have to say this is better than most SyFy ou...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie is a waste of film stock. Do you be...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clark Gable plays a con man who busts into the...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I normally don't like romantic films, but I lo...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>The idea of In the Name of the People is good,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>The Outsiders is undoubtedly a classic Austral...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>Admittedly, I tuned into this in the hopes of ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>In the late 1940s there was a short film serie...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>I agree with other users comments in that the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rate  label\n",
       "0      It's a soap-opera drawing upon an applied ethi...     7      1\n",
       "1      I have to say this is better than most SyFy ou...     3      0\n",
       "2      This movie is a waste of film stock. Do you be...     1      0\n",
       "3      Clark Gable plays a con man who busts into the...     8      1\n",
       "4      I normally don't like romantic films, but I lo...    10      1\n",
       "...                                                  ...   ...    ...\n",
       "34995  The idea of In the Name of the People is good,...     2      0\n",
       "34996  The Outsiders is undoubtedly a classic Austral...     8      1\n",
       "34997  Admittedly, I tuned into this in the hopes of ...     3      0\n",
       "34998  In the late 1940s there was a short film serie...     9      1\n",
       "34999  I agree with other users comments in that the ...     2      0\n",
       "\n",
       "[35000 rows x 3 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Putting all into two Pandas dataframes - training set and testing set\n",
    "train_set = pd.DataFrame()\n",
    "test_set = pd.DataFrame()\n",
    "valid_set = pd.DataFrame()\n",
    "\n",
    "# Dividing reviews into negative and positive to make sure data is always balanced\n",
    "negatives = whole_set.loc[whole_set['label'] == 0]\n",
    "positives = whole_set.loc[whole_set['label'] == 1]\n",
    "\n",
    "# Splitting positive and negative reviews\n",
    "train_set, valid_set, test_set = np.split(positives, [int(0.7*len(positives)), int(0.85*len(positives))])\n",
    "tr_neg, vl_neg, ts_neg = np.split(negatives, [int(0.7*len(negatives)), int(0.85*len(negatives))])\n",
    "\n",
    "# Appending negatives to positives\n",
    "train_set = train_set.append(tr_neg)\n",
    "valid_set = valid_set.append(vl_neg)\n",
    "test_set = test_set.append(ts_neg)\n",
    "\n",
    "# Shuffle and reset the index\n",
    "train_set = train_set.sample(frac=1).reset_index(drop=True)\n",
    "valid_set = valid_set.sample(frac=1).reset_index(drop=True)\n",
    "test_set = test_set.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data exploration\n",
    "\n",
    "Here we explore how the data looks like. That is to figure out how to preprocess the data, what to eliminate etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common 20 counted by appearance in nr of reviews:  [('the', 34512), ('a', 33657), ('and', 33527), ('of', 33109), ('to', 32761), ('is', 31043), ('in', 30224), ('this', 29017), ('that', 27272), ('it', 26552), ('I', 25151), ('for', 24184), ('with', 23784), ('but', 22444), ('was', 22333), ('The', 21788), ('as', 21391), ('on', 20873), ('/><br', 20460), ('have', 19648)]\n",
      "\n",
      "Most common 20 counted by word count total:  [('the', 398431), ('a', 215543), ('and', 211791), ('of', 198887), ('to', 183609), ('is', 142852), ('in', 119064), ('I', 92383), ('that', 89328), ('this', 79871), ('it', 75658), ('/><br', 71081), ('was', 64813), ('as', 58564), ('with', 57992), ('for', 56780), ('The', 46966), ('but', 46488), ('on', 42896), ('movie', 42730)]\n"
     ]
    }
   ],
   "source": [
    "# Data exploration\n",
    "# Most common words\n",
    "\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "cnt2 = Counter()\n",
    "for text in train_set[\"review\"].values:\n",
    "    # Counting the words\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "    # Counting in how many reviews the word appears\n",
    "    for word in set(text.split()):\n",
    "        cnt2[word] += 1\n",
    "\n",
    "print(\"Most common 20 counted by appearance in nr of reviews: \", cnt2.most_common(20))\n",
    "print(\"\\nMost common 20 counted by word count total: \", cnt.most_common(20))\n",
    "\n",
    "# print(\"Least common 20 counted by appearance in nr of reviews: \", cnt2.most_common()[:-20])\n",
    "# print(\"\\nLeast common 20 counted by word count total: \", cnt.most_common()[:-20])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen there are a lot of stop words. There are HTML tags in the set too. The stop words and HTML tags will be removed in with TextPreprocessor class.\n",
    "\n",
    "Vocabulary here means all the words used in the training set. The vocabulary will be based on training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '% of documents')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What % of the reviews use what % of the vocab\n",
    "vocab_size = len(cnt2)\n",
    "sample_size = len(train_set)\n",
    "\n",
    "y = [c/sample_size * 100 for (w, c) in cnt2.most_common()]\n",
    "x = [c/vocab_size * 100 for c in range(1, vocab_size+1)]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x, y)\n",
    "ax.set_title(\"% of the words used in % of the documents\")\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel(\"% of vocabolary\")\n",
    "ax.set_ylabel(\"% of documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above shows how much % of the vocabulary is used by how much % of the documents.\n",
    "\n",
    "We see that only a tiny fraction of the vocubulary are used in most of the documents. \n",
    "Most of the words in vocabulary are rare words, also they're used only in a small fraction of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Length distribution of the reviews\n",
    "train_set['rev_lens_raw'] = train_set['review'].str.len()\n",
    "train_set['rev_lens_words'] = train_set['review'].str.split().apply(len)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "\n",
    "ax[0].hist(train_set['rev_lens_raw'], bins='auto')\n",
    "ax[0].set_xlabel(\"Review length in characters\")\n",
    "ax[0].set_ylabel(\"Frequency\")\n",
    "ax[1].hist(train_set['rev_lens_words'], bins='auto')\n",
    "ax[1].set_xlabel(\"Review length in words\")\n",
    "ax[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histograms above shows distribution of frequency and review length. The longest reviews are 1000 words which is not very unusual. \n",
    "\n",
    "We want to see if short reviews contain garbage, and see they look like normal movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I hope this group of film-makers never re-unites.',\n",
       "       'Brilliant and moving performances by Tom Courtenay and Peter Finch.',\n",
       "       'This movie is terrible but it has some good effects.',\n",
       "       \"I wouldn't rent this one even on dollar rental night.\",\n",
       "       \"You'd better choose Paul Verhoeven's even if you have watched it.\",\n",
       "       'Adrian Pasdar is excellent is this film. He makes a fascinating woman.',\n",
       "       'Ming The Merciless does a little Bardwork and a movie most foul!',\n",
       "       'Long, boring, blasphemous. Never have I been so glad to see ending credits roll.',\n",
       "       'This is a great movie. Too bad it is not available on home video.',\n",
       "       'Comment this movie is impossible. Is terrible, very improbable, bad interpretation e direction. Not look!!!!!'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shortest reviews\n",
    "train_set.nsmallest(10, 'rev_lens_words')['review'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop reviews that are very long\n",
    "#train_set = train_set.loc[train_set['rev_lens_word'] < 1800]\n",
    "#train_set.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Preprocessing and vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerocessing and vectorization serves same goal. What we want to do is to buid\n",
    "\n",
    "What we basically want to do here is to try to predict what class a text belongs to by making some calculations based on how many of which words in the vocabulary that particular text contains. \n",
    "\n",
    "So we want to build a vocabulary first, also a list of words. But we don't want to include absolutely all words used in the training set to be included in the vocabulary. Thus we make some preprocessing, some filtering etc. and that's where TextPreprocessor comes in.\n",
    "\n",
    "E.g. stopwords like \"the\", \"a\", \"and\" etc. don't say anything about whether the review is positive or negative. Thus in the preprocessing stage we eliminate them. We eliminate numbers and other words too that don't give meaning.\n",
    "\n",
    "Very common words, words that are used in almost all reviews, don't say much about if the review is negative or positive. So we eliminate most common words too. But very rare words also don't say much about \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 TextPreprocessor class\n",
    "\n",
    "Most of the functions are in this class are taken from a code posted on Canvas. I just put hem into a class, made some changes and built some additional functions.\n",
    "\n",
    "Preprocessing is done with a function in TextProcessor class named def `preprocess_imdb_reviews()` which uses other functions in the class. It processes all the text in a dataframe under column \"review\" and returns a dataframe with additional column named \"processed\" where all processed text are saved. I keep both of them to be able to repeat code and to make a comparison later.\n",
    "\n",
    "The functions are applied by using .apply() function of the dataframe, which apply a function to each row in a chosen column.\n",
    "\n",
    "As mentioned we don't want to include all words used in the training set to be included in the vocabulary. Thus we make some changes. Here is how we process the text:\n",
    "1. We make all lower cases. Some people use upper case to highlight their words, and first letter of words are in upper case after periods. All all those words mean the same thing, so we don't want to discriminate between those. The only problem here is that movie names and person names would be processed just like some words. E.g. the movie \"Cars\" would be interpreted as noun in plural form cars, and eventually be lemmatized into car or removed. But it's very difficult to write a code to determine what is movie / person name or not, and they don't say much about whether a movie review is positive or negative. Thus for now we just ignore this problem. Lower casing all words also makes other processing steps easier.\n",
    "2. We remove HTML tags. They are not words with meaning, just some clutter to be removed.\n",
    "5. We remove URLs. They are not words with meaning, so just remove them.\n",
    "3. We convert emoticons into text. We do this before removing numbers or anything else as emoticons may contain numbers too. We don't want to remove them as they may contain useful information about the review.\n",
    "4. We remove numbers. They can be dates, ages etc. which don't give much relevant info about the review.\n",
    "6. We expand contractions. Alos \"don't\" means same as \"do not\". So we don't want to distinguish between those. Expanding contractions also will make removing stop words easier. It's important to do it early as it will generate new stop words.\n",
    "7. We remove emojis\n",
    "8. We remove punctuations, like dots and slashes. In computers \"something\" and \"something,\" are perceived as two different words, we don't want that.\n",
    "9. We lemmatize words. Lemmatizing means converting words to base forms.E.g. \"boring\" and \"bored\" are same words, \"child\" and \"children\" are actually same word. We want the computer to perceive them as same words too. Words with same base should be considered as same word.\n",
    "10. We remove the stop words. Words like \"the\", \"a\", \"and\" may be used in all reviews and don't give any information about review. So we just remove them.\n",
    "11. Curbing. We remove the words that exists in more than 85 % of the documents. They are some common words that don't give much context. And we remove the words that exists in less than 0.05 % of the documents. Rare words are words like special movie names, actor names, weirdo words, misspesllings etc. Words that are used only here and there or only in one review can't be used in calculating which class a reviews belongs to. The rates 0.85 and 0.0005 are paramaters to the function. I experimented with different values, I don't want to end up with vocabulary that's too little, but nor too big. Most of the words in vocabulary are rare words that are used in tiny fraction of the set. Thus the bottom curb is just 0.0005. Too little vocabulary give too little information. Too big vocabulary is too heavy for the neural network, and may contain a lot of words that give little information. A vocabulary of 10k-20k is enough. After experiemting with different values I did choose 0.85 and 0.0005 as curbing values.\n",
    "12. At the end I found some garbage words still existing in the set. I made an array of those and removed those from all the reviews. The array is: [\"□\", \"▢\", \"■\", \"\\x96\", \"st\", \"nd\", \"rd\", \"th\"]. \\x96 is just some triangle. st, nd, rd and th are remainders of numerical values like 1st, 2dn, 3rd, 4th etc. which is meaningless.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I think to put this into own .PY file and import from there\n",
    "class TextPreprocessor():\n",
    "    def __init__(self):\n",
    "        import nltk\n",
    "        import re\n",
    "        import string\n",
    "        \n",
    "        nltk.download('stopwords')\n",
    "        nltk.download('wordnet')\n",
    "        from nltk.corpus import stopwords\n",
    "        \", \".join(stopwords.words('english'))\n",
    "        from nltk.stem.wordnet import WordNetLemmatizer \n",
    "        \n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        self.punctuation = string.punctuation\n",
    "        \n",
    "        self.emoji_pattern = re.compile(\"[\"\n",
    "                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                u\"\\U00002702-\\U000027B0\"\n",
    "                                u\"\\U000024C2-\\U0001F251\"\n",
    "                                \"]+\", flags=re.UNICODE)\n",
    "        \n",
    "        # src : https://github.com/NeelShah18/emot/blob/master/emot/emo_unicode.py\n",
    "        self.emoticons = {\n",
    "            u\":‑\\)\":\"Happy face or smiley\",\n",
    "            u\":\\)\":\"Happy face or smiley\",\n",
    "            u\":-\\]\":\"Happy face or smiley\",\n",
    "            u\":\\]\":\"Happy face or smiley\",\n",
    "            u\":-3\":\"Happy face smiley\",\n",
    "            u\":3\":\"Happy face smiley\",\n",
    "            u\":->\":\"Happy face smiley\",\n",
    "            u\":>\":\"Happy face smiley\",\n",
    "            u\"8-\\)\":\"Happy face smiley\",\n",
    "            u\":o\\)\":\"Happy face smiley\",\n",
    "            u\":-\\}\":\"Happy face smiley\",\n",
    "            u\":\\}\":\"Happy face smiley\",\n",
    "            u\":-\\)\":\"Happy face smiley\",\n",
    "            u\":c\\)\":\"Happy face smiley\",\n",
    "            u\":\\^\\)\":\"Happy face smiley\",\n",
    "            u\"=\\]\":\"Happy face smiley\",\n",
    "            u\"=\\)\":\"Happy face smiley\"\n",
    "        }\n",
    "        \n",
    "        self.url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "        self.html_pattern = re.compile('<.*?>')\n",
    "\n",
    "    def lower_case(self, text):\n",
    "        return str.lower(text)\n",
    "    \n",
    "    def remove_punctuation(self, text):\n",
    "        return text.translate(str.maketrans('', '', self.punctuation))\n",
    "    \n",
    "    def remove_stopwords(self, text):\n",
    "        return \" \".join([word for word in text.split() if word not in self.stop_words])\n",
    "    \n",
    "    def remove_words(self, text, freq_words):\n",
    "        return \" \".join([word for word in text.split() if word not in freq_words])\n",
    "    \n",
    "    def remove_emoji(self, text):\n",
    "        # src: https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "        return self.emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    \n",
    "    def remove_emoticons(self, text):\n",
    "        import re\n",
    "        # src : https://github.com/NeelShah18/emot/blob/master/emot/emo_unicode.py\n",
    "        emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in self.emoticons) + u')')\n",
    "        return emoticon_pattern.sub(r'', text)\n",
    "    \n",
    "    def convert_emoticons(self, text):\n",
    "        # src : https://github.com/NeelShah18/emot/blob/master/emot/emo_unicode.py\n",
    "        for emot in self.emoticons:\n",
    "            text = re.sub(u'('+emot+')', \"_\".join(self.emoticons[emot].replace(\",\",\"\").split()), text)\n",
    "        return text\n",
    "    \n",
    "    def lemmatization(self, text):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = word_tokenize(text)\n",
    "        for i in ['v','n','a']:\n",
    "            tokens = [lemmatizer.lemmatize(word, i) for word in tokens]\n",
    "        return \" \".join(tokens)\n",
    "    \n",
    "    def expand_contractions(self, text):\n",
    "        text = re.sub(r\"i'm\", \" i am \", text)\n",
    "        text = re.sub(r\" im \", \" i am \", text)\n",
    "        text = re.sub(r\"\\: p\", \"\", text)\n",
    "        text = re.sub(r\" ive \", \" i have \", text)\n",
    "        text = re.sub(r\" he's \", \" he is \", text)\n",
    "        text = re.sub(r\" she's \", \" she is \", text)\n",
    "        text = re.sub(r\" that's \", \" that is \", text)\n",
    "        text = re.sub(r\" what's \", \" what is \", text)\n",
    "        text = re.sub(r\" where's \", \" where is \", text)\n",
    "        text = re.sub(r\" haven't \", \" have not \", text)\n",
    "        text = re.sub(r\" ur \", \" you are \", text)\n",
    "        text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "        text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "        text = re.sub(r\"\\'re\", \" are\", text)\n",
    "        text = re.sub(r\"\\'d\", \" would\", text)\n",
    "        text = re.sub(r\" won't \", \" will not \", text)\n",
    "        text = re.sub(r\" wouldn't \", \" would not \", text)\n",
    "        text = re.sub(r\" can't \", \" cannot \", text)\n",
    "        text = re.sub(r\" couldn't \", \" could not \", text)\n",
    "        text = re.sub(r\" don't \", \" do not \", text)\n",
    "        text = re.sub(r\" didn't \", \" did not \", text)\n",
    "        text = re.sub(r\" doesn't \", \" does not \", text)\n",
    "        text = re.sub(r\" isn't \", \" is not \", text)\n",
    "        text = re.sub(r\" it's \", \" it is \", text)\n",
    "        text = re.sub(r\" who's \", \" who is \", text)\n",
    "        text = re.sub(r\" there's \", \" there is \", text)\n",
    "        text = re.sub(r\" weren't \", \" were not \", text)\n",
    "        text = re.sub(r\" wasn't \", \" was not \", text)\n",
    "        text = re.sub(r\" ok \", \" okay \", text)\n",
    "        text = re.sub(r\" you're \", \" you are \", text)\n",
    "        text = re.sub(r\" c'mon \", \" come on \", text)\n",
    "        text = re.sub(r\"\\'s\", \" s\", text)\n",
    "        return text\n",
    "    \n",
    "    def remove_numbers(self, text):\n",
    "        text = re.sub(r'[0-9]', '', text)\n",
    "        return text\n",
    "    \n",
    "    def remove_html_tags(self, text):\n",
    "        return self.html_pattern.sub(r'', text)\n",
    "    \n",
    "    def remove_urls(self, text):\n",
    "        return self.url_pattern.sub(r'', text)\n",
    "    \n",
    "    def process_text_vectorized(self, text):\n",
    "        text = self.lower_case(text)\n",
    "        text = self.remove_html_tags(text)\n",
    "        text = self.remove_numbers(text)\n",
    "        text = self.remove_urls(text)\n",
    "        text = self.expand_contractions(text)\n",
    "        text = self.remove_emoji(text)\n",
    "        text = self.remove_punctuation(text)\n",
    "        text = self.lemmatization(text)\n",
    "        text = self.remove_stopwords(text)\n",
    "        return text\n",
    "    \n",
    "    def preprocess_2(self, corpus, max_df, min_df, n_freq_words = 10, n_rare_words = 10):\n",
    "        \n",
    "        vecpreprop = np.vectorize(self.process_text_vectorized)\n",
    "        \n",
    "        arr1 = vecpreprop(corpus)\n",
    "        \n",
    "        from collections import Counter\n",
    "        cnt = Counter()\n",
    "        cnt2 = Counter()\n",
    "        for text in corpus:\n",
    "            # Counting the words\n",
    "            for word in text.split():\n",
    "                cnt[word] += 1\n",
    "            # Counting in how many reviews the word appears\n",
    "            for word in set(text.split()):\n",
    "                cnt2[word] += 1\n",
    "\n",
    "\n",
    "        # Removing most frequent words\n",
    "        freq_words = set([w for (w, wc) in cnt.most_common(n_freq_words)])\n",
    "        rem_freq_words = np.vectorize(self.remove_words)\n",
    "        arr2 = rem_freq_words(arr1, freq_words)\n",
    "\n",
    "        # Removing rarest words\n",
    "        rare_words = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
    "        \n",
    "        rem_rare_words = np.vectorize(self.remove_words)\n",
    "        arr3 = rem_rare_words(arr2, rare_words)\n",
    "\n",
    "        # Remove words used in >90% and <5% of the reviews\n",
    "        curb_max_amount = len(corpus) * max_df\n",
    "        curb_min_amount = len(corpus) * min_df\n",
    "\n",
    "        curb_words = set([w for (w, wc) in cnt2.most_common() if wc > curb_max_amount or wc < curb_min_amount])\n",
    "        print(len(cnt2))\n",
    "        print(len(curb_words))\n",
    "        rem_curb_words = np.vectorize(self.remove_words)\n",
    "        arr4 = rem_curb_words(arr3, curb_words)\n",
    "        \n",
    "        return arr4\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    # preprocessing IMDB reviews\n",
    "    def preprocess_imdb_reviews(self, df, max_df, min_df, n_freq_words = 10, n_rare_words = 10):\n",
    "        df['processed'] = df['review'].apply(lambda text: self.lower_case(text))\n",
    "        df['processed'] = df['processed'].apply(lambda text: self.remove_html_tags(text))\n",
    "        df['processed'] = df['processed'].apply(lambda text: self.remove_urls(text))\n",
    "        df['processed'] = df['processed'].apply(lambda text: self.convert_emoticons(text))\n",
    "        df['processed'] = df['processed'].apply(lambda text: self.remove_numbers(text))\n",
    "        df['processed'] = df['processed'].apply(lambda text: self.expand_contractions(text))\n",
    "        df['processed'] = df['processed'].apply(lambda text: self.remove_emoji(text))\n",
    "        df['processed'] = df['processed'].apply(lambda text: self.remove_punctuation(text))\n",
    "        df['processed'] = df['processed'].apply(lambda text: self.lemmatization(text))\n",
    "        df['processed'] = df['processed'].apply(lambda text: self.remove_stopwords(text))\n",
    "\n",
    "\n",
    "        from collections import Counter\n",
    "        cnt = Counter()\n",
    "        cnt2 = Counter()\n",
    "        for text in df['processed'].values:\n",
    "            # Counting the words\n",
    "#             for word in text.split():\n",
    "#                 cnt[word] += 1\n",
    "            # Counting in how many reviews the word appears\n",
    "            for word in set(text.split()):\n",
    "                cnt2[word] += 1\n",
    "\n",
    "\n",
    "        # Removing most frequent words\n",
    "#         freq_words = set([w for (w, wc) in cnt.most_common(n_freq_words)])\n",
    "        \n",
    "#         df['processed'] = df['processed'].apply(lambda text: self.remove_words(text, freq_words))\n",
    "\n",
    "#         # Removing rarest words\n",
    "#         rare_words = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
    "#         df['processed'] = df['processed'].apply(lambda text: self.remove_words(text, rare_words))\n",
    "\n",
    "        # Remove words used in >90% and <5% of the reviews\n",
    "        curb_max_amount = len(df) * max_df\n",
    "        curb_min_amount = len(df) * min_df\n",
    "        curb_words = set([w for (w, wc) in cnt2.most_common() if wc > curb_max_amount or wc < curb_min_amount])\n",
    "        df['processed'] = df['processed'].apply(lambda text: self.remove_words(text, curb_words))\n",
    "        \n",
    "        # Other words to remove\n",
    "        rem_words = [\"\\x96\", \"st\", \"nd\", \"rd\", \"th\"]\n",
    "        df['processed'] = df['processed'].apply(lambda text: self.remove_words(text, rem_words))\n",
    "\n",
    "        return df, cnt2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 TF IDF Vectorizer class\n",
    "\n",
    "TF-IDF stands for Term Frequency - Ineverse Document Frequency. TF is a number that shows frequency of term in the document, in this case in a particular reveiw. IDF is calculated by: $log(\\frac{n}{1+DF})$ where N is number of documents in the Corpus, (here we use trainin set as corpus) and DF is document frequency, also number of documents that term appears in. If DF is high, the that must be a more common term, and TF of that term in the document has less weight.\n",
    "\n",
    "TF-IDF values are ${TF \\times IDF}$ or ${TF \\times log(\\frac{n}{1 + DF})}$ It takes into account both how much a term appears, and how unique is that term for that review.\n",
    "\n",
    "There are different wasy to calculate TF-IDF values. I used this to avoud division by zero, as we add 1 in the divisor. In some websites they use 1 + n in the dividend to avoid negative values. But since we have removed all terms that apperas in more than 85 % of the documents, it's no term in the vocab appears in all documetns. So negative values of TF-IDF is not possible in this case.\n",
    "\n",
    "\n",
    "\n",
    "When initializing the TfIdfVectorizer class I pass in dataframe (the training set) as argument. Then using two functions (prepare_idfs and prepare_vocab) it builds two dictionaries and saves them.\n",
    "\n",
    "`self._vocab` is a dictionary where the keys are vocabulary taken from processed reviews in the training set. Also it's all the words used in the processed reviews in the training set. Values are used to determine which index TF-IDF values should be saved on. Each value in the `self._vocab` dictionary determines which index the TF-IDF value of a term in the review sohuld be be saved on.\n",
    "\n",
    "`self._idfs` is a dictionary that has same keys as `self._vocab`. But it will contain the IDF values of each term, where IDF's are based on the training set, also based on who many times that term appears in the training set.\n",
    "\n",
    "\n",
    "When we vectorize any text to put it into classification, we first preprocess it using functions in \"TextPreprocessor\", then we vectorize it using  `tf_idf_vectorize_all()`. That function accepts dataframe as argument. It will use .apply of the Pandas Dataframe and run `tf_idf_vectorize()` for each row in the 'processed'. Then we convert it to Numpy Array and return it.\n",
    "\n",
    "`tf_idf_vectorize_all()` will return a Numpy array that has an array for each review, where size of each array is equal to size of `self._vocab` or vocabulary, with TF-IDF values that saved in the indexes that represent the words in the vocab (what index for what word is determined by using `self._vocab` dictionary).\n",
    "\n",
    "\n",
    "\n",
    "Here's illustration with a small example:\n",
    "\n",
    "For simple illustration let's say our corpus is very small and vocabulary has just 3 words. Then the `self._vocab` would be like:\n",
    "{\"hello\": 0, \"world\": 1, \"python\": 2}.\n",
    "\n",
    "`self._idfs` would be something similar, just it will contain IDF values. E.g. based on their frequencies, document size etc. it could be something like:\n",
    "\n",
    "{\"hello\": 0, \"world\": 0, \"python\": 0.405}.\n",
    "\n",
    "Here we assume the set has 8 documents. \"hello\" and \"world\" appears in 2 documents and \"python\" appears in one. So their values will be as shown above.\n",
    "\n",
    "E.g. if the text is \"hello hello world in python\". We will ignore the word 'in' since it's not in the `self._vocab` dictionary.\n",
    "\n",
    "We see the word \"hello\" exists in the `self._vocab` and has value '0 and its IDF value is 0 in `self._idfs`. It appears two times.\n",
    "So we multiply 2 by 0, and save the value in index 0. The word \"world\" has the value '1' in the `self._vocab` dictionary, 0 in `self._idfs` dictionary, appears once in the document. So we multiply 1 by 0, and save the result in index 1. We repeat the same process for python. Then we return a Numpy array that looks like: [0, 0, 0.405]\n",
    "\n",
    "The `self._idfs` and `self._vocab` is used in the code to make the vector generation more efficient, as we don't have to generate vocabs and IDF values each time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TF-IDF VECTORIZER CLASS\n",
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from nltk import FreqDist\n",
    "\n",
    "class TfIdfVectorizer:\n",
    "    def __init__(self, df):\n",
    "        self._idfs = self.prepare_idfs(df)\n",
    "        self._vocab = self.prepare_vocab(df)\n",
    "    \n",
    "    @property\n",
    "    def idfs(self):\n",
    "        return self._idfs\n",
    "    \n",
    "    @idfs.setter\n",
    "    def idfs(self, idfs):\n",
    "        self._idfs = idfs\n",
    "    \n",
    "    @property\n",
    "    def vocab(self):\n",
    "        return self._vocab\n",
    "    \n",
    "    @vocab.setter\n",
    "    def vocab(self, vocab):\n",
    "        self._vocab = vocab\n",
    "    \n",
    "    # Prepare and return vocab out of corpus\n",
    "    def prepare_vocab(self, df):\n",
    "        # Prepare the vocab\n",
    "        self.vocab = set(\" \".join(df['processed'].values).split())\n",
    "        self.vocab = dict.fromkeys(self.vocab, 0)\n",
    "        self.vocab.update((k, i) for i, k in enumerate(self.vocab))\n",
    "        return self.vocab\n",
    "    \n",
    "    # Prepare and return idfs out of corpus\n",
    "    def prepare_idfs(self, df):\n",
    "        # Counting how many reviews a word appears ins\n",
    "        cnt = Counter()\n",
    "        for text in df[\"processed\"].values:\n",
    "            for word in set(text.split()):\n",
    "                cnt[word] += 1\n",
    "        # Preparing the IDF vector\n",
    "        size = len(df)\n",
    "        self.idfs = dict()\n",
    "        for w, c in cnt.items():\n",
    "            self.idfs[w] = math.log((1+size) / (1 + c))\n",
    "        return self.idfs\n",
    "\n",
    "\n",
    "    # TF-IDF vectorize a single text, returning an np.array\n",
    "    def tf_idf_vectorize(self, text):\n",
    "        freq_dist = FreqDist(text.split())\n",
    "        vector = np.zeros(len(self.vocab))\n",
    "        for w, c in freq_dist.items():\n",
    "            if w in self.vocab:\n",
    "                vector[self.vocab[w]] = c * self.idfs[w]\n",
    "        return vector\n",
    "\n",
    "\n",
    "    # One hot encode labels\n",
    "    def one_hot_encode(self, label, nr_of_labels):\n",
    "        arr = np.zeros(nr_of_labels, dtype=int)\n",
    "        arr[label] = 1\n",
    "        return arr\n",
    "\n",
    "    # Vectorize all in the dataset\n",
    "    def tf_idf_vectorize_all(self, df):\n",
    "        vectors = np.array(df['processed'].apply(lambda text: self.tf_idf_vectorize(text)).values.tolist())\n",
    "        return vectors\n",
    "    \n",
    "    # Turn all labels into one hot encoded arrays\n",
    "    def one_hot_encode_all(self, df, nr_of_labels):\n",
    "        vector = np.array(df['label'].apply(lambda label: self.one_hot_encode(label, nr_of_labels)).values.tolist())\n",
    "        return vector\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.4.3 Preprocessing\n",
    "\n",
    "Here we preprocess training set, testing set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abdka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abdka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "      <th>label</th>\n",
       "      <th>rev_lens_raw</th>\n",
       "      <th>rev_lens_words</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's a soap-opera drawing upon an applied ethi...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1279</td>\n",
       "      <td>235</td>\n",
       "      <td>draw upon apply ethic idea movie human suffer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have to say this is better than most SyFy ou...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>132</td>\n",
       "      <td>say good say muchthe plot someone buy game mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie is a waste of film stock. Do you be...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1758</td>\n",
       "      <td>327</td>\n",
       "      <td>movie waste film stock believe map plan milita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clark Gable plays a con man who busts into the...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1113</td>\n",
       "      <td>188</td>\n",
       "      <td>clark gable play con man bust life hardboiled ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I normally don't like romantic films, but I lo...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1313</td>\n",
       "      <td>234</td>\n",
       "      <td>normally like romantic film love film much sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>The idea of In the Name of the People is good,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>596</td>\n",
       "      <td>113</td>\n",
       "      <td>idea name people good murderer want daughter e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>The Outsiders is undoubtedly a classic Austral...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>646</td>\n",
       "      <td>110</td>\n",
       "      <td>outsider undoubtedly classic australian tv ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>Admittedly, I tuned into this in the hopes of ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2147</td>\n",
       "      <td>365</td>\n",
       "      <td>admittedly tune hop see beefcake shot jam brol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>In the late 1940s there was a short film serie...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4848</td>\n",
       "      <td>788</td>\n",
       "      <td>late short film series entitle flicker flashba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>I agree with other users comments in that the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>586</td>\n",
       "      <td>110</td>\n",
       "      <td>agree user comment two main role well act guy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rate  label  \\\n",
       "0      It's a soap-opera drawing upon an applied ethi...     7      1   \n",
       "1      I have to say this is better than most SyFy ou...     3      0   \n",
       "2      This movie is a waste of film stock. Do you be...     1      0   \n",
       "3      Clark Gable plays a con man who busts into the...     8      1   \n",
       "4      I normally don't like romantic films, but I lo...    10      1   \n",
       "...                                                  ...   ...    ...   \n",
       "34995  The idea of In the Name of the People is good,...     2      0   \n",
       "34996  The Outsiders is undoubtedly a classic Austral...     8      1   \n",
       "34997  Admittedly, I tuned into this in the hopes of ...     3      0   \n",
       "34998  In the late 1940s there was a short film serie...     9      1   \n",
       "34999  I agree with other users comments in that the ...     2      0   \n",
       "\n",
       "       rev_lens_raw  rev_lens_words  \\\n",
       "0              1279             235   \n",
       "1               700             132   \n",
       "2              1758             327   \n",
       "3              1113             188   \n",
       "4              1313             234   \n",
       "...             ...             ...   \n",
       "34995           596             113   \n",
       "34996           646             110   \n",
       "34997          2147             365   \n",
       "34998          4848             788   \n",
       "34999           586             110   \n",
       "\n",
       "                                               processed  \n",
       "0      draw upon apply ethic idea movie human suffer ...  \n",
       "1      say good say muchthe plot someone buy game mak...  \n",
       "2      movie waste film stock believe map plan milita...  \n",
       "3      clark gable play con man bust life hardboiled ...  \n",
       "4      normally like romantic film love film much sto...  \n",
       "...                                                  ...  \n",
       "34995  idea name people good murderer want daughter e...  \n",
       "34996  outsider undoubtedly classic australian tv ser...  \n",
       "34997  admittedly tune hop see beefcake shot jam brol...  \n",
       "34998  late short film series entitle flicker flashba...  \n",
       "34999  agree user comment two main role well act guy ...  \n",
       "\n",
       "[35000 rows x 6 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the preprocessor\n",
    "preprocessor = TextPreprocessor()\n",
    "train_set_processed, cnt1 = preprocessor.preprocess_imdb_reviews(train_set, 0.85, 0.0005)\n",
    "test_set_processed, cnt2 = preprocessor.preprocess_imdb_reviews(test_set, 0.85, 0.0005)\n",
    "valid_set_processed, cnt3 = preprocessor.preprocess_imdb_reviews(valid_set, 0.85, 0.0005)\n",
    "\n",
    "train_set_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.4 Checking preprocessed data\n",
    "\n",
    "Here we explore the preprocessed data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data exploration\n",
    "# Most common words\n",
    "\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "cnt2 = Counter()\n",
    "for text in train_set_processed[\"processed\"].values:\n",
    "    # Counting the words\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "    # Counting in how many reviews the word appears\n",
    "    for word in set(text.split()):\n",
    "        cnt2[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common 20 counted by appearance in nr of reviews:  [('movie', 22411), ('film', 20510), ('one', 19663), ('make', 17703), ('like', 16998), ('see', 16925), ('good', 16352), ('get', 14864), ('time', 13671), ('would', 13272), ('watch', 12599), ('go', 12362), ('even', 11706), ('think', 11388), ('character', 11383), ('story', 10745), ('really', 10538), ('bad', 10468), ('much', 9697), ('say', 9418), ('look', 9410), ('well', 9400), ('could', 9380), ('great', 9321), ('know', 9248), ('act', 9211), ('give', 9140), ('scene', 9043), ('end', 9029), ('also', 8730), ('take', 8725), ('way', 8668), ('come', 8666), ('people', 8580), ('first', 8553), ('thing', 8280), ('show', 8202), ('find', 8153), ('play', 7844), ('love', 7718), ('seem', 7207), ('want', 7086), ('many', 7018), ('plot', 7003), ('work', 6965), ('never', 6943), ('actor', 6839), ('try', 6680), ('two', 6660), ('best', 6658), ('little', 6628), ('year', 6609), ('ever', 6566), ('still', 6063), ('life', 5941), ('something', 5579), ('feel', 5481), ('part', 5396), ('interest', 5322), ('use', 5316), ('lot', 5304), ('man', 5277), ('back', 5272), ('old', 4977), ('real', 4960), ('director', 4948), ('cast', 4893), ('another', 4818), ('performance', 4783), ('leave', 4778), ('though', 4736), ('actually', 4717), ('nothing', 4676), ('funny', 4585), ('start', 4578), ('big', 4571), ('tell', 4554), ('every', 4546), ('write', 4515), ('point', 4454), ('long', 4423), ('star', 4403), ('new', 4393), ('turn', 4373), ('live', 4336), ('become', 4261), ('fact', 4228), ('role', 4224), ('young', 4196), ('set', 4195), ('guy', 4191), ('quite', 4133), ('woman', 4132), ('u', 4097), ('around', 4092), ('day', 4056), ('pretty', 4020), ('minute', 4008), ('happen', 3937), ('enough', 3919), ('mean', 3911), ('right', 3882), ('world', 3856), ('late', 3840), ('need', 3834), ('without', 3822), ('however', 3818), ('saw', 3814), ('keep', 3811), ('must', 3768), ('bite', 3759), ('put', 3759), ('enjoy', 3749), ('least', 3725), ('may', 3704), ('line', 3690), ('script', 3677), ('always', 3658), ('fan', 3653), ('last', 3645), ('almost', 3635), ('begin', 3626), ('girl', 3620), ('whole', 3617), ('believe', 3611), ('anything', 3532), ('lead', 3485), ('friend', 3475), ('far', 3441), ('kill', 3420), ('kind', 3406), ('reason', 3397), ('might', 3394), ('place', 3387), ('since', 3354), ('comedy', 3329), ('probably', 3327), ('action', 3302), ('away', 3243), ('music', 3237), ('anyone', 3213), ('shoot', 3212), ('let', 3201), ('sure', 3194), ('call', 3189), ('laugh', 3183), ('original', 3141), ('run', 3137), ('effect', 3130), ('hard', 3128), ('help', 3116), ('yet', 3103), ('rather', 3094), ('name', 3075), ('especially', 3029), ('moment', 3021), ('read', 2995), ('family', 2973), ('course', 2969), ('expect', 2938), ('worth', 2931), ('idea', 2919), ('screen', 2909), ('recommend', 2886), ('tv', 2880), ('fun', 2868), ('bring', 2853), ('horror', 2853), ('although', 2848), ('audience', 2836), ('bore', 2829), ('kid', 2806), ('everything', 2795), ('move', 2790), ('high', 2772), ('job', 2770), ('sense', 2769), ('someone', 2752), ('main', 2678), ('different', 2675), ('maybe', 2661), ('true', 2655), ('everyone', 2651), ('direct', 2651), ('dvd', 2644), ('together', 2617), ('early', 2605), ('waste', 2604), ('mind', 2586), ('money', 2584), ('lose', 2583), ('understand', 2576), ('second', 2569), ('hear', 2568), ('instead', 2560), ('problem', 2559), ('fall', 2549), ('follow', 2527), ('series', 2518), ('sound', 2500), ('child', 2500), ('else', 2489), ('miss', 2484), ('view', 2468), ('beautiful', 2464), ('special', 2451), ('surprise', 2434), ('le', 2433), ('face', 2432), ('excellent', 2423), ('night', 2416), ('three', 2416), ('american', 2404), ('hour', 2390), ('include', 2366), ('classic', 2360), ('talk', 2349), ('remember', 2335), ('piece', 2334), ('open', 2322), ('viewer', 2306), ('appear', 2303), ('simply', 2291), ('short', 2288), ('rest', 2283), ('completely', 2282), ('change', 2268), ('attempt', 2260), ('head', 2260), ('nice', 2251), ('entertain', 2250), ('along', 2240), ('suppose', 2239), ('involve', 2229), ('poor', 2222), ('eye', 2214), ('couple', 2213), ('add', 2193), ('death', 2184), ('word', 2182), ('care', 2177), ('either', 2175), ('lack', 2169), ('book', 2162), ('meet', 2139), ('production', 2133), ('die', 2129), ('decide', 2126), ('truly', 2125), ('hand', 2123), ('home', 2114), ('wrong', 2111), ('version', 2110), ('picture', 2109), ('release', 2107), ('boy', 2104), ('john', 2102), ('wonder', 2097), ('feature', 2093), ('close', 2088), ('full', 2086), ('next', 2083), ('small', 2067), ('save', 2067), ('half', 2050), ('wife', 2022), ('camera', 2021), ('hollywood', 2017), ('top', 1992), ('fight', 1988), ('sit', 1983), ('sort', 1973), ('black', 1969), ('title', 1969), ('definitely', 1965), ('low', 1957), ('case', 1951), ('wonderful', 1946), ('consider', 1945), ('create', 1940), ('perhaps', 1940), ('dialogue', 1939), ('base', 1936), ('others', 1933), ('guess', 1931), ('person', 1929), ('absolutely', 1924), ('house', 1910), ('human', 1897), ('stupid', 1892), ('review', 1883), ('awful', 1883), ('dead', 1882), ('men', 1876), ('fine', 1872), ('comment', 1865), ('often', 1863), ('father', 1861), ('mention', 1860), ('perfect', 1859), ('light', 1854), ('video', 1845), ('experience', 1840), ('example', 1832), ('stand', 1827), ('certainly', 1824), ('terrible', 1821), ('episode', 1818), ('flick', 1809), ('style', 1807), ('stop', 1799), ('budget', 1794), ('entire', 1790), ('rat', 1786), ('war', 1782), ('felt', 1781), ('quality', 1779), ('hope', 1776), ('direction', 1774), ('spend', 1765), ('amaze', 1764), ('force', 1762), ('ask', 1757), ('buy', 1755), ('school', 1754), ('fail', 1744), ('finally', 1737), ('several', 1733), ('disappoint', 1731), ('age', 1729), ('song', 1718), ('matter', 1717), ('deal', 1716), ('hold', 1716), ('break', 1716), ('actress', 1712), ('writer', 1707), ('sequence', 1699), ('cinema', 1684), ('already', 1678), ('learn', 1674), ('throughout', 1673), ('favorite', 1672), ('support', 1663), ('forget', 1663), ('dark', 1655), ('drama', 1654), ('sex', 1645), ('hit', 1644), ('wait', 1637), ('joke', 1635), ('side', 1630), ('yes', 1618), ('final', 1617), ('cut', 1616), ('able', 1613), ('totally', 1608), ('manage', 1603), ('murder', 1591), ('throw', 1584), ('wish', 1578), ('speak', 1577), ('mother', 1574), ('pay', 1565), ('touch', 1561), ('portray', 1560), ('stay', 1560), ('realize', 1555), ('walk', 1549), ('despite', 1547), ('deserve', 1535), ('type', 1533), ('art', 1533), ('unfortunately', 1532), ('brother', 1531), ('credit', 1529), ('rent', 1520), ('heart', 1517), ('oh', 1516), ('win', 1513), ('mr', 1505), ('past', 1494), ('twist', 1490), ('present', 1489), ('history', 1486), ('humor', 1482), ('relationship', 1481), ('score', 1480), ('strong', 1479), ('white', 1477), ('catch', 1472), ('complete', 1471), ('chance', 1468), ('behind', 1460), ('today', 1458), ('talent', 1456), ('overall', 1456), ('stuff', 1456), ('obviously', 1455), ('genre', 1447), ('evil', 1433), ('except', 1420), ('annoy', 1414), ('car', 1414), ('order', 1406), ('theme', 1405), ('highly', 1404), ('horrible', 1402), ('situation', 1396), ('number', 1388), ('question', 1387), ('sometimes', 1384), ('strange', 1383), ('soon', 1380), ('grow', 1379), ('son', 1376), ('please', 1374), ('decent', 1374), ('figure', 1372), ('level', 1370), ('group', 1369), ('brilliant', 1356), ('event', 1355), ('element', 1349), ('hero', 1344), ('voice', 1343), ('slow', 1337), ('extremely', 1325), ('killer', 1317), ('return', 1312), ('power', 1309), ('simple', 1309), ('pick', 1308), ('cinematography', 1305), ('body', 1304), ('obvious', 1301), ('particularly', 1292), ('cause', 1292), ('result', 1291), ('ago', 1289), ('edit', 1286), ('build', 1284), ('pace', 1283), ('opinion', 1283), ('effort', 1276), ('offer', 1276), ('none', 1264), ('etc', 1257), ('deliver', 1256), ('exactly', 1256), ('serious', 1253), ('career', 1252), ('sad', 1251), ('city', 1250), ('state', 1247), ('explain', 1244), ('value', 1242), ('across', 1239), ('daughter', 1235), ('town', 1234), ('okay', 1233), ('god', 1232), ('possible', 1232), ('usually', 1230), ('compare', 1230), ('convince', 1229), ('allow', 1224), ('drive', 1221), ('alone', 1218), ('check', 1211), ('huge', 1208), ('stick', 1205), ('somewhat', 1201), ('blood', 1200), ('cool', 1196), ('theater', 1194), ('michael', 1194), ('pull', 1193), ('hell', 1190), ('country', 1189), ('robert', 1189), ('hilarious', 1188), ('female', 1184), ('provide', 1183), ('ridiculous', 1181), ('mostly', 1180), ('easy', 1179), ('note', 1178), ('seriously', 1173), ('prove', 1172), ('usual', 1166), ('whose', 1166), ('attention', 1164), ('reality', 1161), ('focus', 1160), ('single', 1156), ('violence', 1156), ('beyond', 1151), ('game', 1148), ('pas', 1146), ('avoid', 1146), ('anyway', 1145), ('due', 1141), ('draw', 1140), ('imagine', 1139), ('important', 1138), ('cheap', 1136), ('silly', 1135), ('basically', 1132), ('happy', 1131), ('arent', 1129), ('dialog', 1127), ('hop', 1127), ('shock', 1125), ('filmmaker', 1124), ('major', 1124), ('produce', 1119), ('crap', 1118), ('local', 1113), ('form', 1107), ('apparently', 1106), ('doubt', 1105), ('lady', 1104), ('charm', 1100), ('subject', 1098), ('room', 1095), ('clearly', 1094), ('shot', 1093), ('dream', 1092), ('dance', 1092), ('jam', 1091), ('cover', 1088), ('scary', 1087), ('remind', 1085), ('easily', 1085), ('steal', 1084), ('upon', 1081), ('detail', 1081), ('husband', 1081), ('remain', 1079), ('deep', 1076), ('sister', 1075), ('clear', 1073), ('fit', 1073), ('fill', 1073), ('thank', 1072), ('near', 1070), ('plan', 1067), ('discover', 1066), ('police', 1063), ('aspect', 1058), ('whether', 1057), ('similar', 1056), ('weak', 1056), ('agree', 1047), ('producer', 1044), ('member', 1044), ('carry', 1043), ('entertainment', 1042), ('capture', 1034), ('develop', 1034), ('within', 1031), ('enjoyable', 1029), ('english', 1028), ('middle', 1025), ('message', 1022), ('marry', 1020), ('david', 1019), ('nearly', 1017), ('predictable', 1017), ('modern', 1016), ('novel', 1016), ('certain', 1015), ('sing', 1014), ('tale', 1013), ('choose', 1010), ('escape', 1006), ('confuse', 1005), ('storyline', 1002), ('ten', 1002), ('soundtrack', 1001), ('bunch', 999), ('among', 997), ('date', 995), ('image', 995), ('future', 993), ('wear', 992), ('gore', 991), ('finish', 988), ('send', 985), ('fast', 978), ('parent', 978), ('hate', 975), ('sequel', 975), ('street', 975), ('five', 974), ('musical', 973), ('class', 973), ('standard', 971), ('four', 971), ('continue', 963), ('describe', 962), ('typical', 961), ('television', 961), ('dull', 956), ('romantic', 955), ('comic', 954), ('air', 954), ('mark', 953), ('sorry', 950), ('actual', 947), ('material', 946), ('contain', 945), ('emotion', 938), ('somehow', 937), ('thriller', 936), ('mess', 935), ('fantastic', 933), ('excite', 933), ('admit', 932), ('premise', 931), ('adult', 931), ('particular', 930), ('straight', 929), ('general', 928), ('rock', 928), ('famous', 927), ('suffer', 925), ('period', 924), ('appreciate', 919), ('mystery', 917), ('monster', 913), ('trouble', 912), ('documentary', 910), ('hide', 907), ('notice', 906), ('background', 906), ('cry', 904), ('oscar', 903), ('cop', 902), ('team', 901), ('treat', 900), ('copy', 898), ('possibly', 898), ('gun', 896), ('mix', 893), ('list', 892), ('realistic', 891), ('crime', 891), ('appeal', 890), ('bother', 890), ('reveal', 889), ('large', 889), ('fire', 888), ('spoiler', 888), ('bear', 885), ('eventually', 883), ('difficult', 883), ('believable', 881), ('lame', 878), ('earth', 877), ('masterpiece', 876), ('victim', 873), ('whatever', 873), ('villain', 871), ('blow', 870), ('beat', 867), ('issue', 864), ('george', 863), ('romance', 860), ('choice', 859), ('otherwise', 858), ('mistake', 858), ('chase', 858), ('attack', 857), ('suggest', 857), ('british', 856), ('hat', 853), ('average', 852), ('poorly', 848), ('unless', 845), ('third', 845), ('truth', 844), ('atmosphere', 843), ('forward', 843), ('screenplay', 839), ('suck', 839), ('indeed', 836), ('memorable', 836), ('free', 834), ('emotional', 831), ('america', 831), ('box', 829), ('dog', 828), ('suspense', 826), ('peter', 825), ('battle', 824), ('superb', 822), ('warn', 820), ('student', 819), ('male', 819), ('struggle', 814), ('cheesy', 813), ('space', 812), ('total', 812), ('personal', 812), ('previous', 809), ('imdb', 807), ('towards', 806), ('fear', 804), ('quickly', 803), ('front', 802), ('development', 802), ('incredibly', 801), ('weird', 800), ('beauty', 800), ('b', 800), ('amount', 798), ('king', 797), ('train', 797), ('french', 797), ('perfectly', 796), ('richard', 796), ('paul', 796), ('nature', 795), ('respect', 794), ('costume', 794), ('unique', 794), ('shame', 793), ('hot', 787), ('york', 786), ('crazy', 786), ('flaw', 786), ('remake', 785), ('eat', 783), ('season', 782), ('rich', 781), ('drug', 780), ('society', 780), ('secret', 777), ('lie', 774), ('inside', 772), ('promise', 772), ('fly', 772), ('project', 770), ('concern', 769), ('amuse', 769), ('party', 768), ('dumb', 767), ('plain', 766), ('control', 764), ('sexual', 764), ('scream', 762), ('plus', 762), ('girlfriend', 762), ('water', 762), ('tear', 761), ('week', 759), ('recently', 758), ('various', 758), ('badly', 757), ('accent', 757), ('term', 757), ('drink', 756), ('apart', 754), ('hardly', 753), ('ok', 753), ('jump', 753), ('fairly', 752), ('powerful', 751), ('lover', 751), ('dramatic', 750), ('award', 749), ('plenty', 747), ('location', 744), ('pure', 742), ('business', 742), ('jack', 740), ('bill', 739), ('serve', 737), ('portrayal', 737), ('success', 736), ('color', 736), ('track', 734), ('studio', 733), ('share', 732), ('roll', 731), ('adventure', 726), ('talented', 725), ('exist', 722), ('listen', 720), ('potential', 720), ('stage', 717), ('baby', 717), ('slightly', 715), ('flat', 715), ('western', 714), ('spirit', 713), ('unlike', 713), ('disturb', 713), ('cute', 712), ('outside', 712), ('store', 711), ('design', 708), ('land', 708), ('company', 707), ('concept', 706), ('answer', 706), ('appearance', 705), ('creepy', 704), ('red', 700), ('introduce', 699), ('tom', 698), ('perform', 696), ('clever', 695), ('rise', 695), ('dress', 694), ('animation', 691), ('reach', 689), ('fantasy', 689), ('sleep', 689), ('doctor', 689), ('footage', 685), ('crew', 685), ('memory', 685), ('ability', 684), ('taste', 684), ('claim', 683), ('odd', 683), ('depth', 682), ('destroy', 681), ('intrigue', 681), ('sweet', 681), ('neither', 680), ('entirely', 679), ('public', 678), ('accept', 678), ('incredible', 677), ('scifi', 676), ('kick', 676), ('ruin', 675), ('spot', 674), ('era', 674), ('record', 674), ('channel', 671), ('la', 670), ('popular', 670), ('tension', 668), ('nudity', 668), ('brain', 668), ('sadly', 668), ('language', 666), ('familiar', 666), ('visual', 666), ('positive', 665), ('inspire', 665), ('rate', 664), ('sell', 664), ('purpose', 662), ('receive', 662), ('master', 662), ('approach', 661), ('scar', 661), ('intelligent', 659), ('suddenly', 659), ('william', 655), ('political', 651), ('engage', 651), ('impress', 650), ('basic', 650), ('hang', 648), ('player', 648), ('recent', 647), ('successful', 647), ('drag', 647), ('maker', 645), ('de', 644), ('animal', 643), ('tone', 642), ('stun', 642), ('dr', 642), ('search', 642), ('common', 640), ('handle', 640), ('century', 640), ('extra', 638), ('step', 637), ('strike', 634), ('fake', 634), ('soldier', 632), ('ultimately', 632), ('intend', 632), ('wood', 631), ('barely', 630), ('excuse', 629), ('former', 629), ('trip', 629), ('relate', 628), ('solid', 628), ('social', 625), ('conclusion', 625), ('million', 623), ('hole', 623), ('hair', 619), ('soul', 617), ('somewhere', 617), ('door', 617), ('impossible', 616), ('reviewer', 616), ('trash', 614), ('mood', 614), ('travel', 612), ('suit', 612), ('lee', 611), ('difference', 610), ('fascinate', 610), ('raise', 609), ('cold', 608), ('fair', 607), ('match', 606), ('sick', 605), ('hurt', 605), ('pop', 603), ('literally', 603), ('suspect', 602), ('limit', 601), ('glad', 601), ('genius', 601), ('pointless', 601), ('sign', 600), ('honest', 600), ('impressive', 599), ('pathetic', 598), ('burn', 597), ('violent', 597), ('culture', 596), ('wind', 596), ('repeat', 596), ('clothe', 596), ('tire', 595), ('display', 594), ('compel', 594), ('effective', 593), ('visit', 593), ('cartoon', 593), ('immediately', 593), ('count', 592), ('seek', 592), ('drop', 591), ('teen', 591), ('dont', 590), ('office', 588), ('awesome', 588), ('critic', 587), ('survive', 585), ('redeem', 585), ('opportunity', 584), ('chemistry', 584), ('personality', 583), ('exception', 583), ('surprisingly', 581), ('ring', 580), ('bizarre', 579), ('cost', 578), ('haunt', 577), ('nobody', 575), ('alive', 575), ('wild', 575), ('aside', 574), ('blue', 573), ('paint', 572), ('adaptation', 571), ('expectation', 570), ('study', 569), ('personally', 568), ('beautifully', 568), ('impression', 568), ('subtle', 568), ('smile', 568), ('park', 567), ('normal', 567), ('desire', 566), ('band', 566), ('folk', 565), ('likely', 565), ('fashion', 565), ('cat', 564), ('cinematic', 564), ('edge', 564), ('rare', 563), ('utterly', 563), ('bar', 563), ('honestly', 561), ('regard', 560), ('smart', 560), ('yeah', 560), ('creature', 558), ('ride', 558), ('gem', 558), ('sexy', 558)]\n",
      "\n",
      "Most common 20 counted by word count total:  [('movie', 69535), ('film', 64702), ('one', 36942), ('make', 30977), ('like', 30232), ('see', 28413), ('good', 27829), ('get', 24913), ('would', 21692), ('time', 20819)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(\"Most common 50 counted by appearance in nr of reviews: \", cnt1.most_common(50))\n",
    "\n",
    "vocab_size = len(cnt2)\n",
    "sample_size = len(train_set)\n",
    "\n",
    "x = [c/sample_size * 100 for (w, c) in cnt2.most_common()]\n",
    "y = [c/vocab_size * 100 for c in range(1, vocab_size+1)]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x, y)\n",
    "ax.set_title(\"% of the words used in % of the documents\")\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel(\"% of vocabolary\")\n",
    "ax.set_ylabel(\"% of documents\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above we see that after preprocessing the distribution of vocabulary in the documents are more smooth.\n",
    "\n",
    "Below we see some random samples to check if the data is garbage or not. And we see it looks OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "      <th>label</th>\n",
       "      <th>rev_lens_raw</th>\n",
       "      <th>rev_lens_words</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11423</th>\n",
       "      <td>The funniest show ever on TV, albeit the humor...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3791</td>\n",
       "      <td>661</td>\n",
       "      <td>funny show ever tv albeit humor everyone reali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>Every now and again you hear radio djs invitin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1479</td>\n",
       "      <td>251</td>\n",
       "      <td>every hear radio dj invite listener nominate m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7342</th>\n",
       "      <td>I love the music of the Clash and I love the m...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1642</td>\n",
       "      <td>302</td>\n",
       "      <td>love music clash love music joe go movie hop l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24544</th>\n",
       "      <td>\"The Planet\" is an astounding piece of film ma...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1842</td>\n",
       "      <td>322</td>\n",
       "      <td>planet astound piece film make mere £ producti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20923</th>\n",
       "      <td>I saw this movie in 1959 when I was 11 years o...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1196</td>\n",
       "      <td>215</td>\n",
       "      <td>saw movie year old drivein theater back think ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34315</th>\n",
       "      <td>I would not consider myself as one of Leonard ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>344</td>\n",
       "      <td>would consider one leonard cohen great fan how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21382</th>\n",
       "      <td>I knew full well when I rented this DVD that i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1037</td>\n",
       "      <td>185</td>\n",
       "      <td>know full well rent dvd could well one bad mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32484</th>\n",
       "      <td>I had heard this film was a study of a landsca...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2891</td>\n",
       "      <td>484</td>\n",
       "      <td>hear film study landscape photographer art pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10381</th>\n",
       "      <td>I would give this a zero if they had that rati...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>789</td>\n",
       "      <td>153</td>\n",
       "      <td>would give zero rat fun fun grow tire movie te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25122</th>\n",
       "      <td>A patchwork about 911. The 11 stories from 11 ...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1008</td>\n",
       "      <td>160</td>\n",
       "      <td>story director country sometimes sometimes bor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rate  label  \\\n",
       "11423  The funniest show ever on TV, albeit the humor...    10      1   \n",
       "2927   Every now and again you hear radio djs invitin...     1      0   \n",
       "7342   I love the music of the Clash and I love the m...     3      0   \n",
       "24544  \"The Planet\" is an astounding piece of film ma...     7      1   \n",
       "20923  I saw this movie in 1959 when I was 11 years o...    10      1   \n",
       "34315  I would not consider myself as one of Leonard ...     2      0   \n",
       "21382  I knew full well when I rented this DVD that i...     1      0   \n",
       "32484  I had heard this film was a study of a landsca...    10      1   \n",
       "10381  I would give this a zero if they had that rati...     1      0   \n",
       "25122  A patchwork about 911. The 11 stories from 11 ...     9      1   \n",
       "\n",
       "       rev_lens_raw  rev_lens_words  \\\n",
       "11423          3791             661   \n",
       "2927           1479             251   \n",
       "7342           1642             302   \n",
       "24544          1842             322   \n",
       "20923          1196             215   \n",
       "34315          1990             344   \n",
       "21382          1037             185   \n",
       "32484          2891             484   \n",
       "10381           789             153   \n",
       "25122          1008             160   \n",
       "\n",
       "                                               processed  \n",
       "11423  funny show ever tv albeit humor everyone reali...  \n",
       "2927   every hear radio dj invite listener nominate m...  \n",
       "7342   love music clash love music joe go movie hop l...  \n",
       "24544  planet astound piece film make mere £ producti...  \n",
       "20923  saw movie year old drivein theater back think ...  \n",
       "34315  would consider one leonard cohen great fan how...  \n",
       "21382  know full well rent dvd could well one bad mov...  \n",
       "32484  hear film study landscape photographer art pre...  \n",
       "10381  would give zero rat fun fun grow tire movie te...  \n",
       "25122  story director country sometimes sometimes bor...  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_processed.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.5 Vectorizing data sets using TF-IDF vectors\n",
    "\n",
    "Here we instantiate TfIdfVector useing processed train set. We save the idfs and vocab in a variable for easier reference.\n",
    "\n",
    "Then we generate Numpy arrays. X_train contains vectors representing reviews, Y_train contains labels in a numpy array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the IDF values and VOCAB vector\n",
    "vectorizer = TfIdfVectorizer(train_set_processed)\n",
    "idfs = vectorizer.idfs\n",
    "vocab = vectorizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing train set and test set\n",
    "X_train = vectorizer.tf_idf_vectorize_all(train_set_processed)\n",
    "\n",
    "X_test = vectorizer.tf_idf_vectorize_all(test_set_processed)\n",
    "\n",
    "X_valid = vectorizer.tf_idf_vectorize_all(valid_set_processed)\n",
    "\n",
    "Y_train = train_set_processed['label'].to_numpy()\n",
    "\n",
    "Y_test = test_set_processed['label'].to_numpy()\n",
    "\n",
    "Y_valid = valid_set_processed['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check if labels fit. We print the vocab to see which words are included in the vocab. While it contains a couple of weird words, most of them looks OK. We see the length of vocab is ca 12k which is big enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "12050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vomit': 0,\n",
       " 'hippie': 1,\n",
       " 'min': 2,\n",
       " 'skateboard': 3,\n",
       " 'anita': 4,\n",
       " 'consent': 5,\n",
       " 'biological': 6,\n",
       " 'fake': 7,\n",
       " 'gielgud': 8,\n",
       " 'booth': 9,\n",
       " 'spacey': 10,\n",
       " 'versatile': 11,\n",
       " 'assistance': 12,\n",
       " 'heart': 13,\n",
       " 'subtly': 14,\n",
       " 'illustrate': 15,\n",
       " 'dir': 16,\n",
       " 'journey': 17,\n",
       " 'infinitely': 18,\n",
       " 'himthe': 19,\n",
       " 'newman': 20,\n",
       " 'pause': 21,\n",
       " 'custer': 22,\n",
       " 'establishment': 23,\n",
       " 'yacht': 24,\n",
       " 'inherit': 25,\n",
       " 'doom': 26,\n",
       " 'lowbrow': 27,\n",
       " 'reservoir': 28,\n",
       " 'fonda': 29,\n",
       " 'loosen': 30,\n",
       " 'suspension': 31,\n",
       " 'korean': 32,\n",
       " 'previous': 33,\n",
       " 'great': 34,\n",
       " 'thug': 35,\n",
       " 'chunk': 36,\n",
       " 'intestine': 37,\n",
       " 'evade': 38,\n",
       " 'snake': 39,\n",
       " 'burr': 40,\n",
       " 'quite': 41,\n",
       " 'poke': 42,\n",
       " 'undemanding': 43,\n",
       " 'template': 44,\n",
       " 'since': 45,\n",
       " 'plea': 46,\n",
       " 'attitude': 47,\n",
       " 'radha': 48,\n",
       " 'stomach': 49,\n",
       " 'slop': 50,\n",
       " 'maniac': 51,\n",
       " 'due': 52,\n",
       " 'detroit': 53,\n",
       " 'ogle': 54,\n",
       " 'margin': 55,\n",
       " 'ambitious': 56,\n",
       " 'impale': 57,\n",
       " 'town': 58,\n",
       " 'imo': 59,\n",
       " 'stereotypical': 60,\n",
       " 'magic': 61,\n",
       " 'moviegoing': 62,\n",
       " 'boost': 63,\n",
       " 'syrupy': 64,\n",
       " 'barrymore': 65,\n",
       " 'vcr': 66,\n",
       " 'briefly': 67,\n",
       " 'ad': 68,\n",
       " 'billy': 69,\n",
       " 'shea': 70,\n",
       " 'sombre': 71,\n",
       " 'topless': 72,\n",
       " 'diverse': 73,\n",
       " 'collette': 74,\n",
       " 'crack': 75,\n",
       " 'infamous': 76,\n",
       " 'opus': 77,\n",
       " 'kansa': 78,\n",
       " 'asshole': 79,\n",
       " 'inflict': 80,\n",
       " 'rom': 81,\n",
       " 'fanatical': 82,\n",
       " 'disgust': 83,\n",
       " 'crumble': 84,\n",
       " 'inch': 85,\n",
       " 'pacific': 86,\n",
       " 'maudlin': 87,\n",
       " 'hairstyle': 88,\n",
       " 'device': 89,\n",
       " 'soprano': 90,\n",
       " 'exception': 91,\n",
       " 'obligate': 92,\n",
       " 'wolf': 93,\n",
       " 'nonstop': 94,\n",
       " 'eighty': 95,\n",
       " 'unexpected': 96,\n",
       " 'perpetual': 97,\n",
       " 'politically': 98,\n",
       " 'spread': 99,\n",
       " 'book': 100,\n",
       " 'jones': 101,\n",
       " 'undeveloped': 102,\n",
       " 'mold': 103,\n",
       " 'mostly': 104,\n",
       " 'worldthe': 105,\n",
       " 'eventually': 106,\n",
       " 'horribly': 107,\n",
       " 'tho': 108,\n",
       " 'whale': 109,\n",
       " 'criminal': 110,\n",
       " 'wideeyed': 111,\n",
       " 'unfamiliar': 112,\n",
       " 'elton': 113,\n",
       " 'champ': 114,\n",
       " 'resemble': 115,\n",
       " 'bobby': 116,\n",
       " 'treat': 117,\n",
       " 'pond': 118,\n",
       " 'los': 119,\n",
       " 'mythic': 120,\n",
       " 'project': 121,\n",
       " 'blackmail': 122,\n",
       " 'illustrious': 123,\n",
       " 'hogan': 124,\n",
       " 'whip': 125,\n",
       " 'ho': 126,\n",
       " 'deceit': 127,\n",
       " 'reputation': 128,\n",
       " 'christensen': 129,\n",
       " 'lucid': 130,\n",
       " 'reuse': 131,\n",
       " 'colony': 132,\n",
       " 'groovy': 133,\n",
       " 'heaven': 134,\n",
       " 'operate': 135,\n",
       " 'tot': 136,\n",
       " 'housewife': 137,\n",
       " 'reduce': 138,\n",
       " 'itbut': 139,\n",
       " 'calibre': 140,\n",
       " 'prompt': 141,\n",
       " 'twentysomething': 142,\n",
       " 'detail': 143,\n",
       " 'hobgoblin': 144,\n",
       " 'versatility': 145,\n",
       " 'gorilla': 146,\n",
       " 'spout': 147,\n",
       " 'examine': 148,\n",
       " 'shirt': 149,\n",
       " 'massive': 150,\n",
       " 'foreign': 151,\n",
       " 'sparkle': 152,\n",
       " 'pino': 153,\n",
       " 'kickass': 154,\n",
       " 'decrepit': 155,\n",
       " 'claus': 156,\n",
       " 'improve': 157,\n",
       " 'behindthescenes': 158,\n",
       " 'difference': 159,\n",
       " 'eddy': 160,\n",
       " 'glass': 161,\n",
       " 'forgiveness': 162,\n",
       " 'hopefully': 163,\n",
       " 'droll': 164,\n",
       " 'hawke': 165,\n",
       " 'goofy': 166,\n",
       " 'novel': 167,\n",
       " 'competent': 168,\n",
       " 'fiend': 169,\n",
       " 'competitor': 170,\n",
       " 'infant': 171,\n",
       " 'skin': 172,\n",
       " 'cushing': 173,\n",
       " 'accomplish': 174,\n",
       " 'poppins': 175,\n",
       " 'olivier': 176,\n",
       " 'end': 177,\n",
       " 'sideline': 178,\n",
       " 'sadden': 179,\n",
       " 'freakish': 180,\n",
       " 'vu': 181,\n",
       " 'solve': 182,\n",
       " 'complex': 183,\n",
       " 'boorish': 184,\n",
       " 'ransom': 185,\n",
       " 'sleepy': 186,\n",
       " 'tourdeforce': 187,\n",
       " 'impressively': 188,\n",
       " 'chad': 189,\n",
       " 'perish': 190,\n",
       " '½': 191,\n",
       " 'concert': 192,\n",
       " 'suitably': 193,\n",
       " 'impersonator': 194,\n",
       " 'consult': 195,\n",
       " 'sondra': 196,\n",
       " 'enforcement': 197,\n",
       " 'picnic': 198,\n",
       " 'archetype': 199,\n",
       " 'repetitive': 200,\n",
       " 'humility': 201,\n",
       " 'pancake': 202,\n",
       " 'ceiling': 203,\n",
       " 'surreal': 204,\n",
       " 'loretta': 205,\n",
       " 'ralph': 206,\n",
       " 'rejoice': 207,\n",
       " 'astaire': 208,\n",
       " 'visit': 209,\n",
       " 'pesky': 210,\n",
       " 'edgar': 211,\n",
       " 'seize': 212,\n",
       " 'payne': 213,\n",
       " 'frederic': 214,\n",
       " 'lavish': 215,\n",
       " 'grinch': 216,\n",
       " 'actress': 217,\n",
       " 'rea': 218,\n",
       " 'farther': 219,\n",
       " 'disappointment': 220,\n",
       " 'hairdo': 221,\n",
       " 'crane': 222,\n",
       " 'pessimistic': 223,\n",
       " 'advertise': 224,\n",
       " 'informative': 225,\n",
       " 'irresponsible': 226,\n",
       " 'tyler': 227,\n",
       " 'implausibility': 228,\n",
       " 'bernsen': 229,\n",
       " 'grasshopper': 230,\n",
       " 'upgrade': 231,\n",
       " 'fathom': 232,\n",
       " 'scooby': 233,\n",
       " 'rightfully': 234,\n",
       " 'jury': 235,\n",
       " 'longtime': 236,\n",
       " 'setback': 237,\n",
       " 'slit': 238,\n",
       " 'breathtaking': 239,\n",
       " 'lash': 240,\n",
       " 'rightly': 241,\n",
       " 'libido': 242,\n",
       " 'disc': 243,\n",
       " 'lowe': 244,\n",
       " 'englund': 245,\n",
       " 'friction': 246,\n",
       " 'fraternity': 247,\n",
       " 'gesture': 248,\n",
       " 'technically': 249,\n",
       " 'stevenson': 250,\n",
       " 'west': 251,\n",
       " 'eccleston': 252,\n",
       " 'digitally': 253,\n",
       " 'ruin': 254,\n",
       " 'big': 255,\n",
       " 'archer': 256,\n",
       " 'ang': 257,\n",
       " 'foe': 258,\n",
       " 'etcthe': 259,\n",
       " 'poetic': 260,\n",
       " 'increase': 261,\n",
       " 'bound': 262,\n",
       " 'omen': 263,\n",
       " 'uneasy': 264,\n",
       " 'minor': 265,\n",
       " 'stepsister': 266,\n",
       " 'todd': 267,\n",
       " 'importantly': 268,\n",
       " 'fearful': 269,\n",
       " 'courage': 270,\n",
       " 'cliché': 271,\n",
       " 'hammerhead': 272,\n",
       " 'scriptwriter': 273,\n",
       " 'politely': 274,\n",
       " 'dramatize': 275,\n",
       " 'honestly': 276,\n",
       " 'motivate': 277,\n",
       " 'replete': 278,\n",
       " 'literary': 279,\n",
       " 'tribulation': 280,\n",
       " 'secure': 281,\n",
       " 'repression': 282,\n",
       " 'descent': 283,\n",
       " 'controversy': 284,\n",
       " 'swat': 285,\n",
       " 'fish': 286,\n",
       " 'lunatic': 287,\n",
       " 'sorority': 288,\n",
       " 'selection': 289,\n",
       " 'rhetoric': 290,\n",
       " 'behalf': 291,\n",
       " 'belgium': 292,\n",
       " 'hai': 293,\n",
       " 'forensic': 294,\n",
       " 'recorder': 295,\n",
       " 'solely': 296,\n",
       " 'bitch': 297,\n",
       " 'absurdity': 298,\n",
       " 'cheer': 299,\n",
       " 'mystical': 300,\n",
       " 'compassion': 301,\n",
       " 'fleet': 302,\n",
       " 'marshall': 303,\n",
       " 'figure': 304,\n",
       " 'montage': 305,\n",
       " 'easily': 306,\n",
       " 'flesh': 307,\n",
       " 'champagne': 308,\n",
       " 'choreography': 309,\n",
       " 'secondary': 310,\n",
       " 'medical': 311,\n",
       " 'unfulfilled': 312,\n",
       " 'toddler': 313,\n",
       " 'askey': 314,\n",
       " 'outlet': 315,\n",
       " 'downtown': 316,\n",
       " 'youthe': 317,\n",
       " 'march': 318,\n",
       " 'skeleton': 319,\n",
       " 'confess': 320,\n",
       " 'arrangement': 321,\n",
       " 'sam': 322,\n",
       " 'kelly': 323,\n",
       " 'feelgood': 324,\n",
       " 'standouts': 325,\n",
       " 'smuggle': 326,\n",
       " 'dawson': 327,\n",
       " 'attorney': 328,\n",
       " 'unhealthy': 329,\n",
       " 'fundamental': 330,\n",
       " 'culkin': 331,\n",
       " 'bonnie': 332,\n",
       " 'heel': 333,\n",
       " 'month': 334,\n",
       " 'nowhere': 335,\n",
       " 'stall': 336,\n",
       " 'special': 337,\n",
       " 'hate': 338,\n",
       " 'cringeworthy': 339,\n",
       " 'peg': 340,\n",
       " 'slat': 341,\n",
       " 'paint': 342,\n",
       " 'helm': 343,\n",
       " 'enamor': 344,\n",
       " 'goodi': 345,\n",
       " 'happily': 346,\n",
       " 'feminism': 347,\n",
       " 'patterson': 348,\n",
       " 'scrawny': 349,\n",
       " 'stun': 350,\n",
       " 'maggot': 351,\n",
       " 'hbo': 352,\n",
       " 'soderbergh': 353,\n",
       " 'hellraiser': 354,\n",
       " 'super': 355,\n",
       " 'gossett': 356,\n",
       " 'proposal': 357,\n",
       " 'crapfest': 358,\n",
       " 'natasha': 359,\n",
       " 'lex': 360,\n",
       " 'bikers': 361,\n",
       " 'carbon': 362,\n",
       " 'boringly': 363,\n",
       " 'lens': 364,\n",
       " 'overshadow': 365,\n",
       " 'dandy': 366,\n",
       " 'maverick': 367,\n",
       " 'majesty': 368,\n",
       " 'ohara': 369,\n",
       " 'command': 370,\n",
       " 'carroll': 371,\n",
       " 'jude': 372,\n",
       " 'hybrid': 373,\n",
       " 'star': 374,\n",
       " 'patrick': 375,\n",
       " 'quo': 376,\n",
       " 'latter': 377,\n",
       " 'emergence': 378,\n",
       " 'martino': 379,\n",
       " 'cover': 380,\n",
       " 'underwhelming': 381,\n",
       " 'ryan': 382,\n",
       " 'bythenumbers': 383,\n",
       " 'coarse': 384,\n",
       " 'amiable': 385,\n",
       " 'classy': 386,\n",
       " 'wrench': 387,\n",
       " 'acid': 388,\n",
       " 'connery': 389,\n",
       " 'pope': 390,\n",
       " 'susannah': 391,\n",
       " 'privy': 392,\n",
       " 'bradford': 393,\n",
       " 'seemingly': 394,\n",
       " 'lillian': 395,\n",
       " 'makeshift': 396,\n",
       " 'article': 397,\n",
       " 'franchise': 398,\n",
       " 'sweaty': 399,\n",
       " 'ramon': 400,\n",
       " 'overpower': 401,\n",
       " 'roeg': 402,\n",
       " 'package': 403,\n",
       " 'inherent': 404,\n",
       " 'oscarnominated': 405,\n",
       " 'screenthe': 406,\n",
       " 'song': 407,\n",
       " 'visionary': 408,\n",
       " 'flood': 409,\n",
       " 'flashy': 410,\n",
       " 'issue': 411,\n",
       " 'reaction': 412,\n",
       " 'bodily': 413,\n",
       " 'sensitively': 414,\n",
       " 'considerable': 415,\n",
       " 'smarmy': 416,\n",
       " 'artfully': 417,\n",
       " 'walmart': 418,\n",
       " 'valerie': 419,\n",
       " 'second': 420,\n",
       " 'paresh': 421,\n",
       " 'mug': 422,\n",
       " 'troop': 423,\n",
       " 'doris': 424,\n",
       " 'earl': 425,\n",
       " 'success': 426,\n",
       " 'convent': 427,\n",
       " 'chuck': 428,\n",
       " 'hacker': 429,\n",
       " 'disintegrate': 430,\n",
       " 'te': 431,\n",
       " 'seriousness': 432,\n",
       " 'concentrate': 433,\n",
       " 'groan': 434,\n",
       " 'pleasure': 435,\n",
       " 'devos': 436,\n",
       " 'shag': 437,\n",
       " 'culminate': 438,\n",
       " 'deft': 439,\n",
       " 'outthe': 440,\n",
       " 'belt': 441,\n",
       " 'kingsley': 442,\n",
       " 'chow': 443,\n",
       " 'rerun': 444,\n",
       " 'anthem': 445,\n",
       " 'antique': 446,\n",
       " 'fritz': 447,\n",
       " 'china': 448,\n",
       " 'se': 449,\n",
       " 'alexis': 450,\n",
       " 'drip': 451,\n",
       " 'muni': 452,\n",
       " 'mario': 453,\n",
       " 'afterwards': 454,\n",
       " 'knight': 455,\n",
       " 'squander': 456,\n",
       " 'sierra': 457,\n",
       " 'renew': 458,\n",
       " 'wwf': 459,\n",
       " 'femme': 460,\n",
       " 'mistreat': 461,\n",
       " 'fanciful': 462,\n",
       " 'pm': 463,\n",
       " 'dub': 464,\n",
       " 'tit': 465,\n",
       " 'spray': 466,\n",
       " 'casey': 467,\n",
       " 'nefarious': 468,\n",
       " 'inside': 469,\n",
       " 'generic': 470,\n",
       " 'paulie': 471,\n",
       " 'independence': 472,\n",
       " 'curtiz': 473,\n",
       " 'surprisingly': 474,\n",
       " 'existent': 475,\n",
       " 'pas': 476,\n",
       " 'cannibalism': 477,\n",
       " 'exactly': 478,\n",
       " 'etc': 479,\n",
       " 'lugosi': 480,\n",
       " 'wildly': 481,\n",
       " 'laundry': 482,\n",
       " 'hamill': 483,\n",
       " 'unthinkable': 484,\n",
       " 'filma': 485,\n",
       " 'fictionalize': 486,\n",
       " 'tara': 487,\n",
       " 'qa': 488,\n",
       " 'avid': 489,\n",
       " 'filmmy': 490,\n",
       " 'mcclure': 491,\n",
       " 'empathise': 492,\n",
       " 'chick': 493,\n",
       " 'ninth': 494,\n",
       " 'indulgent': 495,\n",
       " 'stockwell': 496,\n",
       " 'inspire': 497,\n",
       " 'indeed': 498,\n",
       " 'quaid': 499,\n",
       " 'harris': 500,\n",
       " 'tvseries': 501,\n",
       " 'gunga': 502,\n",
       " 'xmen': 503,\n",
       " 'bitterness': 504,\n",
       " 'offthewall': 505,\n",
       " 'elegant': 506,\n",
       " 'squarely': 507,\n",
       " 'whimper': 508,\n",
       " 'ghastly': 509,\n",
       " 'nicky': 510,\n",
       " 'utterly': 511,\n",
       " 'outlaw': 512,\n",
       " 'champion': 513,\n",
       " 'rich': 514,\n",
       " 'adventurous': 515,\n",
       " 'cease': 516,\n",
       " 'kudos': 517,\n",
       " 'animate': 518,\n",
       " 'delightful': 519,\n",
       " 'prague': 520,\n",
       " 'offensive': 521,\n",
       " 'cocky': 522,\n",
       " 'mismatch': 523,\n",
       " 'perfection': 524,\n",
       " 'elisha': 525,\n",
       " 'regal': 526,\n",
       " 'meld': 527,\n",
       " 'reel': 528,\n",
       " 'rite': 529,\n",
       " 'hardwicke': 530,\n",
       " 'resonance': 531,\n",
       " 'nugget': 532,\n",
       " 'normally': 533,\n",
       " 'societal': 534,\n",
       " 'roommate': 535,\n",
       " 'vulgar': 536,\n",
       " 'bike': 537,\n",
       " 'lotr': 538,\n",
       " 'humorless': 539,\n",
       " 'typically': 540,\n",
       " 'dedication': 541,\n",
       " 'reality': 542,\n",
       " 'brosnan': 543,\n",
       " 'gage': 544,\n",
       " 'war': 545,\n",
       " 'hindi': 546,\n",
       " 'excruciate': 547,\n",
       " 'opposite': 548,\n",
       " 'olympic': 549,\n",
       " 'office': 550,\n",
       " 'orleans': 551,\n",
       " 'wash': 552,\n",
       " 'cycle': 553,\n",
       " 'existenz': 554,\n",
       " 'seclude': 555,\n",
       " 'interracial': 556,\n",
       " 'neville': 557,\n",
       " 'clumsily': 558,\n",
       " 'joy': 559,\n",
       " 'badly': 560,\n",
       " 'gratuitous': 561,\n",
       " 'bucket': 562,\n",
       " 'aside': 563,\n",
       " 'prank': 564,\n",
       " 'willie': 565,\n",
       " 'ninja': 566,\n",
       " 'sammy': 567,\n",
       " 'dismiss': 568,\n",
       " 'frequency': 569,\n",
       " 'wonderful': 570,\n",
       " 'hull': 571,\n",
       " 'bargain': 572,\n",
       " 'strategy': 573,\n",
       " 'shefali': 574,\n",
       " 'olive': 575,\n",
       " 'saloon': 576,\n",
       " 'unbiased': 577,\n",
       " 'ingmar': 578,\n",
       " 'annual': 579,\n",
       " 'architect': 580,\n",
       " 'mastery': 581,\n",
       " 'pronounce': 582,\n",
       " 'herman': 583,\n",
       " 'shady': 584,\n",
       " 'bettany': 585,\n",
       " 'transfer': 586,\n",
       " 'moronic': 587,\n",
       " 'timethe': 588,\n",
       " 'nude': 589,\n",
       " 'girlfriend': 590,\n",
       " 'door': 591,\n",
       " 'defender': 592,\n",
       " 'overdose': 593,\n",
       " 'runner': 594,\n",
       " 'poltergeist': 595,\n",
       " 'magically': 596,\n",
       " 'denver': 597,\n",
       " 'outwit': 598,\n",
       " 'darren': 599,\n",
       " 'loosely': 600,\n",
       " 'indication': 601,\n",
       " 'enslave': 602,\n",
       " 'humanity': 603,\n",
       " 'satisfaction': 604,\n",
       " 'frustration': 605,\n",
       " 'contrivance': 606,\n",
       " 'awry': 607,\n",
       " 'exhaust': 608,\n",
       " 'premise': 609,\n",
       " 'skull': 610,\n",
       " 'travis': 611,\n",
       " 'harp': 612,\n",
       " 'isle': 613,\n",
       " 'thieve': 614,\n",
       " 'tube': 615,\n",
       " 'everybody': 616,\n",
       " 'lear': 617,\n",
       " 'particularly': 618,\n",
       " 'masculinity': 619,\n",
       " 'redford': 620,\n",
       " 'ivory': 621,\n",
       " 'adapt': 622,\n",
       " 'dim': 623,\n",
       " 'animation': 624,\n",
       " 'ease': 625,\n",
       " 'horrific': 626,\n",
       " 'cagney': 627,\n",
       " 'blurt': 628,\n",
       " 'crash': 629,\n",
       " 'vacant': 630,\n",
       " 'dan': 631,\n",
       " 'cara': 632,\n",
       " 'pretentious': 633,\n",
       " 'toothe': 634,\n",
       " 'foist': 635,\n",
       " 'immaculate': 636,\n",
       " 'outdated': 637,\n",
       " 'wendy': 638,\n",
       " 'ancient': 639,\n",
       " 'balcony': 640,\n",
       " 'epiphany': 641,\n",
       " 'biopic': 642,\n",
       " 'lifethe': 643,\n",
       " 'appal': 644,\n",
       " 'fourth': 645,\n",
       " 'undermine': 646,\n",
       " 'switch': 647,\n",
       " 'closely': 648,\n",
       " 'rene': 649,\n",
       " 'marginal': 650,\n",
       " 'successfully': 651,\n",
       " 'businessmen': 652,\n",
       " 'currently': 653,\n",
       " 'frame': 654,\n",
       " 'vibrant': 655,\n",
       " 'battleship': 656,\n",
       " 'drawl': 657,\n",
       " 'mill': 658,\n",
       " 'vicious': 659,\n",
       " 'rap': 660,\n",
       " 'shoddy': 661,\n",
       " 'fascist': 662,\n",
       " 'benign': 663,\n",
       " 'quincy': 664,\n",
       " 'undo': 665,\n",
       " 'interrupt': 666,\n",
       " 'sykes': 667,\n",
       " 'cheezy': 668,\n",
       " 'undertake': 669,\n",
       " 'interaction': 670,\n",
       " 'activity': 671,\n",
       " 'cargo': 672,\n",
       " 'noel': 673,\n",
       " 'contestant': 674,\n",
       " 'watchable': 675,\n",
       " 'locate': 676,\n",
       " 'theresa': 677,\n",
       " 'egypt': 678,\n",
       " 'frederick': 679,\n",
       " 'service': 680,\n",
       " 'consolation': 681,\n",
       " 'retro': 682,\n",
       " 'hopper': 683,\n",
       " 'retreat': 684,\n",
       " 'clutter': 685,\n",
       " 'burstyn': 686,\n",
       " 'host': 687,\n",
       " 'hijinks': 688,\n",
       " 'misstep': 689,\n",
       " 'work': 690,\n",
       " 'classify': 691,\n",
       " 'wan': 692,\n",
       " 'blurb': 693,\n",
       " 'kapoor': 694,\n",
       " 'premiere': 695,\n",
       " 'dear': 696,\n",
       " 'fulfillment': 697,\n",
       " 'print': 698,\n",
       " 'mildred': 699,\n",
       " 'ooh': 700,\n",
       " 'phase': 701,\n",
       " 'dilemma': 702,\n",
       " 'firmly': 703,\n",
       " 'drive': 704,\n",
       " 'yikes': 705,\n",
       " 'focus': 706,\n",
       " 'hepburn': 707,\n",
       " 'union': 708,\n",
       " 'shoestring': 709,\n",
       " 'hip': 710,\n",
       " 'randomly': 711,\n",
       " 'explode': 712,\n",
       " 'construct': 713,\n",
       " 'boo': 714,\n",
       " 'marilyn': 715,\n",
       " 'unwilling': 716,\n",
       " 'miraculous': 717,\n",
       " 'hind': 718,\n",
       " 'apparent': 719,\n",
       " 'pod': 720,\n",
       " 'aplenty': 721,\n",
       " 'altman': 722,\n",
       " 'technician': 723,\n",
       " 'carry': 724,\n",
       " 'away': 725,\n",
       " 'interweave': 726,\n",
       " 'teddy': 727,\n",
       " 'spellbind': 728,\n",
       " 'semblance': 729,\n",
       " 'benny': 730,\n",
       " 'subtitle': 731,\n",
       " 'alibi': 732,\n",
       " 'cruel': 733,\n",
       " 'iranian': 734,\n",
       " 'bridge': 735,\n",
       " 'mushroom': 736,\n",
       " 'nausea': 737,\n",
       " 'stance': 738,\n",
       " 'counterpart': 739,\n",
       " 'texan': 740,\n",
       " 'cock': 741,\n",
       " 'seuss': 742,\n",
       " 'caesar': 743,\n",
       " 'woe': 744,\n",
       " 'apply': 745,\n",
       " 'frustrate': 746,\n",
       " 'bunch': 747,\n",
       " 'gradual': 748,\n",
       " 'vent': 749,\n",
       " 'leia': 750,\n",
       " 'shiver': 751,\n",
       " 'correspond': 752,\n",
       " 'deck': 753,\n",
       " 'stalin': 754,\n",
       " 'swank': 755,\n",
       " 'thati': 756,\n",
       " 'nonexistent': 757,\n",
       " 'coppola': 758,\n",
       " 'professor': 759,\n",
       " 'caricature': 760,\n",
       " 'gladiator': 761,\n",
       " 'bruno': 762,\n",
       " 'spunky': 763,\n",
       " 'leung': 764,\n",
       " 'lane': 765,\n",
       " 'cameo': 766,\n",
       " 'brendan': 767,\n",
       " 'remake': 768,\n",
       " 'sickeningly': 769,\n",
       " 'airplane': 770,\n",
       " 'standout': 771,\n",
       " 'devgan': 772,\n",
       " 'eastern': 773,\n",
       " 'teenager': 774,\n",
       " 'hawaii': 775,\n",
       " 'elisabeth': 776,\n",
       " 'audacity': 777,\n",
       " 'somewhere': 778,\n",
       " 'goodbye': 779,\n",
       " 'award': 780,\n",
       " 'apathetic': 781,\n",
       " 'morality': 782,\n",
       " 'precursor': 783,\n",
       " 'superb': 784,\n",
       " 'gel': 785,\n",
       " 'clarify': 786,\n",
       " 'hide': 787,\n",
       " 'invisibility': 788,\n",
       " 'hugo': 789,\n",
       " 'wade': 790,\n",
       " 'pre': 791,\n",
       " 'hilariously': 792,\n",
       " 'recluse': 793,\n",
       " 'eat': 794,\n",
       " 'armstrong': 795,\n",
       " 'historical': 796,\n",
       " 'tax': 797,\n",
       " 'peckinpah': 798,\n",
       " 'moses': 799,\n",
       " 'skate': 800,\n",
       " 'barrel': 801,\n",
       " 'daily': 802,\n",
       " 'performer': 803,\n",
       " 'michelle': 804,\n",
       " 'fringe': 805,\n",
       " 'unarm': 806,\n",
       " 'murky': 807,\n",
       " 'abortion': 808,\n",
       " 'sappy': 809,\n",
       " 'physical': 810,\n",
       " 'unbalance': 811,\n",
       " 'transformer': 812,\n",
       " 'imperial': 813,\n",
       " 'meryl': 814,\n",
       " 'idealistic': 815,\n",
       " 'narrow': 816,\n",
       " 'jackson': 817,\n",
       " 'glorify': 818,\n",
       " 'turn': 819,\n",
       " 'loyalty': 820,\n",
       " 'respectable': 821,\n",
       " 'donovan': 822,\n",
       " 'intercut': 823,\n",
       " 'crud': 824,\n",
       " 'investigative': 825,\n",
       " 'occupant': 826,\n",
       " 'hasnt': 827,\n",
       " 'rumble': 828,\n",
       " 'prominently': 829,\n",
       " 'isabel': 830,\n",
       " 'campbell': 831,\n",
       " 'corrupt': 832,\n",
       " 'snuff': 833,\n",
       " 'forgive': 834,\n",
       " 'moustache': 835,\n",
       " 'turner': 836,\n",
       " 'persuade': 837,\n",
       " 'console': 838,\n",
       " 'nikki': 839,\n",
       " 'dennis': 840,\n",
       " 'recently': 841,\n",
       " 'presley': 842,\n",
       " 'trainer': 843,\n",
       " 'perilous': 844,\n",
       " 'besides': 845,\n",
       " 'evocative': 846,\n",
       " 'eyecandy': 847,\n",
       " 'taboo': 848,\n",
       " 'frenetic': 849,\n",
       " 'slayer': 850,\n",
       " 'relevant': 851,\n",
       " 'announcement': 852,\n",
       " 'gloomy': 853,\n",
       " 'psychosis': 854,\n",
       " 'search': 855,\n",
       " 'specie': 856,\n",
       " 'malcolm': 857,\n",
       " 'beneath': 858,\n",
       " 'kirk': 859,\n",
       " 'expend': 860,\n",
       " 'wisdom': 861,\n",
       " 'refusal': 862,\n",
       " 'abrupt': 863,\n",
       " 'hindu': 864,\n",
       " 'bless': 865,\n",
       " 'featurelength': 866,\n",
       " 'crave': 867,\n",
       " 'mamet': 868,\n",
       " 'faint': 869,\n",
       " 'unappealing': 870,\n",
       " 'neo': 871,\n",
       " 'lori': 872,\n",
       " 'san': 873,\n",
       " 'prospective': 874,\n",
       " 'polite': 875,\n",
       " 'rereleased': 876,\n",
       " 'nationalist': 877,\n",
       " 'plausibility': 878,\n",
       " 'gold': 879,\n",
       " 'failure': 880,\n",
       " 'sweep': 881,\n",
       " 'saw': 882,\n",
       " 'rival': 883,\n",
       " 'cinematographer': 884,\n",
       " 'psychological': 885,\n",
       " 'dustin': 886,\n",
       " 'typical': 887,\n",
       " 'medicine': 888,\n",
       " 'flute': 889,\n",
       " 'hopkins': 890,\n",
       " 'industrial': 891,\n",
       " 'jaffe': 892,\n",
       " 'gandolfini': 893,\n",
       " 'help': 894,\n",
       " 'certificate': 895,\n",
       " 'conjure': 896,\n",
       " 'college': 897,\n",
       " 'cuteness': 898,\n",
       " 'closeup': 899,\n",
       " 'phyllis': 900,\n",
       " 'watch': 901,\n",
       " 'mumble': 902,\n",
       " 'crank': 903,\n",
       " 'exploitive': 904,\n",
       " 'peasant': 905,\n",
       " 'goo': 906,\n",
       " 'perceptive': 907,\n",
       " 'lovable': 908,\n",
       " 'label': 909,\n",
       " 'lull': 910,\n",
       " 'uninterested': 911,\n",
       " 'chairman': 912,\n",
       " 'cheesiness': 913,\n",
       " 'recommendation': 914,\n",
       " 'invasion': 915,\n",
       " 'prolong': 916,\n",
       " 'reprise': 917,\n",
       " 'restroom': 918,\n",
       " 'lily': 919,\n",
       " 'beach': 920,\n",
       " 'function': 921,\n",
       " 'slowmoving': 922,\n",
       " 'bailey': 923,\n",
       " 'overdramatic': 924,\n",
       " 'inherently': 925,\n",
       " 'coaster': 926,\n",
       " 'bullet': 927,\n",
       " 'flawless': 928,\n",
       " 'rhyme': 929,\n",
       " 'go': 930,\n",
       " 'slob': 931,\n",
       " 'scorsese': 932,\n",
       " 'nevertheless': 933,\n",
       " 'showi': 934,\n",
       " 'hopelessly': 935,\n",
       " 'face': 936,\n",
       " 'mann': 937,\n",
       " 'rosa': 938,\n",
       " 'sleazy': 939,\n",
       " 'occasional': 940,\n",
       " 'stunningly': 941,\n",
       " 'every': 942,\n",
       " 'bin': 943,\n",
       " 'professional': 944,\n",
       " 'fiona': 945,\n",
       " 'baldwin': 946,\n",
       " 'temple': 947,\n",
       " 'prey': 948,\n",
       " 'norman': 949,\n",
       " 'strongly': 950,\n",
       " 'coproduction': 951,\n",
       " 'seminal': 952,\n",
       " 'willard': 953,\n",
       " 'kristofferson': 954,\n",
       " 'shortly': 955,\n",
       " 'motley': 956,\n",
       " 'whenever': 957,\n",
       " 'crisp': 958,\n",
       " 'eddie': 959,\n",
       " 'baffle': 960,\n",
       " 'villainess': 961,\n",
       " 'nonactors': 962,\n",
       " 'screen': 963,\n",
       " 'inadequate': 964,\n",
       " 'commonplace': 965,\n",
       " 'zap': 966,\n",
       " 'fifth': 967,\n",
       " 'doorway': 968,\n",
       " 'amok': 969,\n",
       " 'mow': 970,\n",
       " 'clara': 971,\n",
       " 'heri': 972,\n",
       " 'popularity': 973,\n",
       " 'fragile': 974,\n",
       " 'scenery': 975,\n",
       " 'investigate': 976,\n",
       " 'unpretentious': 977,\n",
       " 'skip': 978,\n",
       " 'cottage': 979,\n",
       " 'motherdaughter': 980,\n",
       " 'spot': 981,\n",
       " 'gi': 982,\n",
       " 'awaken': 983,\n",
       " 'perhaps': 984,\n",
       " 'gypsy': 985,\n",
       " 'unify': 986,\n",
       " 'visceral': 987,\n",
       " 'era': 988,\n",
       " 'doodle': 989,\n",
       " 'vagina': 990,\n",
       " 'come': 991,\n",
       " 'robby': 992,\n",
       " 'feminine': 993,\n",
       " 'swoon': 994,\n",
       " 'waste': 995,\n",
       " 'tree': 996,\n",
       " 'cole': 997,\n",
       " 'disgustingly': 998,\n",
       " 'fantasy': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if labels fit\n",
    "index = random.randint(0, len(train_set))\n",
    "print(Y_train[index])\n",
    "print(train_set.loc[index, 'label'])\n",
    "\n",
    "print(len(vocab))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up genetic algorithm\n",
    "\n",
    "Genetic Algorithm is an algorithm that's inspired by evolution theory. Here we have a list of solutions that can be anything that keeps some data in some form of data-structures. They \"mutate\" and \"reproduce\" and new generations are produced. We choose the best chromosomes and eliminate bad ones. The goal is to come up with the best solution after some generations.\n",
    "\n",
    "I built 3 classes to apply the genetic algorithm.\n",
    "1. The classifier: It's a simple neural network. It takes vectors as input and classifies it, and calculates Cross Entropy Loss and accuracy.\n",
    "2. The Chromosome: This is a class that essentially just keeps the weights and makes operations on the weights. In GA we are trying to optimize the weights. So it has some functions like mutation, crossover and assigning fitness.\n",
    "3. GAEngine (Genetic Algorithm Engine): This class makes operations on the chromosomes at a higher lever. It has functions like choosing chromosomes to mutate, to do crossover, choosing what chromosomes to keep etc. and it has a function that runs the routine of the genetic algorithm training.\n",
    "\n",
    "The structure where we use two seperate classes, GAEngine and Chromosome, is inspired from an earlier base code on GA assignment. On some guides online they use that structure too. It's very logical, convenient and easy to understand. Chromosome objects represents the \"species\" and GAEngine represents the \"nature\" in evolution theory.\n",
    "\n",
    "While the GA training routine was put outside the GAEngine in the earlier GA assignment, I put it inside in a function here. That is to make the code more clean.\n",
    "\n",
    "I could use both classifier and Chromosome as same class, since both keeps weights. But classifier keeps vocab and idfs. I didn't want to keep same data multiple places. Their functions are distinct, classifier is a classifier, but Chromosome just keeps and opreates on weights. So keeping them as distinct classes makes more sense and gives more clean structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Classifier\n",
    "In the assignment text they mention using decision tree. I tried to build one, but I have not much experience with decision trees. There are other classifiers too. I haven't any experience in most of them, just a little familiar with Neural Network thus this is what I did choose.\n",
    "\n",
    "Too simple architecture fails to make prediction. I tried with simple architecture and it was almost untrainable. Too complicated architecture (too many nodes, too much hidden layers) causes overfitting and it's very slow in training and prediction. After experimenting with different models, the model I decided is this:\n",
    "\n",
    "Input is as long as length of the vocab, which is 1250.\n",
    "\n",
    "Then a hidden layer of 16 nodes, using ReLU as activation function.\n",
    "Then a hidden layer of 8 nodes, using ReLU as activation function.\n",
    "Then using one more hidden layer of 2 nodes. No special activation function is used, it's just linear.\n",
    "Then at the end I use \"SoftMax\" to get predictions as output.\n",
    "\n",
    "Number of layers can't be set dynamically, but number of hidden nodes can be set dynamically while instantiating the classifier.\n",
    "\n",
    "The classifier returns both \"Cross Entropy Loss\" and \"accuracy\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, idfs, vocab):\n",
    "        self.idfs = idfs\n",
    "        self.vocab = vocab\n",
    "        self.ws_1 = 0\n",
    "        self.ws_2 = 0\n",
    "        self.ws_3 = 0\n",
    "        self.np_predictor = np.vectorize(lambda vec: self.predict(vec))\n",
    "        self.hn_1 = 0\n",
    "        self.hn_2 = 0\n",
    "        self.in_vector = 0\n",
    "\n",
    "    # Initializing weights\n",
    "    def init_weights(self):\n",
    "        self.ws_1 = np.random.rand(self.in_vector, self.hn_1) - 0.5\n",
    "        self.ws_2 = np.random.rand(self.hn_1, self.hn_2) - 0.5\n",
    "        self.ws_3 = np.random.rand(self.hn_2, 2) - 0.5\n",
    "        return self.ws_1, self.ws_2, self.ws_3\n",
    "        \n",
    "    def set_weights(self, ws_1, ws_2, ws_3):\n",
    "        self.ws_1 = ws_1\n",
    "        self.ws_2 = ws_2\n",
    "        self.ws_3 = ws_3\n",
    "    \n",
    "    def set_hidden_nodes(self, in_vector, hn_1, hn_2):\n",
    "        self.hn_1 = hn_1\n",
    "        self.hn_2 = hn_2\n",
    "        self.in_vector = in_vector\n",
    "\n",
    "    def relu(self, x):\n",
    "        return (x > 0) * x\n",
    "    \n",
    "    def relu_grad(self, x):\n",
    "        return x > 0\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        from scipy import special\n",
    "        return special.expit(x)\n",
    "    \n",
    "    def sigmoid_grad(self, x):\n",
    "        return self.sigmoid(x)*(1 - self.sigmoid(x))\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        import numpy as np\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum()\n",
    "        \n",
    "    def train_with_SGD(self, epochs, lr, x, y):\n",
    "        error_list = list()\n",
    "        mse_list = list()\n",
    "        \n",
    "        for n in range(epochs):\n",
    "            for i in range(x.shape[0]):\n",
    "                l_in = x[i:i+1]\n",
    "                l_o, l_4, l_3, l_2, l_1, s_1 = self.predict(l_in, True)           \n",
    "                \n",
    "                delta_2 = l_2 - y[i]\n",
    "                delta_1 = delta_2.dot(self.ws_2.T) * self.relu_grad(l_1)\n",
    "                \n",
    "                self.ws_2 -= lr * (l_1.T.reshape(self.hn_1,1).dot(delta_2))\n",
    "                self.ws_1 -= lr * (l_in.T.reshape(x.shape[1],1).dot(delta_1))\n",
    "\n",
    "                error = delta_2**2\n",
    "                    \n",
    "                error_list.append(error[0][0])\n",
    "            \n",
    "            mse_list.append(sum(error_list) / x.shape[0])\n",
    "            error_list = list()\n",
    "        \n",
    "        cel, output, acc = self.predict_whole_set(x, y)\n",
    "        \n",
    "        return mse_list, cel, output, acc\n",
    "                \n",
    "\n",
    "    def cross_entropy(self, p, y):\n",
    "        import numpy as np\n",
    "        return (-np.nan_to_num(np.eye(2)[y]*np.log(p))).mean() * 2\n",
    "    \n",
    "    def predict(self, x, get_all=False):\n",
    "        #forward pass/prediction\n",
    "        layer_1 = self.relu(x.dot(self.ws_1))\n",
    "        layer_2 = self.relu(layer_1.dot(self.ws_2))\n",
    "        layer_3 = layer_2.dot(self.ws_3)\n",
    "        layer_out = self.softmax(layer_3)\n",
    "        if get_all:\n",
    "            return layer_out, layer_3, layer_2, layer_1\n",
    "        else:\n",
    "            return layer_out\n",
    "    \n",
    "    def get_accuracy(self, y, p):\n",
    "        acc = np.sum((y == np.argmax(p, axis=1))) / len(y)\n",
    "        return acc\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict_whole_set(self, x, y, get_acc = True):\n",
    "        output = np.apply_along_axis(self.predict, 1, x)\n",
    "        cel = self.cross_entropy(output, y)\n",
    "        if get_acc:\n",
    "            acc = self.get_accuracy(y, output)\n",
    "        if get_acc:\n",
    "            acc = self.get_accuracy(y, output)\n",
    "            return cel, output, acc\n",
    "        else:\n",
    "            return cel, output\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we initialize and test our classifier to see how it predicts, if it works as expected or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifier\n",
    "classifier = Classifier(idfs, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.072011638796448\n",
      "0.4997333333333333\n",
      "[[9.99999889e-01 1.11383809e-07]\n",
      " [9.99999319e-01 6.81348389e-07]\n",
      " [9.68211864e-01 3.17881359e-02]\n",
      " ...\n",
      " [1.00000000e+00 1.11331204e-10]\n",
      " [9.96560720e-01 3.43927973e-03]\n",
      " [9.80281584e-01 1.97184162e-02]]\n",
      "[[ 0.26542981  0.3311624  -0.47937628 ...  0.26767305 -0.44613391\n",
      "   0.02103476]\n",
      " [-0.22424768 -0.22932442  0.09071726 ... -0.46091949 -0.25229599\n",
      "   0.02260476]\n",
      " [-0.26262228  0.33867296 -0.30985399 ...  0.31160553  0.20990047\n",
      "  -0.07684057]\n",
      " ...\n",
      " [-0.00915567 -0.02611491 -0.41027426 ... -0.43388695 -0.16385741\n",
      "  -0.34452612]\n",
      " [-0.21153285  0.3718312  -0.36969389 ... -0.26912316  0.39565801\n",
      "   0.34493465]\n",
      " [-0.16418904  0.40560293 -0.3709111  ... -0.29967806  0.14333594\n",
      "   0.1420141 ]] [[-0.44987885  0.05377849  0.46163044  0.43166965  0.45261441  0.21427695\n",
      "   0.24883992 -0.11608683]\n",
      " [-0.45167024 -0.14885657 -0.3353464   0.32729204  0.2174291   0.23605159\n",
      "  -0.2059786  -0.22101227]\n",
      " [-0.4054087  -0.27331523 -0.28265061 -0.26086687  0.04328779 -0.02745758\n",
      "  -0.08283496 -0.01740277]\n",
      " [-0.42269315  0.2134911   0.26950285 -0.17540213 -0.28521171  0.3607279\n",
      "  -0.10235879 -0.04760015]\n",
      " [ 0.16117065 -0.38307274 -0.23842301  0.14318865 -0.17274613  0.19371429\n",
      "  -0.05394928  0.23090062]\n",
      " [-0.45184862  0.18658436  0.33920852  0.37631804 -0.05496258  0.46232818\n",
      "  -0.31064933 -0.45169578]\n",
      " [-0.3379649  -0.01533965  0.27053022 -0.31764566  0.25394874  0.30790101\n",
      "  -0.43341849  0.0079357 ]\n",
      " [-0.01145156 -0.08015887 -0.063497    0.35832485 -0.15612908 -0.23666008\n",
      "   0.14088958  0.01954647]\n",
      " [ 0.38809483 -0.43887516  0.07634238  0.2138452  -0.18937319 -0.17218845\n",
      "   0.15772253 -0.21533194]\n",
      " [-0.25303371  0.06694512  0.06470053  0.35041341 -0.10856303  0.47824751\n",
      "   0.0413937  -0.35827057]\n",
      " [ 0.35048502  0.07638786  0.42611677  0.07955677  0.29474235 -0.39477169\n",
      "   0.45298941 -0.24053123]\n",
      " [-0.27919705 -0.48798265  0.21443195  0.38705001 -0.36058754  0.3139277\n",
      "   0.36541115  0.03186128]\n",
      " [ 0.44147162 -0.22985672  0.07077311 -0.0190576  -0.21061804  0.15997418\n",
      "   0.197401    0.07080201]\n",
      " [ 0.00276778 -0.49529583 -0.45097    -0.08101092  0.38963625 -0.3841063\n",
      "  -0.15768074 -0.30206785]\n",
      " [-0.3888716  -0.17685013  0.26552833 -0.19729596  0.47088907 -0.31684065\n",
      "  -0.4420557   0.32150093]\n",
      " [ 0.3584886  -0.36606908 -0.32058808 -0.4684649  -0.11899887 -0.31207999\n",
      "  -0.38827607  0.49546562]] [[-0.05247871 -0.05195287]\n",
      " [-0.33516884  0.45346271]\n",
      " [ 0.35512302 -0.2342281 ]\n",
      " [ 0.35618694 -0.01542013]\n",
      " [ 0.23489586 -0.37323607]\n",
      " [ 0.37582034  0.21372169]\n",
      " [ 0.16567354  0.31638024]\n",
      " [ 0.34737192 -0.43090347]]\n"
     ]
    }
   ],
   "source": [
    "classifier.set_hidden_nodes(len(vocab), 16, 8)\n",
    "classifier.init_weights()\n",
    "cel_pre, output, acc_pre = classifier.predict_whole_set(X_valid, Y_valid)\n",
    "print(cel_pre)\n",
    "print(acc_pre)\n",
    "\n",
    "print(output)\n",
    "print(classifier.ws_1, classifier.ws_2, classifier.ws_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Chromosome\n",
    "This is the Chromosome. Chromosome keeps the weights and has some methods for mutation, cross.over and fitness calculation\n",
    "\n",
    "I have written own operator functions like`__eq__`. The comparisons will be made based on value of `self.fitness`. In the GAEngine I do compare the fitness values and sort the lists, so rather than calling lambda each time I cal max() or sorte(), I did implement those functions to make the code more clean and robust.\n",
    "\n",
    "The Chromosome has three essential functions:\n",
    "1. Assign fitness. This uses the classifier class above. It is based on accuracy after predicting the data on validation set. The goal is to increase the accuracy as much as possible.\n",
    "2. Cross over: it accepts another chromosome as parameter. New weights are produced from calculations which made based on weight values of both chromosomes (self and other). Then a new chromosome is iniitalized and returned. It's as parents give offspring to a child where childs genes are combination of parent's genes. But in this algorithm the Chromosomes has no genders, so anyone can make offspring from anyone.\n",
    "3. Mutation: here we make som random changes on the weights of the Chromosome.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Chromosome:\n",
    "    # x_pos and y_pos are the features of our chromosome\n",
    "    def __init__(self, ws_1, ws_2, ws_3):\n",
    "        self._fitness = 0\n",
    "        self._ws_1 = ws_1\n",
    "        self._ws_2 = ws_2\n",
    "        self._ws_3 = ws_3\n",
    "    \n",
    "    # Getters and setters\n",
    "    @property\n",
    "    def ws_1(self):\n",
    "        return self._ws_1\n",
    "    \n",
    "    @ws_1.setter\n",
    "    def ws_1(self, value):\n",
    "        self._ws_1 = value\n",
    "    \n",
    "    @property\n",
    "    def ws_2(self):\n",
    "        return self._ws_2\n",
    "    \n",
    "    @ws_2.setter\n",
    "    def ws_2(self, value):\n",
    "        self._ws_2 = value\n",
    "    \n",
    "    @property\n",
    "    def ws_3(self):\n",
    "        return self._ws_3\n",
    "    \n",
    "    @ws_3.setter\n",
    "    def ws_3(self, value):\n",
    "        self._ws_3 = value\n",
    "    \n",
    "    @property\n",
    "    def fitness(self):\n",
    "        return self._fitness\n",
    "    \n",
    "    @fitness.setter\n",
    "    def fitness(self, value):\n",
    "        self._fitness = value\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.fitness < other.fitness\n",
    "\n",
    "    def __le__(self, other):\n",
    "        return self.fitness <= other.fitness\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.fitness == other.fitness\n",
    "    \n",
    "    def __ne__(self, other):\n",
    "        return self.fitness != other.fitness\n",
    "    \n",
    "    def __ge__(self, other):\n",
    "        return self.fitness >= other.fitness\n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        return self.fitness > other.fitness\n",
    "    \n",
    "    def assign_fitness(self, classifier, x, y):\n",
    "        import math\n",
    "        classifier.set_weights(self.ws_1, self.ws_2, self.ws_3)\n",
    "        loss, _, acc = classifier.predict_whole_set(x, y, True)\n",
    "        self.fitness = acc #0 if loss <= 0 or loss == float('inf') else -math.log(1 / loss)\n",
    "    \n",
    "    # produce a new offspring from 2 parents\n",
    "    def crossover(self, other):\n",
    "        r = 2\n",
    "        \n",
    "        min_mat_1 = np.minimum(self.ws_1, other.ws_1)\n",
    "        max_mat_1 = np.maximum(self.ws_1, other.ws_1)\n",
    "        min_mat_2 = np.minimum(self.ws_2, other.ws_2)\n",
    "        max_mat_2 = np.maximum(self.ws_2, other.ws_2)\n",
    "        min_mat_3 = np.minimum(self.ws_3, other.ws_3)\n",
    "        max_mat_3 = np.maximum(self.ws_3, other.ws_3)\n",
    "        \n",
    "        ws_1 = np.random.uniform(min_mat_1-r, max_mat_1+r)\n",
    "        ws_2 = np.random.uniform(min_mat_2-r, max_mat_2+r)\n",
    "        ws_3 = np.random.uniform(min_mat_3-r, max_mat_3+r) \n",
    "        \n",
    "        offspring = Chromosome(ws_1, ws_2, ws_3)\n",
    "        return offspring\n",
    "\n",
    "    # mutate the individual\n",
    "    def mutate(self):\n",
    "        np.random.shuffle(self.ws_1)\n",
    "        self.ws_1 = self.ws_1 + np.random.uniform(-5, 5, size=self.ws_1.shape)\n",
    "        np.random.shuffle(self.ws_2)\n",
    "        self.ws_2 = self.ws_2 + np.random.uniform(-5, 5, size=self.ws_2.shape)\n",
    "        np.random.shuffle(self.ws_3)\n",
    "        self.ws_3 = self.ws_3 + np.random.uniform(-5, 5, size=self.ws_3.shape)\n",
    "        return\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Genetic Algorithm Engine\n",
    "\n",
    "Here I have divided the chromosome in two groups: elite and population.\n",
    "Elite contains the population with highest fitness. This is to make sure if we find a very fit chromosome we don't lose it again because of cross overs or mutations.\n",
    "\n",
    "And we make the mutations first. We make mutations on the least fit chromosomes. We don't want to mutate highest fit chromosomes. How many to mutate is also passed as a parameter. After mutations we determine the mutated chromosomes new fitness values and update elite list again.\n",
    "\n",
    "In the cross-over I use something similar to roulette wheel. How much of the crossover will be from elite will be passed as a parameter. \n",
    "Based on that value, I produce M number of offsprings only from the elites (chosen randomly). Elites are the list of most fit chromosomes. How many to keep in elites is also passed as a parmater to training function.\n",
    "\n",
    "And I produce N number of offsprings from the chromosomes randomly chosen from population. But here the random choice is weighted one, also it's higher probabilty to choose chromosomes with higher fitness values. After all the cross overs the old population is thrown out and new generation is produced from the offsprings. The number of the offsprings is equal to the number of the population to avoid decrease or increase in the population. Since we keep the most fit ones in the elite list, we don't lose winners by replacing the old generation with the new geneartion.\n",
    "\n",
    "After the cross-overs it determines the fitness values of the new population and update the elite list again.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GAEngine:\n",
    "    def __init__(self, classifier):\n",
    "        self._population = []\n",
    "        self._generations = 0\n",
    "        self._classifier = classifier\n",
    "        self.elite = []\n",
    "        self.nr_of_elites = 0\n",
    "\n",
    "    def make_initial_population(self, population_size):       \n",
    "        for i in range(population_size):\n",
    "            ws_1, ws_2, ws_3 = self.classifier.init_weights()\n",
    "            self.population.append(Chromosome(ws_1, ws_2, ws_3))\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def generations(self):\n",
    "        return self._generations\n",
    "    \n",
    "    @generations.setter\n",
    "    def generations(self, g):\n",
    "        self._generations = g\n",
    "    \n",
    "    @property\n",
    "    def population(self):\n",
    "        return self._population\n",
    "    \n",
    "    @population.setter\n",
    "    def population(self, p):\n",
    "        self._population = p\n",
    "    \n",
    "    @property\n",
    "    def classifier(self):\n",
    "        return self._classifier\n",
    "    \n",
    "    @classifier.setter\n",
    "    def classifier(self, cl):\n",
    "        self._classifier = cl\n",
    "    \n",
    "    # selection code goes here...\n",
    "    def do_crossover(self, elite_crossover_rate):\n",
    "        import random\n",
    "        population_size = len(self.population)\n",
    "        \n",
    "                \n",
    "        # Here we combine elitism selection with roulette wheel\n",
    "        # We carry some of the most fit over to the next generation.\n",
    "        # We do cross over with both the elite and other population\n",
    "        # Then we use roulette wheel because we want diversity too.\n",
    "        # We want diversity because it's hard to predict optimal weights\n",
    "        \n",
    "        no_of_elite_crossovers = int(elite_crossover_rate * population_size)\n",
    "        \n",
    "        other_offspring = population_size - no_of_elite_crossovers\n",
    "\n",
    "        new_generation = list()\n",
    "        \n",
    "        # Offsprings from the elite\n",
    "        for i in range(no_of_elite_crossovers):\n",
    "            parent1, parent2 = random.choices(self.elite, k=2)\n",
    "            offspring = parent1.crossover(parent2)\n",
    "            new_generation.append(offspring)\n",
    "        \n",
    "        # Weighted random choice\n",
    "        fitness_values = [x.fitness for x in self.population]\n",
    "        \n",
    "        # Offsprings from other population\n",
    "        for i in range(other_offspring):\n",
    "            parent1, parent2 = random.choices(self.population, weights=fitness_values, k=2)\n",
    "            offspring = parent1.crossover(parent2)\n",
    "            new_generation.append(offspring)\n",
    "        \n",
    "        # The population is the new generation\n",
    "        self.population = new_generation\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def do_mutation(self, no_of_mutation, x, y):\n",
    "        for i in range(no_of_mutation):\n",
    "            self.population[-i-1].mutate()\n",
    "            self.population[-i-1].assign_fitness(self.classifier, x, y)\n",
    "    \n",
    "    \n",
    "    # fitness calculation goes here...\n",
    "    def assign_fitness(self, x, y):\n",
    "        for ch in self.population:\n",
    "            ch.assign_fitness(self.classifier, x, y)\n",
    "        self.population = sorted(self.population, reverse=True)\n",
    "        self.update_elite()\n",
    "        return\n",
    "    \n",
    "    def get_population(self):\n",
    "        return self.population\n",
    "    \n",
    "    def update_elite(self):\n",
    "        if len(self.elite) == 0:\n",
    "            self.elite = self.population[-self.nr_of_elites:]\n",
    "            self.elite = sorted(self.elite, reverse=True)\n",
    "            return\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while i < self.nr_of_elites and j < len(self.population):\n",
    "            if self.elite[i] < self.population[j]:\n",
    "                self.elite[i] = self.population[j]\n",
    "                i += 1\n",
    "                j += 1\n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        self.elite = sorted(self.elite, reverse=True)\n",
    "\n",
    "    \n",
    "    def get_best_chromosome(self):\n",
    "        return max(self.elite)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # TRAINING ROUTINE\n",
    "    def training_routine(self, init_population, nr_of_generations, \n",
    "                        nr_of_mutation, nr_of_elites, elite_crossover_rate, x, y):\n",
    "        self.make_initial_population(init_population)\n",
    "        self.generations = nr_of_generations\n",
    "        self.nr_of_elites = nr_of_elites\n",
    "        \n",
    "        cels = list()\n",
    "\n",
    "\n",
    "        for i in range(self.generations):\n",
    "            self.assign_fitness(x, y)\n",
    "            self.update_elite()\n",
    "            cels.append(self.elite[-1].fitness)\n",
    "            \n",
    "            self.do_mutation(nr_of_mutation, x, y)\n",
    "            self.update_elite()\n",
    "            \n",
    "            self.do_crossover(elite_crossover_rate)\n",
    "            \n",
    "            \n",
    "\n",
    "        # Assign fitness last time before getting the best chromosome\n",
    "        self.assign_fitness(x, y)\n",
    "        self.update_elite()\n",
    "        cels.append(self.get_best_chromosome().fitness)\n",
    "        return self.get_best_chromosome(), cels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.4 Optimizing classifier with Genetic Algorithm\n",
    "\n",
    "Here I just run the training_routine function of the GAEngine.\n",
    "\n",
    "It has following parameters:\n",
    "* init_population: The population to start with.\n",
    "* nr_of_generations: how many generations to run this\n",
    "* nr_of_mutation: how many mutations\n",
    "* nr_of_elites: how many to keep in self.elite.\n",
    "* elite_crossover_rate: the offspring rate is constant (equal to size of population). This determines how much of that offspring should be produced from chromosomes in self.elite, and how much from self.population.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-177-bd99c7f08a9d>:77: RuntimeWarning: divide by zero encountered in log\n",
      "  return (-np.nan_to_num(np.eye(2)[y]*np.log(p))).mean() * 2\n",
      "<ipython-input-177-bd99c7f08a9d>:77: RuntimeWarning: invalid value encountered in multiply\n",
      "  return (-np.nan_to_num(np.eye(2)[y]*np.log(p))).mean() * 2\n",
      "C:\\Users\\abdka\\anaconda3\\envs\\testing\\lib\\site-packages\\numpy\\core\\_methods.py:160: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6h 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Here I run the GA engine\n",
    "classifier = Classifier(idfs, vocab)\n",
    "classifier.set_hidden_nodes(len(vocab), 16, 8)\n",
    "\n",
    "ga = GAEngine(classifier)\n",
    "\n",
    "init_population = 100\n",
    "nr_of_generations = 300 \n",
    "nr_of_mutation = 50\n",
    "nr_of_elites = 50\n",
    "elite_crossover_rate = 0.8\n",
    "\n",
    "ch, cels = ga.training_routine(init_population, \n",
    "                               nr_of_generations, \n",
    "                               nr_of_mutation,\n",
    "                               nr_of_elites, \n",
    "                               elite_crossover_rate, \n",
    "                               X_valid, Y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting increase of fitness in training\n",
    "x = np.linspace(0, len(cels), len(cels))\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(x, cels, label='fitness')\n",
    "\n",
    "plt.xlabel(\"Generations\")\n",
    "plt.ylabel(\"fitness\")\n",
    "plt.title(\"Change of fitness (fitness = accuracy)\")\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validation\n",
    "\n",
    "Here we use the weights of the most fit chromosome after the optimization using GA in our classifier.\n",
    "We classify the whole test set and print the results both in terms of accuracy and CEL to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-177-bd99c7f08a9d>:77: RuntimeWarning: divide by zero encountered in log\n",
      "  return (-np.nan_to_num(np.eye(2)[y]*np.log(p))).mean() * 2\n",
      "<ipython-input-177-bd99c7f08a9d>:77: RuntimeWarning: invalid value encountered in multiply\n",
      "  return (-np.nan_to_num(np.eye(2)[y]*np.log(p))).mean() * 2\n",
      "C:\\Users\\abdka\\anaconda3\\envs\\testing\\lib\\site-packages\\numpy\\core\\_methods.py:160: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n"
     ]
    }
   ],
   "source": [
    "classifier.set_weights(ch.ws_1, ch.ws_2, ch.ws_3)\n",
    "cel_post, output_post, acc_post = classifier.predict_whole_set(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before training:  0.4997333333333333\n",
      "Accuracy after training:  0.7376\n",
      "CEL before training 5.072011638796448\n",
      "CEL after training inf\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy before training: \", acc_pre)\n",
    "print(\"Accuracy after training: \", acc_post)\n",
    "print(\"CEL before training\", cel_pre)\n",
    "print(\"CEL after training\", cel_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(output_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.2469065    3.21252532  -6.27164822 ...  -2.13896112  -5.59220524\n",
      "   -0.0841441 ]\n",
      " [ -0.44141939   8.48862487   3.71262239 ...   0.7381675  -14.12409882\n",
      "  -13.86798985]\n",
      " [  6.99323263 -14.80405034  -8.98340341 ...  -1.98339349  -0.34661764\n",
      "   -8.79816289]\n",
      " ...\n",
      " [  1.41649973  -7.57797793   5.44557948 ...   3.50381265   1.60514616\n",
      "    3.92438687]\n",
      " [ -5.87699909   0.77728401 -14.88713639 ...  -6.71890871   0.60682239\n",
      "   -8.91303156]\n",
      " [-13.3781284   -5.36872497   6.83519258 ...   1.88020177  -1.68629528\n",
      "  -18.15099109]] [[ -2.2469065    3.21252532  -6.27164822 ...  -2.13896112  -5.59220524\n",
      "   -0.0841441 ]\n",
      " [ -0.44141939   8.48862487   3.71262239 ...   0.7381675  -14.12409882\n",
      "  -13.86798985]\n",
      " [  6.99323263 -14.80405034  -8.98340341 ...  -1.98339349  -0.34661764\n",
      "   -8.79816289]\n",
      " ...\n",
      " [  1.41649973  -7.57797793   5.44557948 ...   3.50381265   1.60514616\n",
      "    3.92438687]\n",
      " [ -5.87699909   0.77728401 -14.88713639 ...  -6.71890871   0.60682239\n",
      "   -8.91303156]\n",
      " [-13.3781284   -5.36872497   6.83519258 ...   1.88020177  -1.68629528\n",
      "  -18.15099109]] [[18.02465717 -6.99996707]\n",
      " [ 1.1795972  -4.33473879]\n",
      " [-3.36996078  6.97309421]\n",
      " [-5.28993121  3.7122089 ]\n",
      " [-7.34488839  0.51183016]\n",
      " [ 0.04937252  4.8496624 ]\n",
      " [-1.63293339  2.07508695]\n",
      " [-8.1356436   4.80463986]]\n"
     ]
    }
   ],
   "source": [
    "print(ch.ws_1, ch.ws_1, ch.ws_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch test\n",
    "\n",
    "The assignment asks to build own classifier in Python without using libraries like PyTorch or Tensorflow. Thus I build my own classifier class as seen above.\n",
    "\n",
    "But I wanted to compare training weights using GA vs using SDG. I didn't want to build SDG training algorithm without libraries since the assignment doesn't ask for building a SDG trainer. Thus to make the comparison I used PyTorch here.\n",
    "\n",
    "Below is the \"training with SDG\" routine using PyTorch, and the results shown in a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "\n",
    "def training(num_epochs, model, optimizer, criterion, train_loader, valid_loader, vocab_length):\n",
    "    results = list()\n",
    "    accuracies = list()\n",
    "    valid_results = list()\n",
    "    valid_accuracies = list()\n",
    "\n",
    "    #model.float()\n",
    "    for ep in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        valid_loss = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        total_valid = 0\n",
    "        correct_valid = 0\n",
    "        model.train() # Set model into training mode\n",
    "        for batch in train_loader:\n",
    "            # We extract the images and labels from the batch\n",
    "            vector = batch[:, :vocab_length]\n",
    "            labels = batch[:, vocab_length]\n",
    "            labels = torch.tensor(labels, dtype=torch.long)\n",
    "            # This will prevent the gradient descents from the previous batches to accumulate. Without this the weight will get updated with the sum of\n",
    "            # all previos gradient descents, instead of the gradient descents on the current batch.\n",
    "            optimizer.zero_grad() \n",
    "            output = model(vector) # prediction / output from the model\n",
    "\n",
    "            loss = criterion(output, labels)  # We calculate the loss here\n",
    "            loss.backward() # Computes the derivative of the loss using backpropagation.\n",
    "            optimizer.step() # We update the weights\n",
    "\n",
    "            running_loss += loss.item() # Sum the loss here\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        else:\n",
    "            results.append(running_loss / len(train_loader))  # We append the mean loss into a list\n",
    "            accuracies.append(correct / total)\n",
    "    \n",
    "        # Validation part\n",
    "        model.eval()\n",
    "        with torch.no_grad(): # This will prevent calculation of gradient descents\n",
    "            for batch in valid_loader:\n",
    "                vector = batch[:, :vocab_length]\n",
    "                labels = batch[:, vocab_length]\n",
    "                valid_output = model(vector) # Prediciton\n",
    "                loss = criterion(valid_output, labels.long()) # Calculation of loss\n",
    "                valid_loss += loss.item() # Sum the loss\n",
    "\n",
    "                _, predicted = torch.max(valid_output.data, 1)\n",
    "                total_valid += labels.size(0)\n",
    "                correct_valid += (predicted == labels).sum().item()\n",
    "            else:\n",
    "                valid_results.append(valid_loss / len(valid_loader)) # Here we calculate the mean loss\n",
    "                valid_accuracies.append(correct_valid / total_valid)\n",
    "    return results, accuracies, valid_results, valid_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the learning rate and epoch.\n",
    "learning_rate = 0.00003\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-181-b33fb47361d0>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_torch = torch.tensor(train_torch, dtype=torch.float)\n",
      "<ipython-input-181-b33fb47361d0>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_torch = torch.tensor(valid_torch, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "# Buildint torch values\n",
    "\n",
    "train_torch = np.c_[X_train, Y_train]\n",
    "\n",
    "train_torch = torch.from_numpy(train_torch)\n",
    "train_torch = torch.tensor(train_torch, dtype=torch.float)\n",
    "\n",
    "valid_torch = np.c_[X_valid, Y_valid]\n",
    "\n",
    "valid_torch = torch.from_numpy(valid_torch)\n",
    "valid_torch = torch.tensor(valid_torch, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_torch, batch_size=1, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_torch, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model which is same as the model we'll use in GA\n",
    "model = nn.Sequential(nn.Linear(len(vocab), 16),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(16, 8),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(8,2)\n",
    "                     )\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-179-14579e24792d>:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "# Training with SDG using the model\n",
    "sgd_results, accuracies, sgd_results_valid, accuracies_valid = training(num_epochs, model, optimizer, criterion, train_loader, valid_loader, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sgd_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting the results\n",
    "x_axis = np.linspace(0, num_epochs, num_epochs)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(x_axis, sgd_results, label='Training')\n",
    "ax.plot(x_axis, sgd_results_valid, label='Validation')\n",
    "ax.set_ylabel(\"Mean CEL\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.grid()\n",
    "\n",
    "ax.set_yscale('log')\n",
    "#ax.set_xscale('log')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "len(sgd_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6962735133307321\n",
      "0.1728475492903295\n",
      "0.5004285714285714\n",
      "0.9410857142857143\n",
      "0.6916133698701858\n",
      "0.3230799564411482\n",
      "0.5041333333333333\n",
      "0.8730666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35000"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training mean CEL\", sgd_results[-1])\n",
    "print(\"Accuracy on training\", accuracies[-1])\n",
    "print(\"Validation mean CEL\", sgd_results_valid[-1])\n",
    "print(\"Accuracy on validation\", accuracies_valid[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draft codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-103-b4c45037dd8a>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  nparr3 = np.array([arr1, arr2, arr3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [3, 4],\n",
       "       [3, 4],\n",
       "       [3, 2],\n",
       "       [2, 1],\n",
       "       [9, 3]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = [1,2,3]\n",
    "arr2 = [4,5]\n",
    "arr3 = [7,8, 9,10]\n",
    "\n",
    "nparr3 = np.array([arr1, arr2, arr3])\n",
    "nparr = np.array([[1,2,3],[3,4,5],[4,5,6]])\n",
    "nparr2 = np.array([[1, 3],[3, 4],[3,4],[3,2],[2,1],[9,3]])\n",
    "\n",
    "np.argmax(nparr2, axis=1)\n",
    "nparr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa  uu\n",
      "aa  uu\n"
     ]
    }
   ],
   "source": [
    "string1 = \"aa \\x92 uu\"\n",
    "\n",
    "print(string1)\n",
    "\n",
    "text = re.sub(r'[\\\\x]', '', string1)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
