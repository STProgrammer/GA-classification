{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graded assignment 1 - text classification using Genetic Algorithms\n",
    "## By Abdullah Karagøz\n",
    "\n",
    "In this assignmetn we'll make a binary text classifier using genetic algorithms. We will classify movie reviews from IMDB as either negative or positive. This task consists of several steps:\n",
    "\n",
    "1. Preprocessing of the text\n",
    "2. Genetich Algorithm\n",
    "3. Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abdka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abdka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Upload the text\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from scipy import special\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File directories\n",
    "corpus_train_pos_root = 'aclImdb/train/pos/'\n",
    "corpus_train_neg_root = 'aclImdb/train/neg/'\n",
    "corpus_test_pos_root = 'aclImdb/test/pos/'\n",
    "corpus_test_neg_root = 'aclImdb/test/neg/'\n",
    "\n",
    "# Corpus file objects\n",
    "files_train_pos = PlaintextCorpusReader(corpus_train_pos_root, '.*')\n",
    "files_train_neg = PlaintextCorpusReader(corpus_train_neg_root, '.*')\n",
    "files_test_pos = PlaintextCorpusReader(corpus_test_pos_root, '.*')\n",
    "files_test_neg = PlaintextCorpusReader(corpus_test_neg_root, '.*')\n",
    "\n",
    "\n",
    "# Getting review texts, labels and rates all in arrays\n",
    "reviews_train_pos = [files_train_pos.open(n).read() for n in files_train_pos.fileids()]\n",
    "rates_train_pos = [int(re.split(\"_|\\.\", n)[-2]) for n in files_train_pos.fileids()]\n",
    "labels_train_pos = [np.array([1, 0])] * len(reviews_train_pos)\n",
    "\n",
    "reviews_train_neg = [files_train_neg.open(n).read() for n in files_train_neg.fileids()]\n",
    "rates_train_neg = [int(re.split(\"_|\\.\", n)[-2]) for n in files_train_neg.fileids()]\n",
    "labels_train_neg = [np.array([0, 1])] * len(reviews_train_neg)\n",
    "\n",
    "reviews_test_pos = [files_test_pos.open(n).read() for n in files_test_pos.fileids()]\n",
    "rates_test_pos = [int(re.split(\"_|\\.\", n)[-2]) for n in files_test_pos.fileids()]\n",
    "labels_test_pos = [np.array([1, 0])] * len(reviews_test_pos)\n",
    "\n",
    "reviews_test_neg = [files_test_neg.open(n).read() for n in files_test_neg.fileids()]\n",
    "rates_test_neg = [int(re.split(\"_|\\.\", n)[-2]) for n in files_test_neg.fileids()]\n",
    "labels_test_neg = [np.array([0, 1])] * len(reviews_test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting all into two Pandas dataframes - training set and testing set\n",
    "train_set = pd.DataFrame()\n",
    "test_set = pd.DataFrame()\n",
    "\n",
    "train_set['review'] = reviews_train_pos + reviews_train_neg\n",
    "train_set['rate'] = rates_train_pos + rates_train_neg\n",
    "train_set['label'] = labels_train_pos + labels_train_neg\n",
    "\n",
    "test_set['review'] = reviews_test_pos + reviews_test_neg\n",
    "test_set['rate'] = rates_test_pos + rates_test_neg\n",
    "test_set['label'] = labels_test_pos + labels_test_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I think to put this into own .PY file and import from there\n",
    "class text_preprocessor():\n",
    "    def __init__(self):\n",
    "        import nltk\n",
    "        import re\n",
    "        import string\n",
    "        \n",
    "        nltk.download('stopwords')\n",
    "        nltk.download('wordnet')\n",
    "        from nltk.corpus import stopwords\n",
    "        \", \".join(stopwords.words('english'))\n",
    "        from nltk.stem.wordnet import WordNetLemmatizer \n",
    "        \n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        self.punctuation = string.punctuation\n",
    "        \n",
    "        self.emoji_pattern = re.compile(\"[\"\n",
    "                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                u\"\\U00002702-\\U000027B0\"\n",
    "                                u\"\\U000024C2-\\U0001F251\"\n",
    "                                \"]+\", flags=re.UNICODE)\n",
    "        \n",
    "        # src : https://github.com/NeelShah18/emot/blob/master/emot/emo_unicode.py\n",
    "        self.emoticons = {\n",
    "            u\":‑\\)\":\"Happy face or smiley\",\n",
    "            u\":\\)\":\"Happy face or smiley\",\n",
    "            u\":-\\]\":\"Happy face or smiley\",\n",
    "            u\":\\]\":\"Happy face or smiley\",\n",
    "            u\":-3\":\"Happy face smiley\",\n",
    "            u\":3\":\"Happy face smiley\",\n",
    "            u\":->\":\"Happy face smiley\",\n",
    "            u\":>\":\"Happy face smiley\",\n",
    "            u\"8-\\)\":\"Happy face smiley\",\n",
    "            u\":o\\)\":\"Happy face smiley\",\n",
    "            u\":-\\}\":\"Happy face smiley\",\n",
    "            u\":\\}\":\"Happy face smiley\",\n",
    "            u\":-\\)\":\"Happy face smiley\",\n",
    "            u\":c\\)\":\"Happy face smiley\",\n",
    "            u\":\\^\\)\":\"Happy face smiley\",\n",
    "            u\"=\\]\":\"Happy face smiley\",\n",
    "            u\"=\\)\":\"Happy face smiley\"\n",
    "        }\n",
    "\n",
    "    def lower_case(self, text):\n",
    "        return str.lower(text)\n",
    "    \n",
    "    def remove_punctuation(self, text):\n",
    "        return text.translate(str.maketrans('', '', self.punctuation))\n",
    "    \n",
    "    def remove_stopwords(self, text):\n",
    "        return \" \".join([word for word in str(text).split() if word not in self.stop_words])\n",
    "    \n",
    "    def remove_words(self, text, freq_words):\n",
    "        return \" \".join([word for word in str(text).split() if word not in freq_words])\n",
    "    \n",
    "    def remove_emoji(self, text):\n",
    "        # src: https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "        return self.emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    \n",
    "    def remove_emoticons(self, text):\n",
    "        import re\n",
    "        # src : https://github.com/NeelShah18/emot/blob/master/emot/emo_unicode.py\n",
    "        emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in self.emoticons) + u')')\n",
    "        return emoticon_pattern.sub(r'', text)\n",
    "    \n",
    "    def convert_emoticons(self, text):\n",
    "        # src : https://github.com/NeelShah18/emot/blob/master/emot/emo_unicode.py\n",
    "        for emot in self.emoticons:\n",
    "            text = re.sub(u'('+emot+')', \"_\".join(self.emoticons[emot].replace(\",\",\"\").split()), text)\n",
    "        return text\n",
    "    \n",
    "    def lemmatization(self, text):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = word_tokenize(text)\n",
    "        for i in ['v','n','a']:\n",
    "            tokens = [lemmatizer.lemmatize(word, i) for word in tokens]\n",
    "        text = \" \".join(tokens)\n",
    "        return text\n",
    "    \n",
    "    def expand_contractions(self, text):\n",
    "        text = re.sub(r\"i'm\", \" i am \", text)\n",
    "        text = re.sub(r\" im \", \" i am \", text)\n",
    "        text = re.sub(r\"\\: p\", \"\", text)\n",
    "        text = re.sub(r\" ive \", \" i have \", text)\n",
    "        text = re.sub(r\" he's \", \" he is \", text)\n",
    "        text = re.sub(r\" she's \", \" she is \", text)\n",
    "        text = re.sub(r\" that's \", \" that is \", text)\n",
    "        text = re.sub(r\" what's \", \" what is \", text)\n",
    "        text = re.sub(r\" where's \", \" where is \", text)\n",
    "        text = re.sub(r\" haven't \", \" have not \", text)\n",
    "        text = re.sub(r\" ur \", \" you are \", text)\n",
    "        text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "        text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "        text = re.sub(r\"\\'re\", \" are\", text)\n",
    "        text = re.sub(r\"\\'d\", \" would\", text)\n",
    "        text = re.sub(r\" won't \", \" will not \", text)\n",
    "        text = re.sub(r\" wouldn't \", \" would not \", text)\n",
    "        text = re.sub(r\" can't \", \" cannot \", text)\n",
    "        text = re.sub(r\" cannot \", \" cannot \", text)\n",
    "        text = re.sub(r\" don't \", \" do not \", text)\n",
    "        text = re.sub(r\" didn't \", \" did not \", text)\n",
    "        text = re.sub(r\" doesn't \", \" does not \", text)\n",
    "        text = re.sub(r\" isn't \", \" is not \", text)\n",
    "        text = re.sub(r\" it's \", \" it is \", text)\n",
    "        text = re.sub(r\" who's \", \" who is \", text)\n",
    "        text = re.sub(r\" there's \", \" there is \", text)\n",
    "        text = re.sub(r\" weren't \", \" were not \", text)\n",
    "        text = re.sub(r\" okay \", \" o\", text)\n",
    "        text = re.sub(r\" you're \", \" you are \", text)\n",
    "        text = re.sub(r\" c'mon \", \" come on \", text)\n",
    "        text = re.sub(r\"in'\", \"ing\", text)\n",
    "        text = re.sub(r\"\\'s\", \" s\", text)\n",
    "        return text\n",
    "    \n",
    "    def remove_urls(self, text):\n",
    "        url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "        return url_pattern.sub(r'', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing function\n",
    "def preprocess_imdb_reviews(preprocessor, df):\n",
    "    df['review'] = df['review'].apply(lambda text: preprocessor.lower_case(text))\n",
    "    df['review'] = df['review'].apply(lambda text: preprocessor.expand_contractions(text))\n",
    "    df['review'] = df['review'].apply(lambda text: preprocessor.remove_urls(text))\n",
    "    df['review'] = df['review'].apply(lambda text: preprocessor.remove_emoji(text))\n",
    "    df['review'] = df['review'].apply(lambda text: preprocessor.remove_punctuation(text))\n",
    "    df['review'] = df['review'].apply(lambda text: preprocessor.remove_stopwords(text))\n",
    "    df['review'] = df['review'].apply(lambda text: preprocessor.lemmatization(text))\n",
    "\n",
    "\n",
    "    from collections import Counter\n",
    "    cnt = Counter()\n",
    "    cnt2 = Counter()\n",
    "    for text in df[\"review\"].values:\n",
    "        # Counting the words\n",
    "        for word in text.split():\n",
    "            cnt[word] += 1\n",
    "        # Counting in how many reviews the word appears\n",
    "        for word in set(text.split()):\n",
    "            cnt2[word] += 1\n",
    "\n",
    "    # Removing most frequent words\n",
    "    n_freq_words = 0\n",
    "    freq_words = set([w for (w, wc) in cnt.most_common(n_freq_words)])\n",
    "    df['review'] = df['review'].apply(lambda text: preprocessor.remove_words(text, freq_words))\n",
    "\n",
    "    # Removing rarest words\n",
    "    n_rare_words = 0\n",
    "    rare_words = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
    "    df['review'] = df['review'].apply(lambda text: preprocessor.remove_words(text, rare_words))\n",
    "    \n",
    "    \n",
    "    # Remove words used in >90% and <5% of the reviews\n",
    "    curb_max_amount = len(df) * 0.90\n",
    "    curb_min_amount = len(df) * 0.05\n",
    "\n",
    "    curb_words = set([w for (w, wc) in cnt2.most_common() if wc > curb_max_amount or wc < curb_min_amount])\n",
    "    df['review'] = df['review'].apply(lambda text: preprocessor.remove_words(text, curb_words))\n",
    "    \n",
    "    return df\n",
    "\n",
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abdka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abdka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high comedy run time life year lead believe hi...</td>\n",
       "      <td>9</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year never help consider human everything go w...</td>\n",
       "      <td>8</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best ever see love scene second face classic g...</td>\n",
       "      <td>10</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>film sure give view say give view give view ma...</td>\n",
       "      <td>7</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>film much le movie actually plot make movie ac...</td>\n",
       "      <td>8</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>end movie felt felt like watch like see guess ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>kind movie watch time true watch make sure bad...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>saw last night film one see small movie fan so...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>film turn rather good film release american mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>one film ever see ever make br good line chara...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rate   label\n",
       "0      high comedy run time life year lead believe hi...     9  [1, 0]\n",
       "1      year never help consider human everything go w...     8  [1, 0]\n",
       "2      best ever see love scene second face classic g...    10  [1, 0]\n",
       "3      film sure give view say give view give view ma...     7  [1, 0]\n",
       "4      film much le movie actually plot make movie ac...     8  [1, 0]\n",
       "...                                                  ...   ...     ...\n",
       "24995  end movie felt felt like watch like see guess ...     4  [0, 1]\n",
       "24996  kind movie watch time true watch make sure bad...     3  [0, 1]\n",
       "24997  saw last night film one see small movie fan so...     3  [0, 1]\n",
       "24998  film turn rather good film release american mo...     1  [0, 1]\n",
       "24999  one film ever see ever make br good line chara...     1  [0, 1]\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the preprocessor\n",
    "preprocessor = text_preprocessor()\n",
    "train_set_processed = preprocess_imdb_reviews(preprocessor, train_set)\n",
    "test_set_processed = preprocess_imdb_reviews(preprocessor, test_set)\n",
    "train_set_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FUNCTIONS TO VECTORIZE\n",
    "\n",
    "# Get the IDF values and VOCAB vector\n",
    "def get_idf_vocab(df):\n",
    "    from collections import Counter\n",
    "    import math\n",
    "    \n",
    "    # Prepare the vocab\n",
    "    vocab = set(\" \".join(train_set_processed['review'].values).split())\n",
    "    vocab = dict.fromkeys(vocab, 0)\n",
    "    vocab.update((k, i) for i, k in enumerate(vocab))\n",
    "    \n",
    "    # Counting how many reviews a word appears in\n",
    "    cnt = Counter()\n",
    "    for text in df[\"review\"].values:\n",
    "        for word in set(text.split()):\n",
    "            cnt[word] += 1\n",
    "    # Preparing the IDF vector\n",
    "    size = len(df)\n",
    "    idfs = dict()\n",
    "    for w, c in cnt.items():\n",
    "        idfs[w] = 0 if c == 0 else math.log(size / c)\n",
    "    \n",
    "    return idfs, vocab\n",
    "\n",
    "\n",
    "# TF-IDF vectorize a single text, returning a np.array\n",
    "def tf_idf_vectorize(text, idfs, vocab):\n",
    "    freq_dist = nltk.FreqDist(text.split())\n",
    "    \n",
    "    vector = np.zeros(len(vocab))\n",
    "    \n",
    "    for w, c in freq_dist.items():\n",
    "        if w in vocab:\n",
    "            vector[vocab[w]] = c * idfs[w]\n",
    "    \n",
    "    return vector\n",
    "\n",
    "# Vectorize all in the dataset\n",
    "def tf_idf_vectorize_all(df, idfs, vocab):\n",
    "    df['vectors'] = df['review'].apply(lambda text: tf_idf_vectorize(text, idfs, vocab))\n",
    "    return df\n",
    "    \n",
    "\n",
    "# Get the IDF values and VOCAB vector\n",
    "idfs, vocab = get_idf_vocab(train_set_processed)\n",
    "\n",
    "# Vectorizing train set and test set\n",
    "train_set_processed = tf_idf_vectorize_all(train_set_processed, idfs, vocab)\n",
    "test_set_processed = tf_idf_vectorize_all(test_set_processed, idfs, vocab)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier\n",
    "There are a lot of classifiers. I haven't any experience in most of them, just a little familiar with Neural Network. When assigning fitness in GA I have to test-run all the 25k samples. If I have X number of classifiers and I'll run in N number of generations, then the complexity of running the GA will be at least like:\n",
    "X * N * 25,000. That'll be a big number, and my computer is not that fast.\n",
    "\n",
    "Taking hardware limitations into account, I wanted to choose a model that's quick to run. NN with multilayers may be too complicated and too slow to run. This make experimenting with different methods and tuning hyper-parameters very difficult.\n",
    "\n",
    "After taking a quick look at this link:\n",
    "https://medium.com/text-classification-algorithms/text-classification-algorithms-a-survey-a215b7ab7e2d\n",
    "\n",
    "I decided a simple SVM  would be best to try using as classifier as it's quick to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier():\n",
    "    def __init__(self, idfs, vocab):\n",
    "        self.idfs = idfs\n",
    "        self.vocab = vocab\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return (x > 0) * x \n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        from scipy import special\n",
    "        return special.expit(x)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        import numpy as np\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum()\n",
    "\n",
    "    def cross_entropy(self, p, y):\n",
    "        import numpy as np\n",
    "        return -(sum(np.nan_to_num(y*np.log(p))))\n",
    "    \n",
    "    def predict_single_row(self, x, y, w_1, w_2):\n",
    "        #forward pass/prediction\n",
    "        layer_1 = self.relu(x.dot(w_1))\n",
    "\n",
    "        layer_out = self.softmax(layer_1.dot(w_2))\n",
    "\n",
    "        return layer_out\n",
    "    \n",
    "    def predict_whole_set(self, df, w_1, w_2):\n",
    "        df['predictions'] = df.apply(lambda vec: self.predict_single_row(vec.vectors, vec.label, w_1, w_2), axis=1)\n",
    "        df['CE-loss'] = df.apply(lambda x: self.cross_entropy(x.predictions, x.label), axis=1)\n",
    "        mean_loss = df['CE-loss'].mean()\n",
    "        return mean_loss, df\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing weights\n",
    "def init_weights():\n",
    "    np.random.seed(5)\n",
    "    hidden_nodes = 8\n",
    "    ws_1 = np.random.rand(len(vocab), hidden_nodes) - 0.5\n",
    "    ws_2 = np.random.rand(hidden_nodes, 2) - 0.5\n",
    "    return ws_1, ws_2\n",
    "\n",
    "ws_1, ws_2 = init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(idfs, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, output_df = classifier.predict_whole_set(test_set_processed, ws_1, ws_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7007500825724318\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "      <th>label</th>\n",
       "      <th>vectors</th>\n",
       "      <th>predictions</th>\n",
       "      <th>CE-loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go saw movie last night friend see know comedy...</td>\n",
       "      <td>10</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.5764957613619086, ...</td>\n",
       "      <td>[0.9174607928881857, 0.08253920711181426]</td>\n",
       "      <td>0.086145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actor turn director follow family u open young...</td>\n",
       "      <td>7</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.9405757566456582, 0.05942424335434174]</td>\n",
       "      <td>0.061263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>early movie well fight young go eye american a...</td>\n",
       "      <td>9</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[2.8383867028302134, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.6642002324125545, 0.3357997675874454]</td>\n",
       "      <td>0.409172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saw film act good story movie well film could ...</td>\n",
       "      <td>8</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.6296536964942897, 0.37034630350571035]</td>\n",
       "      <td>0.462585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>take true story u open make film much film als...</td>\n",
       "      <td>8</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[2.8383867028302134, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.7886726473959893, 0.21132735260401064]</td>\n",
       "      <td>0.237404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>let kid watch understand show minute br anyone...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.9649670765399989, 0.03503292346000097]</td>\n",
       "      <td>3.351467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>pretty much tv show people make reason can not...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.999365090360261, 0.0006349096397389085]</td>\n",
       "      <td>7.362028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>try make lot use title bring small surprise ch...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.976...</td>\n",
       "      <td>[0.9954322581746063, 0.004567741825393718]</td>\n",
       "      <td>5.388736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>thing film star always watch feature new film ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.0, 0.0, 2.256847201320192, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.6864880335728475, 0.31351196642715246]</td>\n",
       "      <td>1.159918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>comment well write almost say everything feel ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.5236542010437...</td>\n",
       "      <td>[0.9976315549407891, 0.0023684450592108197]</td>\n",
       "      <td>6.045522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rate   label  \\\n",
       "0      go saw movie last night friend see know comedy...    10  [1, 0]   \n",
       "1      actor turn director follow family u open young...     7  [1, 0]   \n",
       "2      early movie well fight young go eye american a...     9  [1, 0]   \n",
       "3      saw film act good story movie well film could ...     8  [1, 0]   \n",
       "4      take true story u open make film much film als...     8  [1, 0]   \n",
       "...                                                  ...   ...     ...   \n",
       "24995  let kid watch understand show minute br anyone...     1  [0, 1]   \n",
       "24996  pretty much tv show people make reason can not...     1  [0, 1]   \n",
       "24997  try make lot use title bring small surprise ch...     3  [0, 1]   \n",
       "24998  thing film star always watch feature new film ...     3  [0, 1]   \n",
       "24999  comment well write almost say everything feel ...     4  [0, 1]   \n",
       "\n",
       "                                                 vectors  \\\n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 2.5764957613619086, ...   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2      [2.8383867028302134, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4      [2.8383867028302134, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                  ...   \n",
       "24995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "24996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "24997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.976...   \n",
       "24998  [0.0, 0.0, 2.256847201320192, 0.0, 0.0, 0.0, 0...   \n",
       "24999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.5236542010437...   \n",
       "\n",
       "                                       predictions   CE-loss  \n",
       "0        [0.9174607928881857, 0.08253920711181426]  0.086145  \n",
       "1        [0.9405757566456582, 0.05942424335434174]  0.061263  \n",
       "2         [0.6642002324125545, 0.3357997675874454]  0.409172  \n",
       "3        [0.6296536964942897, 0.37034630350571035]  0.462585  \n",
       "4        [0.7886726473959893, 0.21132735260401064]  0.237404  \n",
       "...                                            ...       ...  \n",
       "24995    [0.9649670765399989, 0.03503292346000097]  3.351467  \n",
       "24996   [0.999365090360261, 0.0006349096397389085]  7.362028  \n",
       "24997   [0.9954322581746063, 0.004567741825393718]  5.388736  \n",
       "24998    [0.6864880335728475, 0.31351196642715246]  1.159918  \n",
       "24999  [0.9976315549407891, 0.0023684450592108197]  6.045522  \n",
       "\n",
       "[25000 rows x 6 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(loss)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chromosome:\n",
    "    # x_pos and y_pos are the features of our chromosome\n",
    "    def __init__(self, ws_1, ws_2):\n",
    "        self._fitness = 0\n",
    "        self._ws_1 = ws_1\n",
    "        self._ws_2 = ws_2\n",
    "    \n",
    "    # Getters and setters\n",
    "    @property\n",
    "    def ws_1(self):\n",
    "        return self._ws_1\n",
    "    \n",
    "    @ws_1.setter\n",
    "    def ws_1(self, value):\n",
    "        self._ws_1 = value\n",
    "    \n",
    "    @property\n",
    "    def ws_2(self):\n",
    "        return self._ws_2\n",
    "    \n",
    "    @ws_2.setter\n",
    "    def ws_2(self, value):\n",
    "        self._ws_2 = value\n",
    "    \n",
    "    @property\n",
    "    def fitness(self):\n",
    "        return self._fitness\n",
    "    \n",
    "    @fitness.setter\n",
    "    def fitness(self, value):\n",
    "        self._fitness = value\n",
    "    \n",
    "    def assign_fitness(self, classifier, data_set):\n",
    "        import math\n",
    "        loss, _ = classifier.predict_whole_set(data_set, self.ws_1, self.ws_2)\n",
    "        self.fitness = 1/loss #0 if loss <= 0 or loss == float('inf') else -math.log(1 / loss)\n",
    "    \n",
    "    # produce a new offspring from 2 parents\n",
    "    def crossover(self, other):\n",
    "        r = 0\n",
    "        \n",
    "        min_mat_1 = np.minimum(self.ws_1, other.ws_1)\n",
    "        max_mat_1 = np.maximum(self.ws_1, other.ws_1)\n",
    "        min_mat_2 = np.minimum(self.ws_2, other.ws_2)\n",
    "        max_mat_2 = np.maximum(self.ws_2, other.ws_2)\n",
    "        \n",
    "        ws_1 = np.random.uniform(min_mat_1-r, max_mat_1+r)\n",
    "        ws_2 = np.random.uniform(min_mat_2-r, max_mat_2+r) \n",
    "        \n",
    "        offspring = Chromosome(ws_1, ws_2)\n",
    "        return offspring\n",
    "\n",
    "    # mutate the individual\n",
    "    def mutate(self):\n",
    "        np.random.shuffle(self.ws_1)\n",
    "        self.ws_1 = self.ws_1 + np.random.uniform(-1, 1, size=self.ws_1.shape)\n",
    "        np.random.shuffle(self.ws_2)\n",
    "        self.ws_2 = self.ws_2 + np.random.uniform(-1, 1, size=self.ws_2.shape)\n",
    "        return\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAEngine:\n",
    "    def __init__(self):\n",
    "        self.population = []\n",
    "        self.food = []\n",
    "        self.generations = 0\n",
    "\n",
    "    def make_initial_population(self, population_size):       \n",
    "        for i in range(population_size):\n",
    "            ws_1, ws_2 = self.init_weights()\n",
    "            self.population.append(Chromosome(ws_1, ws_2))\n",
    "    \n",
    "    def set_generations(self, g):\n",
    "        self.generations = g\n",
    "        return\n",
    "        \n",
    "    def get_generations(self):\n",
    "        return self.generations\n",
    "\n",
    "            \n",
    "    # Initializing weights\n",
    "    def init_weights(self):\n",
    "        hidden_nodes = 8\n",
    "        ws_1 = np.random.rand(len(vocab), hidden_nodes) - 0.5\n",
    "        ws_2 = np.random.rand(hidden_nodes, 2) - 0.5\n",
    "        return ws_1, ws_2\n",
    "    \n",
    "\n",
    "    # selection code goes here...\n",
    "    def do_crossover(self, no_of_offspring):\n",
    "        import random\n",
    "        population_size = len(self.population)\n",
    "        # Here we combine elitism selection with roulette wheel\n",
    "        # We carry ca 40 % of the most fit over to the next generation.\n",
    "        # Then we use roulette wheel because we want diversity too.\n",
    "        # We want diversity because the foods are repositioned to different places.\n",
    "        \n",
    "        # Get the top ca 40 % fittest.\n",
    "        rate_to_keep = 0.1\n",
    "        keep_nr = int(population_size * rate_to_keep)\n",
    "        self.population = sorted(self.population, key=lambda x: x.fitness)\n",
    "        new_generation = self.population[-keep_nr:]\n",
    "        \n",
    "        # new_generation = list()\n",
    "\n",
    "        # Then we make offsprings based on random choices with weights.\n",
    "        # We raise the exponent fitness to 2 to make the differences more\n",
    "        # Since we are using \"roulette wheel\" in selection, we want to increase the chance of\n",
    "        # the most fit to be selected.\n",
    "        fitness_values = [x.fitness**2 for x in self.population]\n",
    "        for i in range(no_of_offspring):\n",
    "            parent1, parent2 = random.choices(self.population, weights=fitness_values, k=2)\n",
    "            offspring = parent1.crossover(parent2)\n",
    "            new_generation.append(offspring)\n",
    "        \n",
    "        self.population = new_generation\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # fitness calculation goes here...\n",
    "    def assign_fitness(self, classifier, data_set):\n",
    "        # Fitness is 987 substracted by distance to closest food\n",
    "        # We want the chromosomes close to some food to survive, not close to all foods on average.\n",
    "        nr_of_foods = len(self.food)\n",
    "        for ch in self.population:\n",
    "            ch.assign_fitness(classifier, data_set)\n",
    "        return\n",
    "    \n",
    "    def get_population(self):\n",
    "        return self.population\n",
    "    \n",
    "    def get_best_chromosome(self):\n",
    "        ch = max(self.population, key=lambda x: x.fitness)\n",
    "        return ch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I run the GA engine\n",
    "ga = GAEngine()\n",
    "ga.make_initial_population(10)\n",
    "ga.set_generations(10)\n",
    "\n",
    "\n",
    "for i in range(ga.get_generations()):\n",
    "    ga.assign_fitness(classifier, test_set_processed)\n",
    "    # ca 60 % of population to do crossover\n",
    "    no_of_crossover = int(0.6 * len(ga.get_population()))\n",
    "    ga.do_crossover(no_of_crossover)\n",
    "\n",
    "\n",
    "    # High number of mutations for more variations\n",
    "    no_of_mutation = 2\n",
    "    for i in range(no_of_mutation):\n",
    "        index = random.randint(0, len(ga.get_population())-1)\n",
    "        ga.get_population()[index].mutate()\n",
    "\n",
    "ch = ga.get_best_chromosome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1260330112122419\n"
     ]
    }
   ],
   "source": [
    "print(ch.fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, output_df = classifier.predict_whole_set(test_set_processed, ch.ws_1, ch.ws_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8880734312783958\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "      <th>label</th>\n",
       "      <th>vectors</th>\n",
       "      <th>predictions</th>\n",
       "      <th>CE-loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go saw movie last night friend see know comedy...</td>\n",
       "      <td>10</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.5764957613619086, ...</td>\n",
       "      <td>[0.3530779853400781, 0.6469220146599218]</td>\n",
       "      <td>1.041066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actor turn director follow family u open young...</td>\n",
       "      <td>7</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.5518464811056155, 0.4481535188943845]</td>\n",
       "      <td>0.594485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>early movie well fight young go eye american a...</td>\n",
       "      <td>9</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[2.8383867028302134, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.7373063721280751, 0.26269362787192485]</td>\n",
       "      <td>0.304752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saw film act good story movie well film could ...</td>\n",
       "      <td>8</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.4681015105176985, 0.5318984894823016]</td>\n",
       "      <td>0.759070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>take true story u open make film much film als...</td>\n",
       "      <td>8</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[2.8383867028302134, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.4171412605851502, 0.5828587394148498]</td>\n",
       "      <td>0.874330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>let kid watch understand show minute br anyone...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.4797191937374103, 0.5202808062625897]</td>\n",
       "      <td>0.653387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>pretty much tv show people make reason can not...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.6747361708125804, 0.32526382918741953]</td>\n",
       "      <td>1.123119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>try make lot use title bring small surprise ch...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.976...</td>\n",
       "      <td>[0.37510529933786335, 0.6248947006621366]</td>\n",
       "      <td>0.470172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>thing film star always watch feature new film ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.0, 0.0, 2.256847201320192, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.30186384610608336, 0.6981361538939167]</td>\n",
       "      <td>0.359341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>comment well write almost say everything feel ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.5236542010437...</td>\n",
       "      <td>[0.3413410009974188, 0.6586589990025813]</td>\n",
       "      <td>0.417549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rate   label  \\\n",
       "0      go saw movie last night friend see know comedy...    10  [1, 0]   \n",
       "1      actor turn director follow family u open young...     7  [1, 0]   \n",
       "2      early movie well fight young go eye american a...     9  [1, 0]   \n",
       "3      saw film act good story movie well film could ...     8  [1, 0]   \n",
       "4      take true story u open make film much film als...     8  [1, 0]   \n",
       "...                                                  ...   ...     ...   \n",
       "24995  let kid watch understand show minute br anyone...     1  [0, 1]   \n",
       "24996  pretty much tv show people make reason can not...     1  [0, 1]   \n",
       "24997  try make lot use title bring small surprise ch...     3  [0, 1]   \n",
       "24998  thing film star always watch feature new film ...     3  [0, 1]   \n",
       "24999  comment well write almost say everything feel ...     4  [0, 1]   \n",
       "\n",
       "                                                 vectors  \\\n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 2.5764957613619086, ...   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2      [2.8383867028302134, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4      [2.8383867028302134, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                  ...   \n",
       "24995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "24996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "24997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.976...   \n",
       "24998  [0.0, 0.0, 2.256847201320192, 0.0, 0.0, 0.0, 0...   \n",
       "24999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.5236542010437...   \n",
       "\n",
       "                                     predictions   CE-loss  \n",
       "0       [0.3530779853400781, 0.6469220146599218]  1.041066  \n",
       "1       [0.5518464811056155, 0.4481535188943845]  0.594485  \n",
       "2      [0.7373063721280751, 0.26269362787192485]  0.304752  \n",
       "3       [0.4681015105176985, 0.5318984894823016]  0.759070  \n",
       "4       [0.4171412605851502, 0.5828587394148498]  0.874330  \n",
       "...                                          ...       ...  \n",
       "24995   [0.4797191937374103, 0.5202808062625897]  0.653387  \n",
       "24996  [0.6747361708125804, 0.32526382918741953]  1.123119  \n",
       "24997  [0.37510529933786335, 0.6248947006621366]  0.470172  \n",
       "24998  [0.30186384610608336, 0.6981361538939167]  0.359341  \n",
       "24999   [0.3413410009974188, 0.6586589990025813]  0.417549  \n",
       "\n",
       "[25000 rows x 6 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(loss)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "mat1 = np.array([[5,5,5,2], [1,3,14,5], [-6,4,2,3]])\n",
    "mat2 = np.array([[5,5,5,2], [1,3,14,5], [6,4,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n"
     ]
    }
   ],
   "source": [
    "if (mat1 >= 0).any():\n",
    "    print(\"aaa\")\n",
    "    \n",
    "if (mat2 < 0).any():\n",
    "    print(\"bbb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.shuffle(mat1)\n",
    "np.random.uniform(low=-2, high=1, size=(3,5))\n",
    "mat3 = mat1 + np.random.uniform(-1,1,size=(mat1.shape))\n",
    "mat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test(object):\n",
    "    def __init__(self):\n",
    "        self._ws_1 = None\n",
    "    \n",
    "    @property\n",
    "    def ws_1(self):\n",
    "        return self._ws_1 + 1\n",
    "    \n",
    "    @ws_1.setter\n",
    "    def ws_1(self, x):\n",
    "        self._ws_1 = x + 2\n",
    "        \n",
    "    def func(self, x):\n",
    "        self.ws_1 = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[  0. -inf  nan   0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-157-1c16c3678d74>:5: RuntimeWarning: divide by zero encountered in log\n",
      "  summ = y*np.log(p)\n",
      "<ipython-input-157-1c16c3678d74>:5: RuntimeWarning: invalid value encountered in multiply\n",
      "  summ = y*np.log(p)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.7976931348623157e+308"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.array([1,0,0,1])\n",
    "y = np.array([1,1,0,0])\n",
    "\n",
    "print(type(p))\n",
    "summ = y*np.log(p)\n",
    "print(summ)\n",
    "\n",
    "sum(np.nan_to_num(summ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "-12\n"
     ]
    }
   ],
   "source": [
    "t.ws_1 = 5\n",
    "\n",
    "print(t.ws_1)\n",
    "\n",
    "t.func(-15)\n",
    "print(t.ws_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
